# Analise da Implementacao de Otimizacao de Hiperparametros com Optuna

## Contexto da Implementacao

Durante o desenvolvimento deste trabalho, foi implementado um sistema de otimizacao de hiperparametros utilizando a biblioteca Optuna para tentar melhorar o desempenho dos modelos de previsao, especialmente o XGBoost. O Optuna e uma biblioteca de otimizacao automatica que utiliza algoritmos sofisticados como o Tree-structured Parzen Estimator (TPE) para explorar o espaco de hiperparametros de forma eficiente. A expectativa inicial era que a otimizacao sistematica dos hiperparametros pudesse reduzir o erro de previsao e melhorar a acuracia do modelo em comparacao com os parametros padrao.

## Metodologia de Otimizacao

A implementacao utilizou o TPE Sampler do Optuna, que e um algoritmo bayesiano que constroi modelos probabilisticos do espaco de hiperparametros para guiar a busca de forma inteligente. Foi configurado um MedianPruner para interromper trials pouco promissores prematuramente, economizando recursos computacionais. O processo de otimizacao foi executado com 100 trials, explorando um espaco de busca que incluia parametros como min_child_weight, n_estimators, max_depth, learning_rate, gamma, subsample, colsample_bytree, reg_alpha e reg_lambda. A validacao foi realizada utilizando cross-validation com fold ajustado automaticamente baseado no tamanho do dataset, sendo configurado para 3 folds devido ao tamanho limitado dos dados mensais agregados.

## Resultados Obtidos

Os resultados da otimizacao revelaram uma deterioracao significativa no desempenho do modelo quando comparado ao baseline. O modelo baseline, utilizando parametros conservadores padrao, apresentou um Mean Absolute Error (MAE) de 6.356.730, enquanto o modelo otimizado pelo Optuna alcancou um MAE de 7.242.888, representando uma piora de 13,94% no erro de previsao. Similarmente, o Root Mean Square Error (RMSE) aumentou de 7.691.304 para 8.622.235, uma degradacao de 12,10%, e o Mean Absolute Percentage Error (MAPE) subiu de 15,82% para 19,25%, indicando uma reducao de 21,67% na acuracia relativa. Estes resultados contra-intuitivos, onde a otimizacao sistematica piora o desempenho ao invez de melhora-lo, demandaram uma investigacao detalhada das causas subjacentes.

## Analise das Causas da Degradacao

A principal causa identificada para a piora no desempenho foi o tamanho limitado do dataset disponivel para treinamento e validacao. Apos a agregacao mensal dos dados de vendas, o dataset resultante continha apenas 120 pontos temporais, cobrindo o periodo de outubro de 2015 a setembro de 2025. Com a divisao temporal dos dados respeitando a ordem cronologica, foram utilizados 96 pontos para treinamento (80%) e 24 pontos para teste (20%). Este tamanho de dataset e consideravelmente pequeno para tecnicas sofisticadas de otimizacao de hiperparametros, especialmente quando se utiliza cross-validation, que subdivide ainda mais os dados disponiveis.

Com apenas 96 pontos de treinamento divididos em 3 folds para cross-validation, cada fold de validacao continha aproximadamente 32 pontos mensais. Este numero extremamente reduzido de observacoes para validacao torna as metricas de avaliacao altamente volateis e sensiveis a variabilidade especifica de cada fold. O algoritmo de otimizacao, buscando minimizar o erro de validacao cruzada, acabou selecionando hiperparametros que se ajustavam excessivamente aos padroes especificos presentes nos folds de validacao, mas que nao generalizavam bem para o conjunto de teste final, caracterizando um fenomeno classico de overfitting no processo de validacao.

Alem disso, a natureza temporal dos dados de series temporais adiciona complexidade adicional ao problema. Series temporais de vendas frequentemente apresentam padroes sazonais, tendencias e mudancas estruturais que podem variar ao longo do tempo. Com um dataset pequeno, qualquer variacao atipica ou evento especifico capturado nos dados de validacao pode influenciar desproporcionalmente a escolha dos hiperparametros. O modelo otimizado pode ter aprendido a se ajustar a caracteristicas especificas do periodo de validacao que nao se repetiram no periodo de teste, resultando em previsoes menos acuradas quando aplicado a dados futuros.

Outro fator relevante e a complexidade do espaco de hiperparametros explorado. O XGBoost possui multiplos hiperparametros interdependentes que interagem de formas complexas. A otimizacao simultanea de nove hiperparametros diferentes com apenas 120 pontos de dados totais cria um espaco de busca extremamente amplo em relacao a quantidade de informacao disponivel. Esta desproporcao entre a complexidade do modelo e o tamanho do dataset aumenta drasticamente o risco de encontrar configuracoes que performam bem nos dados de validacao por pura chance estatistica, mas que nao possuem capacidade de generalizacao para novos dados.

A analise de importancia dos hiperparametros realizada pelo Optuna revelou que o parametro min_child_weight foi identificado como o mais importante, com 66,66% de influencia sobre o desempenho do modelo. Este parametro controla o peso minimo necessario em um no filho para continuar a particao, funcionando como um regularizador que previne overfitting. O fato de este parametro ter sido identificado como o mais importante sugere que o modelo estava lutando para encontrar o equilibrio adequado entre complexidade e regularizacao, um desafio amplificado pela escassez de dados. A otimizacao pode ter ajustado este e outros parametros para valores que reduziram o erro de validacao cruzada a custa de maior variancia e menor robustez nas previsoes finais.

## Implicacoes para a Pratica de Machine Learning

Estes resultados demonstram uma licao importante sobre a aplicacao de tecnicas avancadas de machine learning: a otimizacao de hiperparametros nao e uma solucao universal e pode ser contraproducente quando aplicada a datasets de tamanho insuficiente. A literatura de aprendizado de maquina frequentemente recomenda que tecnicas sofisticadas de otimizacao sejam aplicadas apenas quando ha dados suficientes para suportar estimativas confiaveis de desempenho, tipicamente considerando minimo de 200-300 observacoes para series temporais mensais com validacao cruzada.

No contexto deste trabalho, os parametros conservadores padrao do modelo baseline demonstraram ser mais adequados precisamente porque incorporam conhecimento previo e boas praticas acumuladas pela comunidade, funcionando como uma forma de regularizacao implicita. Estes valores padrao foram calibrados para funcionar razoavelmente bem em uma ampla variedade de cenarios, incluindo aqueles com dados limitados. Ao tentar otimizar agressivamente os hiperparametros com dados insuficientes, o processo automatizado perdeu esta sabedoria implicita e ajustou o modelo de forma excessiva aos dados especificos de validacao disponivel.

## Recomendacoes e Alternativas

Para datasets de tamanho limitado como o utilizado neste trabalho, estrategias alternativas seriam mais apropriadas do que a otimizacao extensiva de hiperparametros. Uma abordagem mais conservadora seria realizar uma busca focada em um numero reduzido de hiperparametros mais importantes, mantendo os demais em seus valores padrao. Alternativamente, tecnicas de regularizacao mais fortes poderiam ser aplicadas durante a otimizacao, como a restricao do espaco de busca a valores mais conservadores ou o uso de penalizacoes explicitas para complexidade do modelo.

Outra estrategia relevante seria investir em engenharia de features ao invez de otimizacao de hiperparametros. Com datasets pequenos, a criacao de features informativas baseadas em conhecimento do dominio frequentemente produz ganhos mais robustos do que o ajuste fino de parametros. No contexto de previsao de vendas, isso poderia incluir a incorporacao de indicadores economicos externos, features de calendario mais elaboradas, ou a modelagem explicita de padroes sazonais conhecidos do negocio.

Finalmente, para trabalhos futuros com disponibilidade de mais dados historicos, seria interessante repetir o experimento de otimizacao com um dataset maior, idealmente com pelo menos 300-500 pontos temporais mensais. Com maior volume de dados, as tecnicas de otimizacao de hiperparametros teriam maior probabilidade de identificar configuracoes que genuinamente melhoram a generalizacao do modelo, ao invez de simplesmente se ajustarem aos artefatos especificos dos dados de validacao.

## Conclusao

A implementacao e teste da otimizacao de hiperparametros com Optuna, embora tenha resultado em piora do desempenho para este dataset especifico, forneceu insights valiosos sobre as limitacoes praticas de tecnicas avancadas de machine learning quando aplicadas a dados escassos. Os resultados reafirmam o principio fundamental de que mais sofisticacao tecnica nao substitui a necessidade de dados adequados, e que a escolha de metodos deve sempre considerar as caracteristicas e limitacoes do dataset disponivel. Para o proposito deste trabalho de comparar modelos de machine learning com metodos tradicionais de previsao em Power BI, a experiencia demonstrou que parametros conservadores bem estabelecidos sao mais confiaveis do que otimizacao automatizada quando os dados sao limitados, uma consideracao pratica relevante para aplicacoes empresariais reais onde datasets pequenos sao comuns.