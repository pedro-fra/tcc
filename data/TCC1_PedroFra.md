## UNIVERSIDADE DO VALE DO RIO DOS SINOS (UNISINOS) UNIDADE ACAD√äMICA DE GRADUA√á√ÉO CURSO DE ENGENHARIA DA COMPUTA√á√ÉO

## PEDRO DELAVALD FR√Å

## PREVIS√ÉO DE VENDAS:

An√°lise comparativa entre abordagens de aprendizado de m√°quina e Power BI

S√£o Leopoldo

## PEDRO DELAVALD FR√Å

## PREVIS√ÉO DE VENDAS:

An√°lise comparativa entre abordagens de aprendizado de m√°quina e Power BI

Trabalho de Conclus√£o de Curso apresentado  como  requisito  parcial  para obten√ß√£o do t√≠tulo de Bacharel em Engenharia da Computa√ß√£o, pelo Curso de Engenharia da Computa√ß√£o da Universidade  do  Vale  do  Rio  dos  Sinos (UNISINOS)

Orientador: Prof. MSc. Jean Schmith

## RESUMO

Este  trabalho  tem  como  objetivo  avaliar  e  comparar  o  desempenho  de diferentes  m√©todos  de  previs√£o  de  vendas,  utilizando  tanto  t√©cnicas  estat√≠sticas tradicionais  quanto  algoritmos  modernos  de  aprendizado  de  m√°quina,  aplicados  a dados reais de faturamento extra√≠dos de um dashboard corporativo em Power BI. Diante  do  aumento  da  competitividade  e  da  demanda  por  decis√µes  empresariais baseadas em dados, destaca-se a necessidade de modelos preditivos cada vez mais precisos e robustos. O estudo envolve a implementa√ß√£o dos modelos ARIMA, Theta, Suaviza√ß√£o Exponencial e XGBoost, analisando suas performances preditivas e as possibilidades de ado√ß√£o dessas abordagens no contexto empresarial. Os resultados s√£o avaliados a partir de m√©tricas estat√≠sticas padronizadas, permitindo identificar se algum modelo apresenta desempenho superior ao m√©todo atualmente empregado. A pesquisa contribui para a aproxima√ß√£o entre teoria e pr√°tica, oferecendo subs√≠dios para  a  escolha  de  m√©todos  de  previs√£o  mais  adequados  √†s  necessidades  das organiza√ß√µes e potencializando o valor estrat√©gico das an√°lises de vendas.

Palavras-chave: Previs√£o de Vendas; S√©ries Temporais; Aprendizado de M√°quina; Power  BI;  ARIMA;  XGBoost;  Suaviza√ß√£o  Exponencial;  M√©todo  Theta;  Business Intelligence.

## ABSTRACT

This  work  aims  to  evaluate  and  compare  the  performance  of  different  sales forecasting  methods,  employing  both  traditional  statistical  techniques  and  modern machine learning algorithms, applied to real revenue data extracted from a corporate dashboard in Power BI. Given the increasing competitiveness and demand for datadriven  business  decisions,  there  is  a  growing  need  for  more  accurate  and  robust predictive models. The study involves the implementation of ARIMA,  Theta, Exponential Smoothing, and XGBoost models, analyzing their predictive performance and the feasibility of adopting these approaches in corporate environments. The results are assessed using standardized statistical metrics, allowing for the identification of models that outperform the currently employed method. This research contributes to bridging the gap between theory and practice, offering guidance for the selection of forecasting  methods  that  best  fit  organizational  needs  and  enhancing  the  strategic value of sales analytics.

Key-words: Sales Forecasting; Time Series; Machine Learning; Power BI; ARIMA; XGBoost; Exponential Smoothing; Theta Method; Business Intelligence.

## LISTA DE FIGURAS

| Figura 1 - Metodologia geral do trabalho...................................................................30   |
|-----------------------------------------------------------------------------------------------------------------|
| Figura 2 - Metodologia do modelo ARIMA ................................................................34       |
| Figura 3 - Metodologia do modelo XGBoost.............................................................38         |
| Figura 4 - Metodologia do modelo de Suaviza√ß√£o Exponencial................................42                    |
| Figura 5 - Metodologia do modelo Theta...................................................................45     |

## LISTA DE QUADROS

## LISTA DE SIGLAS

| CNN     | Convolutional Neural Network                       |
|---------|----------------------------------------------------|
| RNN     | Recurrent Neural Network                           |
| ARIMA   | Auto Regressive Integrated Moving Average          |
| XGBoost | X Gradient Boost                                   |
| ML      | Machine Learning                                   |
| PIB     | Produto Interno Bruto                              |
| SARIMA  | Seasonal Auto Regressive Integrated Moving Average |
| LSTM    | Long Short-Term Memory                             |
| STL     | Seasonal and Trend decomposition using LOESS       |
| AIC     | Akaike Information Criterion                       |
| AR      | Auto Regressive                                    |
| MA      | Moving Average                                     |
| SES     | Simple Exponential Smoothing                       |
| ACF     | Autocorrelation Function                           |
| PACF    | Parcial Autocorrelation Function                   |
| KPSS    | Kwiatkowski-Phillips-Schmidt-Shin                  |
| ADF     | Augmented Dickey Fuller                            |
| RMSSE   | Root Mean Squared Scaled Error                     |
| RMSE    | Root Mean Squared Error                            |
| MAE     | Mean Absolute Error                                |
| BI      | Business Intelligence                              |
| GBDT    | Gradient Boosting Decision Tree                    |

## SUM√ÅRIO

| 1 INTRODU√á√ÉO.......................................................................................................11        |                                                                                                            |
|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| 1.1 TEMA..................................................................................................................11 |                                                                                                            |
| 1.2 DELIMITA√á√ÉO DO TEMA...................................................................................12                 |                                                                                                            |
| 1.3 PROBLEMA                                                                                                                 | ........................................................................................................12 |
| 1.4 OBJETIVOS........................................................................................................12      |                                                                                                            |
| 1.4.1 Objetivo geral                                                                                                         | .................................................................................................12        |
| 1.4.2 Objetivos espec√≠ficos.....................................................................................12           |                                                                                                            |
| 1.5 JUSTIFICATIVA                                                                                                            | ..................................................................................................13       |
| 2 FUNDAMENTA√á√ÉO TE√ìRICA.............................................................................14                       |                                                                                                            |
| 2.1 S√âRIES TEMPORAIS.........................................................................................14              |                                                                                                            |
| 2.1.1 Conceitos fundamentais e defini√ß√µes                                                                                    | ..........................................................14                                               |
| 2.1.2 Caracter√≠sticas principais..............................................................................14             |                                                                                                            |
| 2.1.3 Classifica√ß√µes de s√©ries temporais..............................................................15                     |                                                                                                            |
| 2.1.4 Exemplos de aplica√ß√£o..................................................................................16              |                                                                                                            |
| 2.2 M√âTODO THETA................................................................................................16           |                                                                                                            |
| 2.2.1 Descri√ß√£o geral e origem...............................................................................17              |                                                                                                            |
| 2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros..........................................................17                         |                                                                                                            |
| 2.2.3 Equa√ß√£o da linha Theta .................................................................................18             |                                                                                                            |
| 2.2.4 Express√µes aditivas e multiplicativas                                                                                  | ..........................................................18                                               |
| 2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros                                                                 | .....................18                                                                                    |
| 2.2.6 Exemplos pr√°ticos de uso.............................................................................19                |                                                                                                            |
| 2.3 MODELO ARIMA                                                                                                             | ................................................................................................20         |
| 2.3.1 Defini√ß√£o e estrutura do modelo ARIMA......................................................20                          |                                                                                                            |
| 2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA                                                                            | ...........................................21                                                              |
| 2.3.3 Como o modelo ARIMA funciona para prever dados futuros?                                                                | ..................21                                                                                       |
| 2.3.4 Casos pr√°ticos e exemplos na literatura......................................................22                        |                                                                                                            |
| 2.4 SUAVIZA√á√ÉO EXPONENCIAL...........................................................................23                      |                                                                                                            |
| 2.4.1 Defini√ß√£o e estrutura do m√©todo ..................................................................23                   |                                                                                                            |
| 2.4.2 Vantagens e limita√ß√µes na previs√£o de dados                                                                            | ............................................24                                                             |
| 2.4.3 Aplica√ß√µes e estudos de caso ......................................................................25                  |                                                                                                            |
| 2.5 XGBOOST...........................................................................................................26     |                                                                                                            |
| 2.5.1 Vis√£o geral do Extreme Gradient Boosting..................................................26                           |                                                                                                            |

| 2.5.2 Caracter√≠sticas e conceitos do XGBoost .....................................................27                        |                                                                                                 |
|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|
| 2.5.3 Como o XGBoost prev√™ dados futuros ........................................................27                         |                                                                                                 |
| 2.5.4 Exemplos pr√°ticos de uso do XGBoost........................................................29                         |                                                                                                 |
| 3 METODOLOGIA....................................................................................................30         |                                                                                                 |
| 3.1 METODOLOGIA DE TRABALHO                                                                                                 | .......................................................................30                       |
| 3.1.1 Defini√ß√£o do problema e objetivos da previs√£o                                                                         | ..........................................31                                                    |
| 3.1.2 Coleta e integra√ß√£o dos dados                                                                                         | .....................................................................31                         |
| 3.1.3 Pr√©-processamento e transforma√ß√µes dos dados                                                                          | ......................................32                                                        |
| 3.1.4 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal...............................32                                |                                                                                                 |
| 3.2 MODELOS DE PREVIS√ÉO UTILIZADOS...........................................................33                             |                                                                                                 |
| 3.2.1 ARIMA..............................................................................................................34 |                                                                                                 |
| 3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente...............................35                              |                                                                                                 |
| 3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal...................................35                             |                                                                                                 |
| 3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o                                                                      | ............................................35                                                  |
| 3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste                                                                    | ........................................36                                                      |
| 3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q.................................................................36                |                                                                                                 |
| 3.2.1.6 Treinamento do modelo.................................................................................36            |                                                                                                 |
| 3.2.1.7 Valida√ß√£o do modelo e ajustes finos .............................................................37                 |                                                                                                 |
| 3.2.1.8 An√°lise residual                                                                                                    | .............................................................................................37 |
| 3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura.............................37                                  |                                                                                                 |
| 3.2.2 XGBoost..........................................................................................................38   |                                                                                                 |
| 3.2.2.1 Prepara√ß√£o e engenharia de vari√°veis..........................................................38                    |                                                                                                 |
| 3.2.2.2 Divis√£o dos dados em treino e teste                                                                                 | .............................................................39                                 |
| 3.2.2.3 Normaliza√ß√£o e tratamento dos dados..........................................................39                     |                                                                                                 |
| 3.2.2.4 Configura√ß√£o dos hiper par√¢metros iniciais...................................................39                     |                                                                                                 |
| 3.2.2.5 Treinamento inicial do modelo.......................................................................40              |                                                                                                 |
| 3.2.2.6 Avalia√ß√£o inicial de desempenho                                                                                     | ..................................................................41                            |
| 3.2.2.7 Busca e ajuste de hiper par√¢metros..............................................................41                  |                                                                                                 |
| 3.2.2.8 Valida√ß√£o cruzada e an√°lise de resultados                                                                           | ...................................................41                                           |
| 3.2.2.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados                                                         | ..................41                                                                            |
| 3.2.3 Suaviza√ß√£o exponencial                                                                                                | ................................................................................42              |
| 3.2.3.1 Prepara√ß√£o dos dados                                                                                                | ..................................................................................42            |
| 3.2.3.2 An√°lise explorat√≥ria e estrutura da s√©rie temporal                                                                  | ........................................43                                                      |
| 3.2.3.3 Divis√£o em conjunto de treino e teste............................................................43                 |                                                                                                 |

10

| 3.2.3.4 Sele√ß√£o do tipo de suaviza√ß√£o exponencial e par√¢metros............................43                                  |                                                                 |
|-------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------|
| 3.2.3.5 Treinamento inicial do modelo.......................................................................44                |                                                                 |
| 3.2.3.6 Gera√ß√£o das previs√µes..................................................................................44             |                                                                 |
| 3.2.3.7 Avalia√ß√£o do desempenho............................................................................44                 |                                                                 |
| 3.2.3.8 Ajuste fino e revalida√ß√£o ...............................................................................44           |                                                                 |
| 3.2.3.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados                                                           | ..................44                                            |
| 3.2.4 Theta................................................................................................................45 |                                                                 |
| 3.2.4.1 Organiza√ß√£o e pr√©-condi√ß√µes dos dados......................................................45                         |                                                                 |
| 3.2.4.2 An√°lise inicial e sazonalidade........................................................................46              |                                                                 |
| 3.2.4.3 Separa√ß√£o temporal para avalia√ß√£o..............................................................46                     |                                                                 |
| 3.2.4.4 Configura√ß√£o e execu√ß√£o do algoritmo .........................................................46                      |                                                                 |
| 3.2.4.5 Produ√ß√£o das previs√µes e p√≥s-processamento.............................................46                             |                                                                 |
| 3.2.4.6 Avalia√ß√£o quantitativa e diagn√≥stico                                                                                  | .............................................................47 |
| 3.2.4.7 Itera√ß√£o e consolida√ß√£o dos resultados                                                                                | ........................................................47      |
| 3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS..............................................47                                        |                                                                 |
| 3.4 CRONOGRAMA..................................................................................................48            |                                                                 |
| REFER√äNCIAS.........................................................................................................49        |                                                                 |

## 1 INTRODU√á√ÉO

A previs√£o de vendas, no contexto atual da transforma√ß√£o digital e da crescente demanda por decis√µes empresariais baseadas em dados, se estabelece como um dos grandes desafios e diferenciais competitivos para organiza√ß√µes de todos os portes. Com  mercados  cada  vez  mais  din√¢micos  e  suscet√≠veis  a  varia√ß√µes  econ√¥micas, tecnol√≥gicas e comportamentais, a precis√£o nas estimativas de faturamento assume papel central no planejamento, controle de estoques, log√≠stica, defini√ß√£o de metas e estrat√©gias comerciais. Este cen√°rio impulsionou o avan√ßo de diferentes m√©todos de previs√£o,  desde  t√©cnicas  estat√≠sticas  tradicionais  at√©  abordagens  inovadoras  de aprendizado  de  m√°quina,  que  v√™m  transformando  a  forma  como  as  empresas analisam e projetam seus resultados futuros.

O uso disseminado de ferramentas de BI, como o Power BI, trouxe grandes avan√ßos  para  a  visualiza√ß√£o  e  interpreta√ß√£o  dos  dados  hist√≥ricos  das  empresas, permitindo  a  elabora√ß√£o  de  dashboards  customizados  para  acompanhamento  do desempenho de vendas. Contudo, muitos desses sistemas ainda utilizam m√©todos de previs√£o relativamente simples, que podem n√£o captar integralmente a complexidade dos  padr√µes  temporais,  sazonalidades  e  vari√°veis  ex√≥genas  presentes  nos  dados (ENSAFI et al., 2022). Paralelamente, algoritmos de ML, como o XGBoost, v√™m sendo destacados na literatura por sua elevada acur√°cia preditiva, robustez e flexibilidade na incorpora√ß√£o de m√∫ltiplos fatores ao processo de modelagem,  sendo escolhido frequentemente em cen√°rios reais e competi√ß√µes internacionais (CHEN; GUESTRIN, 2016).

Diante  desse  contexto,  torna-se  pertinente  avaliar,  sob  uma  perspectiva aplicada  e  comparativa,  se  modelos  de  ML  podem  efetivamente  aprimorar  as previs√µes  de  faturamento  realizadas  por  solu√ß√µes  j√°  consolidadas  no  ambiente empresarial, como o Power BI, contribuindo para a gera√ß√£o de insights mais robustos e embasados para a tomada de decis√£o.

## 1.1 TEMA

O presente trabalho aborda o tema da previs√£o de vendas utilizando s√©ries temporais,  com  foco  na  compara√ß√£o  entre  m√©todos  tradicionais  e  modernos  de modelagem preditiva aplicados a dados reais de faturamento empresarial.

## 1.2 DELIMITA√á√ÉO DO TEMA

A pesquisa concentra-se na an√°lise comparativa do desempenho de diferentes modelos de previs√£o utilizando dados hist√≥ricos extra√≠dos de um banco de dados. O estudo  limita-se  √†  previs√£o  de  faturamento  mensal,  simulando  o  contexto  pr√°tico enfrentado por empresas que necessitam estimar o resultado do m√™s corrente com base em informa√ß√µes parciais, do primeiro dia do m√™s at√© o momento da consulta.

## 1.3 PROBLEMA

O problema que orienta este trabalho √©: Modelos avan√ßados de aprendizado de  m√°quina  podem  proporcionar  previs√µes  mais  precisas  de  faturamento,  quando comparados  √†  abordagem  utilizada  em  dashboards  de  Power  BI?  A  investiga√ß√£o busca responder se a ado√ß√£o de modelos de aprendizado de m√°quina como XGBoost, ARIMA,  Suaviza√ß√£o  Exponencial  e  Theta  pode,  de  fato,  melhorar  a  acur√°cia  das proje√ß√µes realizadas atualmente pela empresa, promovendo maior confiabilidade e valor estrat√©gico √†s informa√ß√µes disponibilizadas.

## 1.4 OBJETIVOS

## 1.4.1 Objetivo geral

Avaliar,  de  forma  comparativa,  o  desempenho  de diferentes  abordagens  de previs√£o de vendas, sejam elas tradicionais ou baseadas em ML, aplicadas a dados reais  de  faturamento,  verificando  se  algum  dos  modelos  apresenta  desempenho superior ao m√©todo atualmente utilizado em dashboards de Power BI.

## 1.4.2 Objetivos espec√≠ficos

- a)  Revisar  e  contextualizar  os  principais  conceitos  de  s√©ries  temporais, m√©todos  estat√≠sticos  cl√°ssicos  e  t√©cnicas  de  ML  voltadas  √†  previs√£o  de vendas, conforme descrito por autores como Bezerra (2006), Makridakis, Wheelwright e Hyndman (1999) e Ensafi et al. (2022);

- b)  Estruturar  e  pr√©-processar  os  dados hist√≥ricos  de  faturamento  de  acordo com as exig√™ncias de cada modelo preditivo, assegurando anonimiza√ß√£o, integridade e conformidade com boas pr√°ticas de ci√™ncia de dados;
- c)  Implementar, treinar e validar modelos de previs√£o ARIMA,  Theta, Suaviza√ß√£o Exponencial e XGBoost, utilizando m√©tricas estat√≠sticas padronizadas para avalia√ß√£o do desempenho;
- d)  Analisar comparativamente os resultados obtidos e discutir as vantagens, limita√ß√µes e possibilidades pr√°ticas para ado√ß√£o dos m√©todos preditivos no contexto empresarial.

Acredita-se que essa abordagem possibilite uma an√°lise abrangente e rigorosa, identificando  as  oportunidades  e  desafios  envolvidos  na  transi√ß√£o  para  modelos preditivos mais avan√ßados no ambiente corporativo.

## 1.5 JUSTIFICATIVA

A relev√¢ncia deste estudo se justifica tanto pelo avan√ßo recente das t√©cnicas de an√°lise preditiva quanto pela necessidade real de organiza√ß√µes aprimorarem seus processos de tomada de decis√£o frente a cen√°rios de incerteza e competitividade. Do ponto  de  vista  acad√™mico,  h√°  uma  lacuna  na  literatura  nacional  sobre  aplica√ß√µes pr√°ticas  e  comparativas  de  modelos  de  machine  learning  em  ambientes  de  BI amplamente adotados por empresas brasileiras, como o Power BI (ENSAFI et al., 2022;  SHIRI  et  al.,  2024).  Internacionalmente,  pesquisas  v√™m  demonstrando  o potencial  de  algoritmos  como  XGBoost  na  supera√ß√£o  de  m√©todos  tradicionais  de previs√£o, especialmente em s√©ries temporais com padr√µes complexos e influ√™ncias externas (CHEN; GUESTRIN, 2016).

No √¢mbito empresarial, a ado√ß√£o de modelos mais precisos pode representar ganhos substanciais em  planejamento, controle financeiro e competitividade, permitindo que decis√µes sejam tomadas com maior base quantitativa e menor risco. Este  trabalho,  ao  propor  uma  an√°lise  comparativa  fundamentada,  contribui  para aproximar a teoria e a pr√°tica, orientando gestores e profissionais de dados quanto √† melhor escolha de m√©todos para suas demandas espec√≠ficas.

## 2 FUNDAMENTA√á√ÉO TE√ìRICA

Neste cap√≠tulo, apresenta-se o embasamento  te√≥rico indispens√°vel ao desenvolvimento  do  presente  estudo.  Ser√£o  discutidos  os  conceitos  fundamentais relacionados √† previs√£o de dados, contemplando tanto a aplica√ß√£o de algoritmos de aprendizado de m√°quina quanto a utiliza√ß√£o de c√°lculos no Power BI. A partir dessa fundamenta√ß√£o,  busca-se  sustentar  o  estudo  de  caso  realizado,  evidenciando  as principais  vantagens  e  limita√ß√µes  de  cada  abordagem  na  an√°lise  e  proje√ß√£o  de informa√ß√µes.

## 2.1 S√âRIES TEMPORAIS

A an√°lise de s√©ries temporais √© uma importante √°rea da estat√≠stica, dedicada √† compreens√£o, modelagem e previs√£o de fen√¥menos que s√£o observados de forma sequencial  no  tempo.  Conforme  Bezerra  (2006),  a  utiliza√ß√£o  da  an√°lise  de  s√©ries temporais √© amplamente difundida em diversas √°reas, como economia, meteorologia, sa√∫de, controle de processos industriais, vendas e finan√ßas, devido √† capacidade de identificar padr√µes de comportamento e realizar previs√µes futuras com base em dados hist√≥ricos.

## 2.1.1 Conceitos fundamentais e defini√ß√µes

De acordo com Parzen (1961), uma s√©rie temporal pode ser entendida como um  conjunto  de  observa√ß√µes  dispostas  cronologicamente,  sendo  representada matematicamente  como  um  processo  estoc√°stico,  no  qual  cada  valor  observado corresponde a um instante espec√≠fico no tempo.

## 2.1.2 Caracter√≠sticas principais

Entre os principais conceitos e caracter√≠sticas envolvidos na an√°lise de s√©ries temporais, destacam-se:

- a)  Estacionariedade:  Segundo  Bezerra  (2006),  a  estacionariedade  ocorre quando as propriedades estat√≠sticas, tais como  m√©dia, vari√¢ncia e covari√¢ncia,  permanecem  constantes  ao  longo  do  tempo.  A  condi√ß√£o  de

estacionariedade √© importante para aplica√ß√£o correta de diversos modelos, como os modelos ARIMA.

- b)  Tend√™ncia: Refere-se √† dire√ß√£o predominante da s√©rie ao longo do tempo, podendo  ser  crescente,  decrescente  ou  est√°vel.  Segundo  Makridakis, Wheelwright e Hyndman (1999), a tend√™ncia √© fundamental para entender o comportamento das s√©ries e escolher modelos adequados.
- c)  Sazonalidade: Corresponde  √†s  varia√ß√µes  peri√≥dicas  e  regulares  que ocorrem  em  intervalos  fixos,  como  mensal  ou  anual,  devido  a  fatores externos ou eventos recorrentes (MAKRIDAKIS, WHEELWRIGHT; HYNDMAN, 1999).
- d)  Autocorrela√ß√£o:  Representa  a  correla√ß√£o  da  s√©rie  consigo  mesma  em diferentes momentos do tempo (lags). De acordo com Parzen (1961), esse conceito √© fundamental para identificar e compreender o comportamento das s√©ries temporais.
- e) Ru√≠do  branco:  Para  Bezerra  (2006),  √©  a  parcela  aleat√≥ria  da  s√©rie temporal, composta por erros aleat√≥rios independentes com m√©dia zero e vari√¢ncia constante, que n√£o apresentam qualquer tipo de padr√£o previs√≠vel.

## 2.1.3 Classifica√ß√µes de s√©ries temporais

Makridakis, Wheelwright e Hyndman (1999) classificam as s√©ries temporais em tipos distintos:

- a)  S√©ries  estacion√°rias:  Caracterizam-se  por  apresentar  m√©dia  e  vari√¢ncia constantes ao longo do tempo. S√£o frequentemente observadas em s√©ries financeiras de retorno.
- b)  S√©ries n√£o estacion√°rias: S√£o s√©ries cujas propriedades estat√≠sticas, como m√©dia e/ou vari√¢ncia, alteram-se com o tempo. Exemplos comuns incluem s√©ries econ√¥micas como PIB e infla√ß√£o.
- c)  S√©ries lineares e n√£o lineares: S√©ries lineares podem ser modeladas por t√©cnicas tradicionais,  como  ARIMA,  enquanto  s√©ries n√£o  lineares  exigem modelos mais avan√ßados, como redes neurais artificiais (SHIRI et al., 2024).

## 2.1.4 Exemplos de aplica√ß√£o

V√°rios  estudos  demonstram  a  aplica√ß√£o  pr√°tica  das  s√©ries  temporais  em diversos contextos:

- a)  Previs√£o  de  vendas  no  varejo:  Ensafi  et  al.  (2022)  compararam  t√©cnicas tradicionais  como  SARIMA  e  Suaviza√ß√£o  Exponencial  com  m√©todos avan√ßados  como  redes  neurais  LSTM  e  CNN  para  previs√£o  das  vendas sazonais de m√≥veis. Os resultados mostraram que as redes neurais LSTM apresentaram maior precis√£o na captura de padr√µes complexos e sazonais.
- b)  Previs√£o  de  vendas  semanais em lojas de departamento: Pao e Sullivan (2014) utilizaram t√©cnicas como √°rvores de decis√£o, STL+ARIMA e redes neurais feed-forward com entradas temporais defasadas, concluindo que as redes neurais tiveram um desempenho superior, capturando com efici√™ncia as sazonalidades das vendas semanais.
- c)  Aplica√ß√£o  de  Deep  Learning  em  s√©ries  temporais  complexas:  Shiri  et  al. (2024) realizaram uma revis√£o abrangente sobre o uso de modelos de deep learning, como CNN, RNN, LSTM e Transformer, em s√©ries temporais. O estudo apontou que t√©cnicas modernas baseadas em deep learning t√™m se mostrado  superiores  √†s  t√©cnicas  tradicionais,  principalmente  em  s√©ries complexas e com grandes volumes de dados.

## 2.2 M√âTODO THETA

O m√©todo Theta ganhou popularidade ao vencer a competi√ß√£o M3 de previs√µes de s√©ries temporais devido √† sua simplicidade e efici√™ncia em gerar previs√µes precisas para  diversos  tipos  de  dados.  Desde  ent√£o,  este  m√©todo  tem  sido  amplamente estudado  e  aprimorado,  resultando  em  diferentes  variantes  que  exploram  seu potencial  para  aplica√ß√µes  autom√°ticas  e  mais  robustas.  (ASSIMAKOPOULOS; NIKILOPOULOS, 2000).

## 2.2.1 Descri√ß√£o geral e origem

O m√©todo Theta √© uma t√©cnica de previs√£o uni variada que decomp√µe a s√©rie temporal original em componentes denominados "linhas Theta". Cada linha Theta √© obtida  ajustandose  a  curvatura  dos  dados  originais  atrav√©s  de  um  par√¢metro  Œ∏ aplicado √†s segundas diferen√ßas da s√©rie original. (ASSIMAKOPOULOS; NIKILOPOULOS,  2000;  SPILIOTIS;  ASSIMAKOPOULOS;  MAKRIDAKIS,  2020).  A combina√ß√£o dessas linhas Theta gera previs√µes que equilibram tend√™ncias de curto e longo prazo. (ASSIMAKOPOULOS; NIKILOPOULOS, 2000).

## 2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros

As principais caracter√≠sticas do m√©todo Theta incluem:

- a)  Decomposi√ß√£o da s√©rie temporal: a s√©rie original √©  dividida em m√∫ltiplas linhas  Theta,  destacando  diferentes  caracter√≠sticas  como  tend√™ncias  de curto e longo prazo (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000).
- b) Par√¢metro Œ∏ (Theta): controla a curvatura das linhas, com ùúÉ &lt; 1 enfatizando tend√™ncias de longo prazo e ùúÉ &gt; 1 destacando varia√ß√µes de curto prazo. (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000; SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).
- c)  Combina√ß√£o de previs√µes: as previs√µes geradas a partir das linhas Theta s√£o  combinadas  usando  pondera√ß√µes  espec√≠ficas  para  gerar  resultados mais robustos e precisos (FIORUCCI et al., 2016).
- d)  Flexibilidade  e  robustez:  permite  ajuste  e  adapta√ß√£o  autom√°tica  dos par√¢metros  para  diferentes  s√©ries  temporais,  tornando-o  vers√°til  para diversos contextos (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).
- e)  Efici√™ncia  computacional:  destaca-se  pela  simplicidade  computacional, sendo f√°cil e r√°pido de implementar, especialmente quando comparado com m√©todos mais complexos como ARIMA ou redes neurais (FIORUCCI et al., 2016).
- f)  Capacidade  de  generaliza√ß√£o:  √©  aplic√°vel  em  s√©ries  temporais  com diferentes  padr√µes,  como  tend√™ncias  lineares,  n√£o  lineares,  s√©ries  com

comportamento sazonal e s√©ries irregulares (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

- g)  Simplicidade na interpreta√ß√£o: oferece resultados facilmente interpret√°veis, facilitando seu uso pr√°tico em  ambientes corporativos e industriais (FIORUCCI et al., 2016).

## 2.2.3 Equa√ß√£o da linha Theta

Segundo Spiliotis, Assimakopoulos e Makridakis (2020), o m√©todo Theta pode ser matematicamente descrito da seguinte forma:

Seja ùëå ùë° uma s√©rie temporal observada no tempo ùë° .  Uma linha Theta ùëçùë° (ùúÉ) √© obtida pela express√£o:

‚àá 2 ùëçùë° (ùúÉ) = ùúÉ‚àá 2 ùëå ùë° = ùúÉ(ùëå ùë° -2ùëå(ùë°-1) + ùëå (ùë°+2)), ùë° = 3, ‚Ä¶ , ùëõ onde ‚àá 2 ùëå ùë° √© o operador das segundas diferen√ßas da s√©rie original ùëå no ponto ùë° .

## 2.2.4 Express√µes aditivas e multiplicativas

No m√©todo Theta, as previs√µes podem ser realizadas utilizando express√µes aditivas ou multiplicativas:

- a)  Modelo aditivo: √© o modelo original do m√©todo Theta, no qual as previs√µes s√£o  obtidas  pela  combina√ß√£o  linear  aditiva  das  linhas  Theta  ajustadas (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000).
- b)  Modelo  multiplicativo:  √©  uma  extens√£o  recente  do  m√©todo,  permitindo modelar situa√ß√µes em que componentes como sazonalidade e tend√™ncia interagem de forma multiplicativa, sendo especialmente √∫til em s√©ries com tend√™ncia exponencial ou comportamento sazonal multiplicativo (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

## 2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros

Para  prever  dados  futuros,  o  m√©todo  Theta  realiza  as  seguintes  etapas (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000; FIORUCCI, 2016):

- a)  Decomposi√ß√£o:  a  s√©rie  temporal  √©  decomposta  em  linhas  Theta  com diferentes curvaturas.
- b)  Extrapola√ß√£o:  cada  linha  √©  extrapolada  individualmente,  frequentemente usando m√©todos simples, como suaviza√ß√£o exponencial simples (SES) para tend√™ncias  de  curto  prazo  e  regress√£o  linear  para  tend√™ncias  de  longo prazo.
- c)  Combina√ß√£o das linhas: as previs√µes individuais s√£o combinadas, geralmente com pesos iguais ou otimizados, produzindo uma previs√£o final robusta.

## 2.2.6 Exemplos pr√°ticos de uso

- O m√©todo Theta tem sido amplamente aplicado em diversas √°reas, demonstrando sua robustez:
- a)  Competi√ß√£o M3: a vers√£o cl√°ssica do m√©todo Theta alcan√ßou resultados superiores √†s demais t√©cnicas na competi√ß√£o M3, uma famosa competi√ß√£o internacional focada em  m√©todos  de  previs√£o de s√©ries temporais, especialmente em s√©ries mensais e microecon√¥micas, destacando-se por sua precis√£o e simplicidade (MAKRIDAKIS; HIBON, 2000).
- b)  Diagn√≥stico automotivo: Lozia (2022) utilizou o m√©todo Theta na avalia√ß√£o diagn√≥stica  de  amortecedores  automotivos,  demonstrando  a  efic√°cia  do m√©todo  em  modelar  e  prever  o  comportamento  din√¢mico  de  sistemas mec√¢nicos complexos.
- c)  Previs√£o autom√°tica: Spiliotis, Assimakopoulos e Makridakis (2020) propuseram  generaliza√ß√µes  do  m√©todo  Theta  capazes  de  selecionar automaticamente a forma mais apropriada (aditiva ou multiplicativa) e ajustar a inclina√ß√£o das tend√™ncias, superando outros algoritmos autom√°ticos em competi√ß√µes recentes (como M4), especialmente em s√©ries anuais.

## 2.3 MODELO ARIMA

O modelo ARIMA √© uma t√©cnica estat√≠stica amplamente utilizada para an√°lise e previs√£o de s√©ries temporais, desenvolvido por Box  e  Jenkins (1970). √â especialmente indicado para s√©ries cujos valores passados e erros hist√≥ricos podem ser utilizados para prever valores futuros (NEWBOLD, 1983).

## 2.3.1 Defini√ß√£o e estrutura do modelo ARIMA

O  modelo  ARIMA  √©  uma  combina√ß√£o  dos  modelos  autorregressivos  (AR), integrados (I) e de m√©dias m√≥veis (MA), definidos pela seguinte nota√ß√£o geral ARIMA (p, d, q), onde (NEWBOLD, 1983):

- a)  p: ordem do termo autorregressivo (AR), representa a rela√ß√£o linear entre a observa√ß√£o atual e as anteriores.
- b)  d: n√∫mero de diferencia√ß√µes necess√°rias para tornar a s√©rie estacion√°ria.
- c)  q: ordem dos termos de m√©dia m√≥vel (MA), que refletem os erros anteriores do modelo.

Matematicamente, o modelo ARIMA (p, d, q) pode ser expresso da seguinte forma (NEWBOLD, 1983):

<!-- formula-not-decoded -->

Onde:

- ùëå ùë° : valor atual da s√©rie temporal.
- ùëå ùë°-1 , ùëå ùë°-2 ,..., ùëå ùë°-ùëù : valores anteriores da s√©rie temporal (termos AR).
- ùúÄùë° :  erro  aleat√≥rio  (res√≠duos)  com distribui√ß√£o normal, m√©dia zero e vari√¢ncia constante (ru√≠do branco).
- ùúÄùë°-1 , ùúÄùë°-2 , ..., ùúÄùë°-ùëû : erros anteriores da s√©rie (termos MA).
- ùõø : constante.
- ùúô1 , ùúô2, ‚Ä¶ , ùúôùëù : coeficientes do termo autorregressivo.
- ùúÉ1 , ùúÉ2, ‚Ä¶ , ùúÉ ùëû : coeficientes do termo de m√©dia m√≥vel.

## 2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA

As principais caracter√≠sticas do modelo ARIMA incluem (BOX; JENKINS, 1970; FATTAH et al., 2018):

- a)  Flexibilidade:  Pode  ajustar-se  a  diversas  s√©ries  temporais,  incorporando tend√™ncia, ciclos e sazonalidade.
- b)  Necessidade de estacionariedade: S√©ries temporais precisam ser estacion√°rias  para  utiliza√ß√£o  correta  do  modelo.  A  estacionariedade  √© geralmente obtida por diferencia√ß√£o sucessiva das s√©ries temporais.
- c)  Simplicidade: F√°cil de compreender e implementar, apresentando resultados robustos em previs√µes de curto prazo.

Para verificar se uma s√©rie √© estacion√°ria, frequentemente s√£o utilizados testes estat√≠sticos como o teste Dickey-Fuller (ADF) e o teste KPSS (MURAT et al., 2018).

## 2.3.3 Como o modelo ARIMA funciona para prever dados futuros?

O  processo  de  constru√ß√£o  do  modelo  ARIMA  segue  a  metodologia  BoxJenkins,  que  possui  as  seguintes  etapas  (BOX;  JENKINS,  1970;  MONDAL  et  al., 2014):

- a)  Identifica√ß√£o do modelo: Determina√ß√£o das ordens p, d e q, com base na an√°lise  gr√°fica  das  fun√ß√µes  de  autocorrela√ß√£o  (ACF)  e  autocorrela√ß√£o parcial (PACF).
- b)  Estima√ß√£o  dos  par√¢metros:  Os  coeficientes  do  modelo  s√£o  estimados, normalmente utilizando o m√©todo da m√°xima verossimilhan√ßa.
- c)  Diagn√≥stico do modelo: Verifica√ß√£o da adequa√ß√£o do modelo por meio da an√°lise dos res√≠duos (erros), usando testes como o teste de Ljung-Box e crit√©rios estat√≠sticos como AIC (Crit√©rio de Informa√ß√£o de Akaike).
- d)  Previs√£o:  Realiza√ß√£o  da  previs√£o  de  valores  futuros  utilizando  o  modelo ajustado.

## 2.3.4 Casos pr√°ticos e exemplos na literatura

- O  modelo  ARIMA  tem  diversas  aplica√ß√µes  pr√°ticas,  como  evidenciado  em diferentes estudos acad√™micos:
- a)  Previs√£o  de  demanda  em  ind√∫strias  aliment√≠cias:  Fattah  et  al.  (2018) mostraram que o modelo ARIMA (1,0,1) foi eficaz em prever a demanda futura, ajudando a empresa na gest√£o eficiente de estoques e redu√ß√£o de custos.
- b)  Previs√£o  de  vendas  no  e-commerce:  Um  modelo  h√≠brido  combinando ARIMA  com  redes  neurais  LSTM  foi  utilizado  para  previs√£o  precisa  em ambientes com alta volatilidade, como o com√©rcio eletr√¥nico (VAVLIAKIS et al., 2021).
- c)  Previs√£o no mercado farmac√™utico: Fourkiotis e Tsadiras (2024) utilizaram ARIMA  em  combina√ß√£o  com  t√©cnicas  de  aprendizado  de  m√°quina  para prever a demanda por produtos farmac√™uticos, mostrando sua efic√°cia em capturar efeitos sazonais. Para enfrentar esse desafio, Fourkiotis e Tsadiras (2024) utilizaram t√©cnicas de an√°lise uni variada de s√©ries temporais para desenvolver previs√µes mais precisas. Os autores analisaram uma base de dados real contendo 600.000 registros hist√≥ricos de vendas provenientes de uma  farm√°cia  online,  abrangendo  um  per√≠odo  entre  2014  e  2019.  A metodologia proposta envolveu as etapas de pr√©-processamento e limpeza de dados, segmenta√ß√£o dos dados, an√°lise explorat√≥ria e identifica√ß√£o dos padr√µes  temporais,  aplica√ß√£o  e  compara√ß√£o  do  modelo  ARIMA  com modelos avan√ßados de ML como LSTM e XGBoost e, por fim, avalia√ß√£o do modelo  com  m√©tricas  espec√≠ficas.  Os  resultados  demonstraram  que  o modelo  ARIMA  apresentou  uma  boa  capacidade  preditiva  ao  capturar adequadamente a sazonalidade e tend√™ncias lineares de vendas. Contudo, os  autores  destacaram  que modelos de ML avan√ßados, especialmente o XGBoost, tiveram um desempenho ainda superior. Em particular, o XGBoost obteve as menores taxas de erro absoluto percentual m√©dio (MAPE). Apesar da  boa  performance  dos  modelos  avan√ßados  de  Machine  Learning,  o modelo  ARIMA  ainda  obteve  desempenho  competitivo  e  foi  considerado

eficaz especialmente em s√©ries temporais com forte componente linear e sazonalidade bem definida.

- d)  Previs√£o de pre√ßos no mercado financeiro: Mondal et al. (2014) utilizaram ARIMA  para  prever  pre√ßos  de  a√ß√µes,  destacando  sua  simplicidade  e robustez na previs√£o de tend√™ncias.

## 2.4 SUAVIZA√á√ÉO EXPONENCIAL

O m√©todo de suaviza√ß√£o exponencial tem recebido grande aten√ß√£o no contexto de  previs√µes  estat√≠sticas  devido  √†  sua  efic√°cia,  simplicidade  e  adaptabilidade  na previs√£o de s√©ries temporais. Sua popularidade adv√©m da capacidade intr√≠nseca de atribuir pesos maiores √†s observa√ß√µes mais recentes em detrimento das observa√ß√µes mais antigas, permitindo r√°pidas adapta√ß√µes √†s mudan√ßas na din√¢mica dos dados (GARDNER, 1985; CIPRA, 1992).

Essa t√©cnica tornou-se uma abordagem padr√£o em diversos campos pr√°ticos, incluindo gest√£o de estoques, controle de processos industriais, finan√ßas e gest√£o de cadeias de suprimentos. Sua ampla ado√ß√£o se d√° pela facilidade computacional e pela interpreta√ß√£o de suas previs√µes em compara√ß√£o com m√©todos mais complexos como modelos ARIMA e redes neurais (MCKENZIE, 1984).

## 2.4.1 Defini√ß√£o e estrutura do m√©todo

O m√©todo de exponential smoothing √© uma t√©cnica recursiva para previs√£o de s√©ries  temporais  que  se  baseia  na  pondera√ß√£o  exponencial  decrescente  das observa√ß√µes passadas. Formalmente, uma previs√£o futura √© constru√≠da como uma combina√ß√£o linear entre a observa√ß√£o mais recente e a previs√£o feita anteriormente. Essa  caracter√≠stica de  atualiza√ß√£o recursiva  confere simplicidade  e efici√™ncia computacional ao m√©todo (BROWN, 1962; MCKENZIE, 1984).

Matematicamente, para o SES, a previs√£o do valor da s√©rie temporal ùëãùë°+1 pode ser expressa por:

<!-- formula-not-decoded -->

Onde:

- ùëã ÃÇ ùë°+1 : valor previsto para o pr√≥ximo per√≠odo;

- ùëãùë° : valor observado no per√≠odo atual;
- ùëã ÃÇ ùë° : previs√£o feita anteriormente para o per√≠odo atual;
- ùõº :  constante  de  suaviza√ß√£o 0 &lt; ùõº &lt; 1 ,  que  define  o  grau  de  pondera√ß√£o aplicado ao dado mais recente (BROWN, 1962).

J√°  m√©todos  mais  avan√ßados,  como  o  m√©todo  de  Holt-Winters,  consideram explicitamente os componentes de n√≠vel, tend√™ncia e sazonalidade da s√©rie temporal. Segundo Gardner (1985), para s√©ries com comportamento sazonal e tend√™ncia linear, a previs√£o futura para ‚Ñé passos √† frente √© dada pela express√£o geral do m√©todo de Holt-Winters multiplicativo:

<!-- formula-not-decoded -->

Onde:

- ùêøùë° √© o n√≠vel estimado da s√©rie no tempo ùë° ;
- ùëèùë° √© a tend√™ncia estimada no tempo ùë° ;
- ùëÜùë°+‚Ñé-ùëö(ùëò+1) √© o fator sazonal estimado no tempo correspondente;
- ‚Ñé representa o horizonte futuro da previs√£o (quantidade de per√≠odos √† frente);
- ùëö √©  o  per√≠odo  sazonal  da  s√©rie  (por  exemplo, ùëö = 12 para  s√©ries  mensais anuais);
- ùëò √© o n√∫mero de ciclos completos transcorridos.

Esses  m√©todos  avan√ßados  permitem  previs√µes  mais  precisas  em  s√©ries complexas, com tend√™ncias claras ou padr√µes sazonais fortes, superando m√©todos mais  simples  como  m√©dias  m√≥veis  ou  o  pr√≥prio  exponential  smoothing  simples (MCKENZIE, 1984; GARDNER, 1985).

## 2.4.2 Vantagens e limita√ß√µes na previs√£o de dados

Entre  as  caracter√≠sticas  fundamentais  do  m√©todo  de  exponential  smoothing destacam-se:

- a)  Adaptabilidade: capacidade de responder rapidamente √†s altera√ß√µes estruturais  na  s√©rie  temporal,  atribuindo  pesos  exponenciais  aos  dados recentes (GARDNER, 1985).

- b)  Simplicidade  computacional:  a  estrutura  recursiva  dos  c√°lculos  torna  o m√©todo atrativo em aplica√ß√µes pr√°ticas, especialmente onde √© necess√°ria atualiza√ß√£o constante das previs√µes (BROWN, 1962).
- c)  Flexibilidade  estrutural:  diferentes  vers√µes,  como  simples,  dupla  e  tripla (Holt-Winters),  permitem  modelar  comportamentos  como  tend√™ncia  e sazonalidade com efici√™ncia (MCKENZIE, 1984).
- d)  Robustez:  vers√µes  robustas  do  m√©todo,  que  usam  a  minimiza√ß√£o  dos desvios  absolutos  ou  m√©todos  M-estimadores  ao  inv√©s  de  m√≠nimos quadrados, t√™m maior resist√™ncia a dados at√≠picos e s√©ries temporais com distribui√ß√µes assim√©tricas ou de caudas pesadas (CIPRA, 1992).

## 2.4.3 Aplica√ß√µes e estudos de caso

- a)  Impacto  da  suaviza√ß√£o  exponencial  no  Efeito  Bullwhip:  Chen,  Ryan  e Simchi-Levi (2000) investigaram como a utiliza√ß√£o do exponential smoothing na previs√£o de demanda pode intensificar o efeito bullwhip, fen√¥meno no qual pequenas varia√ß√µes na demanda s√£o ampliadas ao longo da cadeia de suprimentos. Eles demonstraram que, ao utilizar previs√µes com exponential smoothing,  as  varia√ß√µes  nas  demandas  observadas  pelos  fabricantes  se tornam significativamente maiores do que as percebidas pelos varejistas, aumentando os desafios de gest√£o e planejamento log√≠stico nas organiza√ß√µes.
- b)  Robustez a outliers em s√©ries temporais: Cipra (1992) avaliou o desempenho de vers√µes robustas do m√©todo de exponential smoothing em s√©ries temporais contaminadas por outliers e distribui√ß√µes de caudas longas. Utilizando  minimiza√ß√£o  dos  desvios  absolutos  (norma ùêø1 )  em  vez  dos m√≠nimos quadrados, Cipra verificou experimentalmente que essas vers√µes robustas forneceram previs√µes significativamente mais est√°veis e precisas na presen√ßa de valores extremos, superando m√©todos tradicionais especialmente em s√©ries financeiras e industriais onde valores at√≠picos s√£o comuns.
- c)  Aplica√ß√µes em controle de estoques: Gardner (1985) destacou o uso bemsucedido de exponential smoothing no controle e previs√£o para gest√£o de estoques. Nesse contexto, foram aplicadas varia√ß√µes do m√©todo para prever

demandas futuras e determinar n√≠veis √≥timos de estoque, reduzindo custos relacionados  √†  manuten√ß√£o  excessiva  ou  insuficiente  de  produtos  em invent√°rio.  Esse  exemplo  demonstra  claramente  como  o  exponential smoothing  pode  auxiliar  gestores  a  otimizarem  recursos  financeiros  e log√≠sticos nas organiza√ß√µes.

- d)  Previs√µes  de  demanda  em  s√©ries  sazonais  e  com  tend√™ncia:  McKenzie (1984) apresentou exemplos pr√°ticos demonstrando a efic√°cia do exponential  smoothing  para  s√©ries  temporais  com  forte  comportamento sazonal e tend√™ncia definida. Em seu estudo, foi utilizado o m√©todo HoltWinters para capturar esses componentes, proporcionando previs√µes mais precisas que outros m√©todos tradicionais como m√©dias m√≥veis simples e modelos  ARIMA  em  s√©ries  complexas,  especialmente  no  contexto  de demanda sazonal de varejo e setores produtivos.

## 2.5 XGBOOST

O XGBoost tornou-se um dos m√©todos mais populares e eficazes no √¢mbito da previs√£o  e  classifica√ß√£o  em  machine  learning,  devido  √†  sua  capacidade  de  lidar eficientemente  com  grandes  quantidades  de  dados  e  produzir  modelos  altamente precisos. Originalmente proposto por Chen e Guestrin em 2016, o XGBoost combina otimiza√ß√µes  algor√≠tmicas  e  t√©cnicas  avan√ßadas  de  engenharia  de  sistemas  para aprimorar significativamente o desempenho de previs√µes e classifica√ß√µes em diversas √°reas (CHEN; GUESTRIN, 2016).

## 2.5.1 Vis√£o geral do Extreme Gradient Boosting

O XGBoost √© uma implementa√ß√£o otimizada do algoritmo Gradient Boosting, baseado  em  √°rvores  de  decis√£o  sequenciais.  Diferentemente  das  abordagens tradicionais, que utilizam √°rvores independentes (como o Random Forest), o XGBoost constr√≥i √°rvores de maneira iterativa, com cada √°rvore subsequente aprendendo dos res√≠duos e erros das anteriores. A combina√ß√£o final das √°rvores resulta em um modelo robusto  e  altamente  eficiente  para  prever  valores  futuros  e  classificar  dados complexos (MALIK; HARODE; KUNWAR, 2020).

## 2.5.2 Caracter√≠sticas e conceitos do XGBoost

Entre as caracter√≠sticas fundamentais do XGBoost destacam-se:

- a)  Boosting: M√©todo de aprendizado de m√°quina que cria um modelo forte por meio da combina√ß√£o sequencial de modelos fracos. Cada novo modelo tenta corrigir  os  erros  dos  modelos  anteriores  (MALIK;  HARODE;  KUNWAR, 2020).
- b)  Regulariza√ß√£o: O XGBoost incorpora penalidades ao modelo para evitar o ajuste excessivo (overfitting), limitando a complexidade atrav√©s de par√¢metros  como  profundidade  m√°xima  das  √°rvores,  penaliza√ß√£o  por complexidade  (gamma)  e  regulariza√ß√£o  dos  pesos  das  folhas  (lambda). Essa abordagem resulta em modelos mais generaliz√°veis (CHEN; GUESTRIN, 2016).
- c)  Sparsity-aware  Split  Finding:  Um  algoritmo  que  otimiza  o  processo  de divis√£o das √°rvores levando  em conta a esparsidade dos dados, economizando  recursos  computacionais  ao  ignorar  valores  ausentes  ou zerados durante a constru√ß√£o das √°rvores (CHEN; GUESTRIN, 2016).
- d)  Paraleliza√ß√£o  e  computa√ß√£o  distribu√≠da:  O XGBoost √© projetado para ser executado em m√∫ltiplas  CPUs,  permitindo o  processamento  paralelo  dos dados e acelerando significativamente o treinamento de grandes modelos (CHEN; GUESTRIN, 2016).
- e)  Shrinking  e  Column  Subsampling:  T√©cnicas  adicionais  que  ajudam  a controlar a complexidade do modelo. Shrinking reduz o impacto individual de cada √°rvore, enquanto Column Subsampling seleciona aleatoriamente um subconjunto de atributos para cada √°rvore, aumentando a robustez e a velocidade do modelo (CHEN; GUESTRIN, 2016).

## 2.5.3 Como o XGBoost prev√™ dados futuros

- O  funcionamento  do  XGBoost  para  previs√µes  ocorre  de  maneira  iterativa, seguindo os passos:

- a)  Inicializa√ß√£o: O processo se inicia com a defini√ß√£o de uma previs√£o inicial, que geralmente corresponde √† m√©dia dos valores reais presentes nos dados de treinamento, no caso de problemas de regress√£o. Essa previs√£o inicial serve como ponto de partida para o modelo e representa a estimativa mais simples  poss√≠vel  sem  considerar  ainda  as  rela√ß√µes  complexas  entre  as vari√°veis (CHEN; GUESTRIN, 2016; NIELSEN, 2016).
- b)  C√°lculo  dos  res√≠duos:  Ap√≥s  a  obten√ß√£o  da  previs√£o  inicial,  calcula-se  a diferen√ßa entre os valores previstos e os valores reais, gerando assim os res√≠duos. Esses res√≠duos indicam o quanto o modelo atual est√° errando na previs√£o.  O  objetivo  do  XGBoost  √©  reduzir  esses  res√≠duos  a  cada  nova itera√ß√£o, corrigindo gradualmente as falhas do modelo anterior (NIELSEN, 2016; ZHANG et al., 2021).
- c)  Treinamento iterativo das √°rvores: Em cada itera√ß√£o, uma nova √°rvore de decis√£o √© treinada, n√£o para prever diretamente os valores finais, mas sim para modelar os res√≠duos obtidos na etapa anterior. Ou seja, cada √°rvore seguinte  busca  aprender  e  corrigir  os  erros  cometidos  pelo  conjunto  das √°rvores  anteriores,  ajustando-se  a  padr√µes  ainda  n√£o  capturados  (XIE; ZHANG, 2021; NIELSEN, 2016).
- d)  Atualiza√ß√£o  das  previs√µes:  As  previs√µes  do  modelo  s√£o  atualizadas somando as previs√µes das novas √°rvores treinadas √†s previs√µes acumuladas das √°rvores anteriores. Com  isso, o modelo torna-se progressivamente mais preciso a cada ciclo, pois incorpora sucessivamente corre√ß√µes  dos  erros  passados.  Ao  final  do  processo,  a  previs√£o  final  √© composta  pela  soma  ponderada  de  todas  as  √°rvores  criadas  durante  as itera√ß√µes, representando assim uma combina√ß√£o de m√∫ltiplos aprendizados parciais (CHEN; GUESTRIN, 2016; XIE; ZHANG, 2021).

A fun√ß√£o objetivo otimizada no processo √©:

<!-- formula-not-decoded -->

onde:

ùëô(ùë¶ ÃÇ ùë¶ , ùë¶ ùëñ ) representa a fun√ß√£o de perda (e.g., erro quadr√°tico m√©dio);

Œ©(ùëì ùëò ) representa o termo de regulariza√ß√£o que controla a complexidade do modelo (CHEN; GUESTRIN, 2016).

## 2.5.4 Exemplos pr√°ticos de uso do XGBoost

- a)  Utilidades: Segundo Noorunnahar et al. (apud Kontopoulou et al., 2023), no campo de utilidades, foi conduzido um estudo com o objetivo de prever a produ√ß√£o  anual  de  arroz  em  Bangladesh.  Os  autores  compararam  a precis√£o das previs√µes feitas por um m√©todo ARIMA otimizado, fundamentado no crit√©rio AIC, e pelo algoritmo XGBoost. Para a avalia√ß√£o dos modelos, foram consideradas m√©tricas de erro como MAE, MPE, RMSE e  MAPE.  Os  resultados  indicaram  que  o  modelo  XGBoost  obteve  um desempenho  superior  em  rela√ß√£o  ao  ARIMA  no  conjunto  de  teste, demonstrando  maior  efic√°cia  na  previs√£o  da  produ√ß√£o  de  arroz  para  o contexto analisado.
- b)  Previs√£o de volume de vendas no varejo: No setor de utilidades e com√©rcio, o XGBoost tem se mostrado eficaz na previs√£o de volumes de vendas. A pesquisa de Dairu e Shilong (2021) √© um exemplo, onde o modelo XGBoost foi utilizado para prever o volume de vendas no varejo, comparando seus resultados com o ARIMA cl√°ssico, o algoritmo GBDT, um modelo de LSTM e a ferramenta de previs√£o Prophet. Os resultados desse estudo indicaram que as abordagens baseadas em √°rvores, treinadas com caracter√≠sticas de clima e temperatura, ofereceram o melhor desempenho de previs√£o entre os cinco  modelos,  enquanto  o  ARIMA  apresentou  o  pior  desempenho. Notavelmente,  o  XGBoost  exigiu  significativamente  menos  itera√ß√µes  de treinamento  do  que  o  GBDT  e,  juntamente  com  o  GBDT,  necessitou  de menos dados e recursos em contraste com os modelos de  LSTM. Al√©m disso, os autores propuseram um modelo de previs√£o de vendas baseado em XGBoost para um conjunto de dados de bens de varejo do Walmart, demonstrando  bom  desempenho  com  menor  tempo  de  computa√ß√£o  e recursos de mem√≥ria.

## 3 METODOLOGIA

Este  cap√≠tulo  apresenta  os  procedimentos  metodol√≥gicos  adotados  para  a realiza√ß√£o  da  presente  pesquisa,  detalhando  de  forma  sistem√°tica  as  etapas  que orientaram  o  desenvolvimento  do  estudo.  S√£o  descritos  o  tipo  de  pesquisa,  a abordagem utilizada, os m√©todos de coleta e an√°lise dos dados, bem como os crit√©rios que fundamentaram as escolhas metodol√≥gicas. O objetivo √© conferir transpar√™ncia e fundamenta√ß√£o  cient√≠fica  ao  percurso  investigativo,  garantindo  a  validade  e  a confiabilidade dos resultados obtidos.

## 3.1 METODOLOGIA DE TRABALHO

Com  o  intuito  de  proporcionar  uma  vis√£o  geral  do  percurso  metodol√≥gico adotado, a figura a seguir apresenta, de forma esquem√°tica, as principais etapas e procedimentos desenvolvidos ao longo deste trabalho. O diagrama tem como objetivo ilustrar,  de  maneira clara e objetiva, a estrutura metodol√≥gica geral que orientou a condu√ß√£o da pesquisa.

Figura 1 - Metodologia geral do trabalho

<!-- image -->

Fonte: elaborado pelo autor

## 3.1.1 Defini√ß√£o do problema e objetivos da previs√£o

Este trabalho tem como ponto de partida uma necessidade pr√°tica observada em um dos  produtos  desenvolvidos  pela  empresa  onde  atuo,  voltado  √†  an√°lise  e visualiza√ß√£o  de  dados  corporativos.  Especificamente,  trata-se  de  um  dashboard constru√≠do na plataforma Power BI, que apresenta diversas an√°lises de desempenho, incluindo uma medida respons√°vel por estimar o faturamento do m√™s corrente com base nos dados registrados desde o primeiro dia do m√™s at√© o momento da consulta.

O problema que este trabalho prop√µe a investigar consiste em avaliar se √© poss√≠vel aprimorar essa estimativa por meio da aplica√ß√£o de modelos de aprendizado de m√°quina. Para isso, ser√£o desenvolvidos diferentes modelos preditivos utilizando os mesmos dados utilizados atualmente no dashboard, buscando simular o contexto real de previs√£o. Em seguida, ser√° avaliado o desempenho de cada modelo com base em  m√©tricas  estat√≠sticas,  e  comparado  o  resultado  mais  eficaz  com  a  previs√£o atualmente gerada pelo Power BI.

O objetivo principal deste estudo √© verificar se algum dos modelos testados apresenta desempenho superior ao c√°lculo de previs√£o utilizado hoje no produto da empresa. Caso isso ocorra, a ado√ß√£o do modelo poder√° resultar em previs√µes mais precisas e na gera√ß√£o de insights mais robustos e estrat√©gicos.

## 3.1.2 Coleta e integra√ß√£o dos dados

A  coleta  e  integra√ß√£o  dos  dados  utilizados  neste  trabalho  ser√£o  realizadas atrav√©s da ferramenta Visual Studio Code. Os dados empregados correspondem √†s s√©ries  hist√≥ricas  de  faturamento  dispon√≠veis  em  um  produto  interno  da  empresa, sendo originalmente utilizados em um dashboard desenvolvido em Power BI.

Inicialmente,  ser√°  realizada  a  ingest√£o  dos  dados  em  seu  formato  bruto, assegurando a preserva√ß√£o de todas as informa√ß√µes relevantes. Considerando os aspectos √©ticos e a necessidade de garantir a confidencialidade das informa√ß√µes, ser√° feita  a  anonimiza√ß√£o  dos  dados  diretamente  no  Visual  Studio  Code,  por  meio  de transforma√ß√µes  utilizando  a  linguagem  de  programa√ß√£o  Python.  Essa  etapa  ser√° essencial para remover ou ofuscar quaisquer identificadores sens√≠veis,  sem comprometer a estrutura ou a qualidade dos dados utilizados nas an√°lises.

Ap√≥s  a  anonimiza√ß√£o,  os  dados  ser√£o  estruturados  e  armazenados  na plataforma  para  dar  continuidade  √†s  etapas  de  pr√©-processamento,  modelagem  e valida√ß√£o, mantendo total alinhamento com a granularidade temporal e o contexto operacional do sistema de previs√£o atualmente existente.

## 3.1.3 Pr√©-processamento e transforma√ß√µes dos dados

Ap√≥s a coleta dos dados, ser√° iniciado o processo de pr√©-processamento com o objetivo de preparar as informa√ß√µes para a aplica√ß√£o dos modelos de previs√£o. Esta etapa  compreender√°  tanto  procedimentos  voltados  √†  integridade  e  √†  estrutura anal√≠tica dos dados quanto √† conformidade √©tica e √† prote√ß√£o da privacidade.

Como primeira medida, ser√° realizada a anonimiza√ß√£o dos dados diretamente na ferramenta Visual Studio Code, utilizando scripts desenvolvidos em Python. Essa anonimiza√ß√£o ter√° como finalidade remover ou substituir identificadores sens√≠veis por pseud√¥nimos ou c√≥digos aleat√≥rios, assegurando que nenhuma informa√ß√£o de car√°ter pessoal ou sigiloso pudesse ser associada a entidades reais. Essa pr√°tica est√° em conformidade com os princ√≠pios de seguran√ßa de dados e com a responsabilidade profissional no manuseio de informa√ß√µes empresariais.

Conclu√≠da a anonimiza√ß√£o, ser√£o conduzidas as etapas de transforma√ß√£o dos dados.  Os  registros  ser√£o  organizados  em  formato  de  s√©rie  temporal  uni  variada, respeitando a ordena√ß√£o cronol√≥gica e a granularidade mensal original dos dados de faturamento. Ser√° realizado o tratamento de valores ausentes por meio de t√©cnicas apropriadas, como interpola√ß√£o linear ou imputa√ß√£o por m√©dia m√≥vel, a depender da distribui√ß√£o local dos dados.

Outras etapas incluir√£o a padroniza√ß√£o dos tipos de dados, normaliza√ß√£o de nomes de colunas, e a identifica√ß√£o e tratamento de valores at√≠picos (outliers), que poderiam interferir na qualidade das previs√µes. Ao final desse processo, ser√° gerado um  conjunto  de  dados  estruturado  e  limpo,  que  servir√°  como  base  geral  para  a constru√ß√£o das vers√µes espec√≠ficas adaptadas a cada modelo preditivo.

## 3.1.4 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal

Com os dados devidamente pr√©-processados e estruturados, se iniciar√° a etapa de an√°lise explorat√≥ria, com o objetivo de compreender o comportamento hist√≥rico da

s√©rie  de  faturamento  e  identificar  padr√µes  relevantes  para  o  desenvolvimento  dos modelos preditivos.

Primeiramente,  ser√£o  constru√≠das  visualiza√ß√µes  gr√°ficas  da  s√©rie  temporal, como linhas de tend√™ncia, histogramas de distribui√ß√£o e gr√°ficos de decomposi√ß√£o, a fim  de  observar  aspectos  como  crescimento  ao  longo  do  tempo,  presen√ßa  de sazonalidade, varia√ß√µes abruptas e poss√≠veis rupturas na estrutura dos dados. Essa an√°lise  visual  √©  essencial  para  a  identifica√ß√£o  inicial  de  tend√™ncias  e  ciclos econ√¥micos caracter√≠sticos do contexto empresarial.

Em seguida, ser√£o aplicadas t√©cnicas estat√≠sticas para quantificar e validar os padr√µes observados. Ser√£o calculadas medidas descritivas como m√©dia, mediana, desvio-padr√£o e coeficiente de varia√ß√£o, al√©m da aplica√ß√£o de testes formais para verifica√ß√£o de estacionariedade, como os testes ADF e KPSS. Os resultados desses testes  permitir√£o  avaliar  a  necessidade  de diferencia√ß√£o  ou outras  transforma√ß√µes espec√≠ficas para tornar a s√©rie adequada aos requisitos dos modelos estat√≠sticos.

Al√©m  disso,  ser√£o  realizadas  an√°lises  de  autocorrela√ß√£o  e  autocorrela√ß√£o parcial (ACF e PACF), fundamentais para a parametriza√ß√£o de modelos como ARIMA, al√©m da identifica√ß√£o de lags relevantes.

Com base nos resultados desta an√°lise, a s√©rie temporal ser√° estruturada em diferentes formatos para atender √†s exig√™ncias de cada abordagem preditiva.

## 3.2 MODELOS DE PREVIS√ÉO UTILIZADOS

A modelagem preditiva √© a etapa central deste trabalho, sendo respons√°vel por transformar os dados estruturados em previs√µes quantitativas para o faturamento do produto  analisado.  Considerando  as  diferentes  abordagens  e  caracter√≠sticas  dos dados, ser√£o selecionados m√∫ltiplos modelos de previs√£o, cada um com suas pr√≥prias vantagens, desvantagens e requisitos espec√≠ficos de pr√©-processamento.

Os modelos escolhidos para este estudo incluem t√©cnicas tradicionais de s√©ries temporais, como ARIMA e Theta, bem como algoritmos mais recentes e avan√ßados, como  XGBoost,  que  s√£o  amplamente  utilizados  em  aplica√ß√µes  empresariais  para problemas de previs√£o com s√©ries temporais. Cada um desses modelos foi avaliado quanto √† sua capacidade de capturar padr√µes hist√≥ricos, prever tend√™ncias futuras e lidar  com os desafios t√≠picos desse tipo de dado, como sazonalidade, tend√™ncia e varia√ß√µes irregulares.

Para  garantir  uma  an√°lise  comparativa  robusta,  foram  considerados  fatores como a facilidade de implementa√ß√£o, complexidade computacional e a precis√£o das previs√µes geradas. Al√©m disso, cada modelo ser√° treinado e validado com os mesmos conjuntos de dados, permitindo uma compara√ß√£o justa e direta de seu desempenho.

Nos subt√≥picos a seguir, cada modelo √© apresentado individualmente, incluindo os requisitos espec√≠ficos para pr√©-processamento dos dados e o diagrama do fluxo metodol√≥gico correspondente.

## 3.2.1 ARIMA

A figura a seguir mostra a metodologia utilizada para o modelo.

Figura 2 - Metodologia do modelo ARIMA

<!-- image -->

Fonte: elaborado pelo autor

## 3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente

Para iniciar a modelagem com ARIMA, ser√£o usadas tr√™s bibliotecas Python, sendo elas a biblioteca Darts, que cont√©m as v√°rias fun√ß√µes j√° pr√©-programadas para processamento  de  s√©ries  temporais,  Pandas  para  manipula√ß√£o  de  dos  dados  e Matplotlib para a cria√ß√£o de gr√°ficos que auxiliar√£o na an√°lise explorat√≥ria e valida√ß√£o dos modelos.

Essa configura√ß√£o do ambiente √© uma etapa fundamental, pois garante que todas as opera√ß√µes subsequentes, como treinamento do modelo e c√°lculo de m√©tricas possam ser realizadas de forma eficiente e organizada.

## 3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal

Ap√≥s a configura√ß√£o do ambiente, o pr√≥ximo passo ser√° carregar os dados que ser√£o  utilizados  no  modelo.  Para  isso,  ser√°  necess√°rio  que  os  dados  estejam estruturados de forma adequada, com uma coluna de datas como √≠ndice. No Darts, os dados precisam ser convertidos para a estrutura TimeSeries, que √© otimizada para opera√ß√µes t√≠picas de s√©ries temporais, como diferencia√ß√£o, transforma√ß√£o e predi√ß√£o.

Essa convers√£o √© crucial, pois permite que o modelo ARIMA manipule os dados corretamente e aplique fun√ß√µes especializadas para s√©ries temporais, como detec√ß√£o de sazonalidade, an√°lise de tend√™ncia e valida√ß√£o cruzada.

## 3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o

A  estacionaridade  √©  uma  premissa  essencial  para  a  aplica√ß√£o  do  modelo ARIMA,  pois  pressup√µe  que  as  propriedades  estat√≠sticas  da  s√©rie,  como  m√©dia  e vari√¢ncia,  permane√ßam constantes ao longo do tempo. Para verificar se a s√©rie √© estacion√°ria, ser√£o aplicados os testes ADF e o KPSS, que avaliam a presen√ßa de tend√™ncias e sazonalidades.

Se os testes indicarem que a s√©rie n√£o √© estacion√°ria, ser√° necess√°rio aplicar uma transforma√ß√£o de diferencia√ß√£o para estabilizar a m√©dia e remover a tend√™ncia. Esse  processo  √©  importante  para  evitar  que  o  modelo  ajuste  padr√µes  esp√∫rios, garantindo previs√µes mais precisas e robustas.

## 3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste

Para  validar  adequadamente  o  modelo,  √©  fundamental  dividir  os  dados  em conjuntos de treino e teste. Essa divis√£o dever√° respeitar a ordem temporal dos dados, para  que  as  previs√µes  do  modelo  sejam  baseadas  em  informa√ß√µes  passadas, simulando um cen√°rio real de produ√ß√£o. Ser√° adotado inicialmente a pr√°tica comum de utilizar 80% dos dados para treino e 20% para teste, mas essa propor√ß√£o poder√° ser ajustada futuramente.

A separa√ß√£o dos dados desta forma permite avaliar a capacidade do modelo de generalizar para novos dados e evitar o risco de overfitting, onde o modelo se ajusta excessivamente ao conjunto de treino e perde desempenho em dados desconhecidos.

## 3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q

Os par√¢metros do modelo ARIMA, p, d e q, ser√£o definidos para que o modelo capture corretamente os padr√µes da s√©rie temporal. Esses par√¢metros representam:

- a)  p  (ordem autorregressiva): N√∫mero de lags utilizados para prever o valor atual com base em valores passados.
- b)  d  (ordem  de  diferencia√ß√£o):  N√∫mero  de  vezes  que  a  s√©rie  deve  ser diferenciada para remover tend√™ncias.
- c)  q (ordem do modelo de m√©dia m√≥vel): N√∫mero de termos de erro defasados usados para ajustar o modelo.

A escolha desses par√¢metros ser√° feita com base na an√°lise das fun√ß√µes de autocorrela√ß√£o  (ACF)  e  autocorrela√ß√£o  parcial  (PACF),  que  indicam  a  for√ßa  e  o alcance das correla√ß√µes temporais presentes nos dados. Esta √© uma etapa cr√≠tica, pois  define  a  complexidade  do  modelo  e  sua  capacidade  de  capturar  padr√µes temporais.

## 3.2.1.6 Treinamento do modelo

Com os par√¢metros definidos, o pr√≥ximo passo ser√° ajustar o modelo ARIMA aos  dados  de  treino.  Esse  ajuste  ser√°  feito  utilizando  o  m√©todo  de  m√°xima

verossimilhan√ßa, que busca encontrar os coeficientes do modelo que minimizam o erro de previs√£o no conjunto de treino.

Durante esta etapa, o modelo aprende os padr√µes hist√≥ricos da s√©rie, ajustando os termos autorregressivos, de diferencia√ß√£o e de m√©dia m√≥vel para fornecer a melhor representa√ß√£o poss√≠vel dos dados passados.

## 3.2.1.7 Valida√ß√£o do modelo e ajustes finos

Ap√≥s o treinamento inicial, ser√° necess√°rio validar o modelo no conjunto de teste para avaliar sua capacidade de generaliza√ß√£o. Esta etapa ser√° feita a partir do c√°lculo de m√©tricas como MAE e RMSE, que medem a precis√£o das previs√µes.

Al√©m disso, ser√° analisada a possibilidade de aplicar t√©cnicas de ajuste fino, como grid search, para refinar os par√¢metros p, d e q e otimizar o desempenho do modelo. Esse ajuste √© essencial para garantir que o modelo n√£o apenas ajuste bem os dados de treino, mas tamb√©m seja capaz de fazer previs√µes precisas em dados novos.

## 3.2.1.8 An√°lise residual

Uma an√°lise dos res√≠duos do modelo ser√° feita para verificar se os erros de previs√£o se distribuem de forma aleat√≥ria, sem padr√µes n√£o modelados. Res√≠duos com  padr√µes  indicam  que  o  modelo  n√£o  conseguiu  capturar  completamente  as rela√ß√µes temporais nos dados, sugerindo a necessidade de ajustes nos par√¢metros.

Al√©m disso, essa an√°lise tamb√©m tem o intuito de revelar a presen√ßa de outliers ou  eventos  at√≠picos  que  n√£o  foram  adequadamente  modelados,  o  que  pode comprometer a precis√£o das previs√µes futuras.

## 3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura

Finalmente,  os  resultados  do  modelo  ARIMA,  incluindo  as  previs√µes  e  os res√≠duos, ser√£o salvos para futura compara√ß√£o com os demais modelos e com as previs√µes atualmente geradas pelo Power BI. Essa etapa √© essencial para a an√°lise final do desempenho do modelo e para a escolha da abordagem preditiva mais precisa e robusta para o objetivo final.

## 3.2.2 XGBoost

A figura 3 mostra a metodologia utilizada para o modelo.

Figura 3 -Metodologia do modelo XGBoost

<!-- image -->

Fonte: elaborado pelo autor

## 3.2.2.1 Prepara√ß√£o e engenharia de vari√°veis

Diferentemente do ARIMA, cuja entrada √© a pr√≥pria s√©rie temporal univariada, o XGBoost exige que a s√©rie seja transformada em uma base tabular. Ser√£o criadas vari√°veis defasadas, m√©dias m√≥veis e estat√≠sticas que descrevam a s√©rie ao longo do tempo. Al√©m disso, poder√£o ser adicionadas  vari√°veis  de  calend√°rio  (m√™s,  dia  da semana, feriados  etc.),  enriquecendo  o  conjunto  de  treinamento  com  informa√ß√µes

contextuais.  Esta  etapa  √©  exclusiva  e  essencial  para  o  XGBoost,  pois  permite  ao modelo explorar depend√™ncias temporais e efeitos sazonais/ex√≥genos.

## 3.2.2.2 Divis√£o dos dados em treino e teste

Assim como no ARIMA, os dados ser√£o divididos em conjuntos de treino e teste, sempre respeitando a ordem cronol√≥gica para evitar vazamento de informa√ß√µes futuras.

## 3.2.2.3 Normaliza√ß√£o e tratamento dos dados

Esta etapa, embora similar √† limpeza realizada no ARIMA, ser√° orientada para o  contexto  tabular.  Ser√£o  tratados  valores  ausentes  gerados  na  cria√ß√£o  de  lags  e m√©dias  m√≥veis  por  meio  de  imputa√ß√£o  ou  exclus√£o.  Se  necess√°rio,  as  vari√°veis poder√£o  ser  normalizadas  ou  padronizadas  para  garantir  melhor  desempenho  do algoritmo.

## 3.2.2.4 Configura√ß√£o dos hiper par√¢metros iniciais

Diferentemente do ARIMA, em que os par√¢metros de configura√ß√£o s√£o (p, d, q) definidos com base em an√°lise de autocorrela√ß√£o da pr√≥pria s√©rie temporal, o modelo XGBoost depende de um conjunto mais amplo de hiper par√¢metros que controlam tanto a complexidade quanto o desempenho do algoritmo de √°rvores de decis√£o.

Entre os principais hiper par√¢metros que dever√£o ser configurados inicialmente, destacam-se:

- a)  n\_estimators (n√∫mero de √°rvores): Define quantas √°rvores de decis√£o ser√£o criadas e combinadas pelo modelo.
- b)  max\_depth  (profundidade  m√°xima):  Limita  a  quantidade  de  divis√µes  que cada  √°rvore  pode  fazer,  afetando  a  capacidade  de  capturar  padr√µes complexos sem sobre ajuste.
- c)  learning\_rate (taxa de aprendizado): Controla o peso de cada nova √°rvore adicionada no processo de boosting, influenciando diretamente a velocidade e a estabilidade do treinamento.

- d)  subsample (amostragem): Determina a fra√ß√£o de exemplos utilizados para treinar cada √°rvore, o que pode aumentar a generaliza√ß√£o do modelo.
- e)  colsample\_bytree: Define a propor√ß√£o de vari√°veis consideradas em cada divis√£o, reduzindo a chance de sobre ajuste.

A sele√ß√£o inicial desses hiper par√¢metros poder√£o ser realizadas com base em estudos  pr√©vios,  valores  sugeridos  na  literatura  ou  ainda  com  valores  padr√£o  do pr√≥prio XGBoost. √â importante salientar que, diferentemente do ARIMA, o XGBoost permite  grande  flexibilidade  na  escolha  e  combina√ß√£o  desses  hiper  par√¢metros, tornando o processo de ajuste potencialmente mais complexo e exigente em termos de experimenta√ß√£o.

## 3.2.2.5 Treinamento inicial do modelo

O processo de treinamento inicial do XGBoost se diferencia substancialmente do ARIMA,  principalmente pela estrutura dos dados e pelo  mecanismo  de aprendizado.

Enquanto  o  ARIMA  utiliza  uma  s√©rie  temporal  univariada  e  ajusta  seus par√¢metros para capturar padr√µes autorregressivos e de m√©dia m√≥vel, o XGBoost ir√° trabalhar sobre uma base tabular composta por m√∫ltiplas features, incluindo vari√°veis defasadas (lags), m√©dias m√≥veis, vari√°veis sazonais e de calend√°rio, entre outras. O modelo ser√° treinado utilizando o conjunto de treino previamente definido, buscando construir  sucessivas  √°rvores  de  decis√£o  (de  acordo  com  o  n√∫mero  definido  em n\_estimators ) que, em conjunto, minimizar√£o o erro de previs√£o.

Durante esse processo, cada nova √°rvore ser√° constru√≠da para corrigir os erros cometidos pelas √°rvores anteriores, em um procedimento iterativo chamado boosting. O ajuste do modelo ser√° realizado at√© que todos os dados de treino tenham sido utilizados para aprender os padr√µes relevantes da s√©rie temporal e de suas vari√°veis derivadas.

Ao  final  do  treinamento  inicial,  o  modelo  estar√°  preparado  para  realizar previs√µes sobre o conjunto de teste, e os resultados obtidos servir√£o como base para a avalia√ß√£o inicial de desempenho e para eventuais ajustes de hiper par√¢metros em etapas subsequentes.

## 3.2.2.6 Avalia√ß√£o inicial de desempenho

A  avalia√ß√£o  do  desempenho  inicial  ser√°  realizada  de  maneira  an√°loga  ao ARIMA, por meio de m√©tricas como RMSE, MAE ou MAPE, aplicadas ao conjunto de teste. A an√°lise dos erros tamb√©m poder√° indicar a necessidade de ajuste nas features ou nos hiper par√¢metros.

## 3.2.2.7 Busca e ajuste de hiper par√¢metros

Enquanto o ajuste de par√¢metros do ARIMA envolve os valores de p, d, q, no XGBoost ser√°  realizada  uma  busca  sistem√°tica  para  identificar  os  melhores  hiper par√¢metros do modelo, como taxa de aprendizado, n√∫mero de √°rvores e profundidade m√°xima.

## 3.2.2.8 Valida√ß√£o cruzada e an√°lise de resultados

Assim como no ARIMA, ser√° empregada valida√ß√£o cruzada adequada a s√©ries temporais, assegurando a robustez dos resultados e a aus√™ncia de sobre ajuste. Os resultados da valida√ß√£o ser√£o analisados quanto √† consist√™ncia e poss√≠veis padr√µes residuais.

## 3.2.2.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados

Por fim, as previs√µes finais geradas pelo modelo XGBoost ser√£o armazenadas para compara√ß√£o direta com os resultados do ARIMA, dos demais modelos avaliados e com as previs√µes atualmente geradas pelo Power BI.

## 3.2.3 Suaviza√ß√£o exponencial

A figura 4 mostra a metodologia utilizada para o modelo.

Figura 4 - Metodologia do modelo de Suaviza√ß√£o Exponencial

<!-- image -->

Fonte: elaborado pelo autor

## 3.2.3.1 Prepara√ß√£o dos dados

A prepara√ß√£o dos dados para o modelo de Suaviza√ß√£o Exponencial seguir√° o padr√£o estabelecido para os modelos estat√≠sticos (ARIMA e Theta), sendo utilizada a s√©rie  temporal  original  em  formato  univariado  e  na  granularidade  apropriada  ao problema. Ser√° garantida a ordena√ß√£o cronol√≥gica, bem como a anonimiza√ß√£o das informa√ß√µes conforme as diretrizes √©ticas. Dados ausentes ser√£o tratados previamente, por meio de interpola√ß√£o, imputa√ß√£o por m√©dia ou exclus√£o.

## 3.2.3.2 An√°lise explorat√≥ria e estrutura da s√©rie temporal

Ser√°  conduzida  uma  an√°lise  gr√°fica  e  estat√≠stica  para  identifica√ß√£o  de tend√™ncias, ciclos e poss√≠veis padr√µes sazonais. Essa etapa ser√° fundamental para determinar o tipo de suaviza√ß√£o exponencial a ser adotado (simples, com tend√™ncia ou com tend√™ncia e sazonalidade), e para subsidiar a configura√ß√£o dos par√¢metros do modelo.

## 3.2.3.3 Divis√£o em conjunto de treino e teste

A base de dados ser√° segmentada em conjuntos de treino e teste, preservando a sequ√™ncia temporal dos registros. A propor√ß√£o adotada poder√° variar conforme o tamanho da amostra, mas a divis√£o seguir√° a mesma l√≥gica dos modelos estat√≠sticos anteriores, visando simular o ambiente real de previs√£o.

## 3.2.3.4 Sele√ß√£o do tipo de suaviza√ß√£o exponencial e par√¢metros

A  sele√ß√£o  dos  par√¢metros  do  modelo  ser√°  realizada  com  base  na  an√°lise explorat√≥ria e nas op√ß√µes oferecidas pela implementa√ß√£o da biblioteca. Poder√£o ser especificados manualmente, ou deixados para ajuste autom√°tico, par√¢metros como:

- a)  Tipo de tend√™ncia: aditiva, multiplicativa ou ausente;
- b)  Tipo de sazonalidade: aditiva, multiplicativa ou ausente;
- c)  Periodicidade sazonal, de acordo com a frequ√™ncia da s√©rie (por exemplo, 12 para dados mensais com sazonalidade anual);
- d)  Uso ou n√£o de tend√™ncia amortecida.

Caso a estrutura da s√©rie n√£o seja evidente, a configura√ß√£o autom√°tica dos par√¢metros  ser√°  empregada,  permitindo  ao  algoritmo  determinar  os  componentes mais adequados.

## 3.2.3.5 Treinamento inicial do modelo

O treinamento ser√° realizado por meio do ajuste do modelo da biblioteca Darts ao  conjunto  de  treino,  utilizando  os  par√¢metros  selecionados  na  etapa  anterior.  O algoritmo ir√° otimizar os coeficientes de suaviza√ß√£o (como alfa, beta e gama) para minimizar  o  erro  de  previs√£o,  podendo  realizar  busca  autom√°tica  das  melhores configura√ß√µes.  Ressalta-se  que  a  s√©rie  de  entrada  dever√°  estar  livre  de  valores ausentes e ser estritamente univariada, conforme as exig√™ncias do modelo.

## 3.2.3.6 Gera√ß√£o das previs√µes

Ap√≥s o treinamento, ser√£o geradas as previs√µes para o horizonte de teste. As previs√µes ser√£o extra√≠das a partir do modelo ajustado, permitindo a compara√ß√£o direta com os valores reais observados.

## 3.2.3.7 Avalia√ß√£o do desempenho

O desempenho do modelo de Suaviza√ß√£o Exponencial ser√° aferido por meio de  m√©tricas  como  RMSE,  MAE  ou  MAPE,  as  mesmas  empregadas  nos  demais modelos.  Essa  abordagem  garantir√°  a  comparabilidade  entre  todos  os  m√©todos avaliados.

## 3.2.3.8 Ajuste fino e revalida√ß√£o

Se necess√°rio, ser√£o realizados ajustes nos par√¢metros do modelo, como a sele√ß√£o de periodicidade sazonal diferente ou a altera√ß√£o da estrutura de tend√™ncia.

Novos treinamentos e avalia√ß√µes ser√£o conduzidos at√© que se atinja um desempenho considerado robusto.

## 3.2.3.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados

Os  resultados,  incluindo  previs√µes,  res√≠duos  e  par√¢metros  utilizados,  ser√£o armazenados  de  maneira  estruturada.  Esses  resultados  ser√£o  ent√£o  comparados futuramente com os demais modelos implementados e com a previs√£o atualmente utilizada no Power BI, visando identificar a abordagem mais precisa e confi√°vel.

## 3.2.4 Theta

A figura 5 mostra a metodologia utilizada para o modelo.

Figura 5 - Metodologia do modelo Theta

<!-- image -->

Fonte: elaborado pelo autor

## 3.2.4.1 Organiza√ß√£o e pr√©-condi√ß√µes dos dados

Antes de qualquer processamento, a s√©rie temporal ser√° conferida quanto √† univarian√ßa e aus√™ncia de valores nulos, pois estas s√£o condi√ß√µes  indispens√°veis para a aplica√ß√£o do Theta na Darts. Caso sejam identificados dados ausentes, ser√£o realizados  procedimentos  de  interpola√ß√£o  ou  elimina√ß√£o  dos  registros  afetados.  A granularidade  e  ordena√ß√£o  cronol√≥gica  tamb√©m  ser√£o  revisadas,  assegurando  a integridade sequencial da s√©rie.

## 3.2.4.2 An√°lise inicial e sazonalidade

A an√°lise explorat√≥ria, com foco em tend√™ncias e padr√µes repetitivos, orientar√° a parametriza√ß√£o do modelo. Se a sazonalidade for uma caracter√≠stica relevante da s√©rie,  j√°  identificada  em  etapas  anteriores  ou  confirmada  aqui,  alguns  par√¢metros ser√£o definidos explicitamente, assim como o per√≠odo sazonal. Em casos de incerteza quanto  √†  presen√ßa  de  sazonalidade,  ser√°  mantida  a  configura√ß√£o  autom√°tica  do Theta.

## 3.2.4.3 Separa√ß√£o temporal para avalia√ß√£o

A divis√£o entre dados para treino e teste respeitar√° a l√≥gica j√° adotada ao longo do trabalho: os registros mais antigos compor√£o a base de aprendizagem do modelo, enquanto  o  trecho  final  da  s√©rie  ser√°  reservado  exclusivamente  para  avalia√ß√£o preditiva.  Essa  separa√ß√£o  garante  que  as  previs√µes  simulem  um  cen√°rio  real  de atualiza√ß√£o e monitoramento cont√≠nuo.

## 3.2.4.4 Configura√ß√£o e execu√ß√£o do algoritmo

A etapa de configura√ß√£o no Darts √© simplificada pelo car√°ter autom√°tico do modelo Theta,  dispensando  a necessidade de  ajustes manuais  extensos.  Quando apropriado, ser√£o explicitados par√¢metros, priorizando reprodutibilidade e alinhamento com os padr√µes identificados na an√°lise inicial. A execu√ß√£o do treinamento ser√° realizada diretamente pela biblioteca, com o Theta operando sobre o conjunto de treino e processando internamente a decomposi√ß√£o e recomposi√ß√£o da s√©rie segundo sua abordagem matem√°tica caracter√≠stica.

## 3.2.4.5 Produ√ß√£o das previs√µes e p√≥s-processamento

Com  o  modelo  ajustado,  ser√£o  produzidas  as  previs√µes  para  o  intervalo definido de teste. Os resultados, extra√≠dos diretamente do modelo, ser√£o posteriormente reintegrados ao fluxo de avalia√ß√£o conjunta com os demais algoritmos aplicados.

## 3.2.4.6 Avalia√ß√£o quantitativa e diagn√≥stico

O desempenho do Theta ser√° analisado utilizando m√©tricas padronizadas do projeto, permitindo n√£o apenas comparar acur√°cia, mas tamb√©m  avaliar o comportamento residual e identificar poss√≠veis limita√ß√µes do modelo frente a outliers ou mudan√ßas estruturais da s√©rie.

## 3.2.4.7 Itera√ß√£o e consolida√ß√£o dos resultados

Na  hip√≥tese  de  resultados  insatisfat√≥rios,  o  fluxo  prev√™  nova  an√°lise  dos par√¢metros  de  sazonalidade  e  repeti√ß√£o  do  ciclo  de  ajuste  e  teste.  As  melhores configura√ß√µes e resultados obtidos ser√£o devidamente documentados e os dados de previs√µes armazenados de forma compat√≠vel com os demais experimentos.

## 3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS

Ap√≥s o ajuste e valida√ß√£o de todos os modelos preditivos considerados neste trabalho,  ser√°  realizada  uma  compara√ß√£o  quantitativa  do  desempenho  de  cada modelo utilizando  as  seguintes  m√©tricas  estat√≠sticas,  recomendadas  pela  literatura para problemas de previs√£o de s√©ries temporais:

- a)  Erro M√©dio Absoluto (MAE);
- b)  Raiz do Erro Quadr√°tico M√©dio (RMSE);
- c)  Erro Percentual Absoluto M√©dio (MAPE).

Essas m√©tricas ser√£o calculadas para o conjunto de teste de cada modelo. O modelo que apresentar o menor valor de erro (considerando principalmente MAE e RMSE),  ser√°  selecionado  como  o  modelo  de  melhor  desempenho,  conforme abordagem utilizada por Hyndman et al. (1999) e Gardner (1985).

Na sequ√™ncia, o modelo de melhor desempenho ser√° comparado diretamente ao m√©todo de previs√£o atualmente empregado no Power BI. Essa compara√ß√£o ser√° realizada utilizando as mesmas m√©tricas, com o objetivo de identificar se a abordagem baseada  em  aprendizado  de  m√°quina  ou  m√©todos  estat√≠sticos  apresenta  ganhos significativos de acur√°cia em rela√ß√£o √† solu√ß√£o j√° adotada no produto da empresa.

A  escolha  final  do  modelo  ser√°  baseada  n√£o  apenas  no  desempenho quantitativo,  mas  tamb√©m  na  sua  viabilidade  de  implementa√ß√£o  e  integra√ß√£o  √† plataforma existente, conforme recomendam Gardner (1985) e Hyndman et al. (1999).

## 3.4 CRONOGRAMA

Quadro 1 - Cronograma de Desenvolvimento do Projeto

| Etapas do Projeto                              | Agosto   | Setembro   | Outubro   | Novembro   | Dezembro   |
|------------------------------------------------|----------|------------|-----------|------------|------------|
| Coleta e Anonimiza√ß√£o dos Dados                | X        |            |           |            |            |
| Pr√©-processamento e Estrutura√ß√£o dos Dados     | X        |            |           |            |            |
| An√°lise Explorat√≥ria e Visualiza√ß√µes           | X        |            |           |            |            |
| Implementa√ß√£o do Modelo ARIMA                  |          | X          |           |            |            |
| Implementa√ß√£o do Modelo Suaviza√ß√£o Exponencial |          |            | X         |            |            |
| Implementa√ß√£o do Modelo Theta                  |          |            | X         |            |            |
| Implementa√ß√£o do Modelo XGBoost                |          |            |           | X          |            |
| Valida√ß√£o, Ajuste Fino e Sele√ß√£o dos Modelos   |          |            |           | X          |            |
| Compara√ß√£o com Power BI                        |          |            |           | X          |            |
| Documenta√ß√£o dos Resultados                    |          |            |           | X          | X          |

Fonte: elaborado pelo autor

## REFER√äNCIAS

ASSIMAKOPOULOS, V.; NIKOLOPOULOS, K. The theta model: a decomposition approach to forecasting. International Journal of Forecasting , v. 16, n. 4, p. 521 -530, out. 2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00066-2.

BEZERRA, Manoel Ivanildo Silvestre. Apostila de An√°lise de S√©ries Temporais . S√£o Paulo: UNESP, 2006. Dispon√≠vel em:

https://www.ibilce.unesp.br/Home/Departamentos/MatematicaEstatistica/apostila\_ser ies\_temporais\_unesp.pdf.

BOX, G. E. P. et al. Time series analysis: forecasting and control . Hoboken, New Jersey: John Wiley &amp; Sons, 2015.

CHEN, T.; GUESTRIN, C. XGBoost: a Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD '16 , v. 1, n. 1, p. 785 -794, 13 ago. 2016. Dispon√≠vel em: https://doi.org/10.1145/2939672.2939785.

DAIRU, X.; SHILONG, Z. Machine Learning Model for Sales Forecasting by Using XGBoost . Dispon√≠vel em: https://doi.org/10.1109/ICCECE51280.2021.9342304.

ENSAFI, Y. et al. Time-series forecasting of seasonal items sales using machine learning -A comparative analysis. International Journal of Information Management Data Insights , v. 2, n. 1, p. 100058, abr. 2022. Dispon√≠vel em: https://doi.org/10.1016/j.jjimei.2022.100058.

FATTAH, J. et al. Forecasting of demand using ARIMA model. International Journal of Engineering Business Management , v. 10, n. 1, p. 184797901880867, jan. 2018. Dispon√≠vel em: https://journals.sagepub.com/doi/10.1177/1847979018808673.

FIORUCCI, J. A. et al. Models for optimising the theta method and their relationship to state space models. International Journal of Forecasting , v. 32, n. 4, p. 1151 -1161, out. 2016. Dispon√≠vel em: https://doi.org/10.1016/j.ijforecast.2016.02.005.

FOURKIOTIS, K. P.; TSADIRAS, A. Applying Machine Learning and Statistical Forecasting Methods for Enhancing Pharmaceutical Sales Predictions. Forecasting , v. 6, n. 1, p. 170 -186, 1 mar. 2024. Dispon√≠vel em:

https://doi.org/10.3390/forecast6010010.

GARDNER, E. S. Exponential smoothing: The state of the art. Journal of Forecasting , v. 4, n. 1, p. 1 -28, 1985. Dispon√≠vel em: https://doi.org/10.1002/for.3980040103.

KONTOPOULOU, V. I. et al. A Review of ARIMA vs. Machine Learning Approaches for Time Series Forecasting in Data Driven Networks. Future Internet , v. 15, n. 8, p. 255, 1 ago. 2023. Dispon√≠vel em: https://doi.org/10.3390/fi15080255.

LOZIA, Z. Application of modelling and simulation to evaluate the theta method used in diagnostics of automotive shock absorbers. The Archives of Automotive Engineering -Archiwum Motoryzacji , v. 96, n. 2, p. 5 -30, 30 jun. 2022. Dispon√≠vel em: https://doi.org/10.14669/AM/150823.

MAKRIDAKIS, S.; HIBON, M. The M3-Competition: results, conclusions and implications. International Journal of Forecasting , v. 16, n. 4, p. 451 -476, out. 2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00057-1.

MAKRIDAKIS, S.; WHEELWRIGHT, S. C.; HYNDMAN, R. J. Forecasting: Methods and Applications. In: Elements of Forecasting . Oxfordshire: Taylor &amp; Francis, 1999. p. 345 -346. Dispon√≠vel em:

https://www.researchgate.net/publication/52008212\_Forecasting\_Methods\_and\_Appl ications.

MALIK, Shubham; HARODE, Rohan; KUNWAR, Akash Singh. XGBoost: a deep dive into boosting . Medium Blog, 2020. Dispon√≠vel em: http://dx.doi.org/10.13140/RG.2.2.15243.64803.

MCKENZIE, ED. General exponential smoothing and the equivalent arma process. Journal of Forecasting , v. 3, n. 3, p. 333 -344, jul. 1984. Dispon√≠vel em: https://doi.org/10.1002/for.3980030312.

MONDAL, P.; SHIT, L.; GOSWAMI, S. Study of Effectiveness of Time Series Modeling (Arima) in Forecasting Stock Prices. International Journal of Computer Science, Engineering and Applications , v. 4, n. 2, p. 13 -29, 30 abr. 2014. Dispon√≠vel em: https://doi.org/10.5121/ijcsea.2014.4202.

MURAT, M. et al. Forecasting daily meteorological time series using ARIMA and regression models. International Agrophysics , v. 32, n. 2, p. 253 -264, 1 abr. 2018. Dispon√≠vel em: https://doi.org/10.1515/intag-2017-0007.

NEWBOLD, P. ARIMA model building and the time series analysis approach to forecasting. Journal of Forecasting , v. 2, n. 1, p. 23 -35, jan. 1983. Dispon√≠vel em: https://doi.org/10.1002/for.3980020104.

PAO, James J.; SULLIVAN, Danielle S. Time series sales forecasting . Final year project, Computer Science, Stanford Univ., Stanford, CA, USA, 2017. Dispon√≠vel em: https://cs229.stanford.edu/proj2017/final-reports/5244336.pdf.

The Annals of Mathematical

PARZEN, E. An Approach to Time Series Analysis. Statistics , v. 32, n. 4, p. 951 -989, 1961. Dispon√≠vel em: https://www.jstor.org/stable/2237900.

SHIRI, F. M. et al. A Comprehensive Overview and Comparative Analysis on Deep Learning Models. Journal on Artificial Intelligence , v. 6, n. 1, p. 301 -360, 2024. Dispon√≠vel em: https://doi.org/10.32604/jai.2024.054314.

SPILIOTIS, E.; ASSIMAKOPOULOS, V.; MAKRIDAKIS, S. Generalizing the Theta method for automatic forecasting. European Journal of Operational Research , jan. 2020. Dispon√≠vel em: http://dx.doi.org/10.1016/j.ejor.2020.01.007.

VAVLIAKIS, K.; SIAILIS, A.; SYMEONIDIS, A. Optimizing Sales Forecasting in eCommerce with ARIMA and LSTM Models. Proceedings of the 17th International Conference on Web Information Systems and Technologies , 2021. Dispon√≠vel em: https://doi.org/10.5220/0010659500003058.