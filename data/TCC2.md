## UNIVERSIDADE DO VALE DO RIO DOS SINOS (UNISINOS)

## UNIDADE ACAD√äMICA DE GRADUA√á√ÉO CURSO DE ENGENHARIA DA

## COMPUTA√á√ÉO

## PEDRO DELAVALD FR√Å

## PREVIS√ÉO DE VENDAS:

An√°lise comparativa entre abordagens de aprendizado de m√°quina e Power BI

S√£o Leopoldo

2025


---

# Page 2

2

## PEDRO DELAVALD FR√Å

## PREVIS√ÉO DE VENDAS:

An√°lise comparativa entre abordagens de aprendizado de m√°quina e Power BI

Trabalho

de

Conclus√£o

de

Curso

apresentado como requisito parcial para

obten√ß√£o do t√≠tulo de Bacharel em

Engenharia da Computa√ß√£o, pelo Curso de

Engenharia

da

Computa√ß√£o

da

Universidade do Vale do Rio dos Sinos

## (UNISINOS)

Orientador: Prof. MSc. Jean Schmith

S√£o Leopoldo

2025


---

# Page 3

## RESUMO

Este trabalho tem como objetivo avaliar e comparar o desempenho de

diferentes m√©todos de previs√£o de vendas, utilizando tanto t√©cnicas estat√≠sticas

tradicionais quanto algoritmos modernos de aprendizado de m√°quina, aplicados a

dados reais de faturamento extra√≠dos de um dashboard corporativo em Power BI.

Diante do aumento da competitividade e da demanda por decis√µes empresariais

baseadas em dados, destaca-se a necessidade de modelos preditivos cada vez mais

precisos e robustos. O estudo envolve a implementa√ß√£o dos modelos ARIMA, Theta,

Suaviza√ß√£o Exponencial e XGBoost, analisando suas performances preditivas e as

possibilidades de ado√ß√£o dessas abordagens no contexto empresarial. Os resultados

s√£o avaliados a partir de m√©tricas estat√≠sticas padronizadas, permitindo identificar se

algum modelo apresenta desempenho superior ao m√©todo atualmente empregado. A

pesquisa contribui para a aproxima√ß√£o entre teoria e pr√°tica, oferecendo subs√≠dios

para a escolha de m√©todos de previs√£o mais adequados √†s necessidades das

organiza√ß√µes e potencializando o valor estrat√©gico das an√°lises de vendas.

Palavras-chave: Previs√£o de Vendas; S√©ries Temporais; Aprendizado de M√°quina;

Power BI; ARIMA; XGBoost; Suaviza√ß√£o Exponencial; M√©todo Theta; Business

Intelligence.


---

# Page 4

## ABSTRACT

This work aims to evaluate and compare the performance of different sales

forecasting methods, employing both traditional statistical techniques and modern

machine learning algorithms, applied to real revenue data extracted from a corporate

dashboard in Power BI. Given the increasing competitiveness and demand for data-

driven business decisions, there is a growing need for more accurate and robust

predictive models. The study involves the implementation of ARIMA, Theta,

Exponential Smoothing, and XGBoost models, analyzing their predictive performance

and the feasibility of adopting these approaches in corporate environments. The results

are assessed using standardized statistical metrics, allowing for the identification of

models that outperform the currently employed method. This research contributes to

bridging the gap between theory and practice, offering guidance for the selection of

forecasting methods that best fit organizational needs and enhancing the strategic

value of sales analytics.

Key-words: Sales Forecasting; Time Series; Machine Learning; Power BI; ARIMA;

XGBoost; Exponential Smoothing; Theta Method; Business Intelligence.


---

# Page 5

## LISTA DE FIGURAS

Figura 1 - Metodologia geral do trabalho ................................................................... 30

Figura 2 - Metodologia do modelo ARIMA ................................................................ 48

Figura 3 ‚Äì Metodologia do modelo XGBoost ............................................................. 64

Figura 4 - Metodologia do modelo de Suaviza√ß√£o Exponencial ... Erro! Indicador n√£o

definido.

Figura 5 - Metodologia do modelo Theta ...................... Erro! Indicador n√£o definido.


---

# Page 6

6

## LISTA DE QUADROS

Quadro 1 - Cronograma de Desenvolvimento do Projeto ............. Erro! Indicador n√£o

definido.


---

# Page 7

## LISTA DE SIGLAS

## CNN

Convolutional Neural Network

## RNN

Recurrent Neural Network

## ARIMA

Auto Regressive Integrated Moving Average

XGBoost

X Gradient Boost

## ML

Machine Learning

## PIB

Produto Interno Bruto

## SARIMA

Seasonal Auto Regressive Integrated Moving Average

## LSTM

Long Short-Term Memory

## STL

Seasonal and Trend decomposition using LOESS

## AIC

Akaike Information Criterion

## AR

Auto Regressive

## MA

Moving Average

## SES

Simple Exponential Smoothing

## ACF

Autocorrelation Function

## PACF

Parcial Autocorrelation Function

## KPSS

Kwiatkowski-Phillips-Schmidt-Shin

## ADF

Augmented Dickey Fuller

## RMSSE

Root Mean Squared Scaled Error

## RMSE

Root Mean Squared Error

## MAE

Mean Absolute Error

## BI

Business Intelligence

## GBDT

Gradient Boosting Decision Tree


---

# Page 8

## SUM√ÅRIO

1 INTRODU√á√ÉO ....................................................................................................... 11

1.1 TEMA .................................................................................................................. 11

1.2 DELIMITA√á√ÉO DO TEMA ................................................................................... 12

1.3 PROBLEMA ........................................................................................................ 12

1.4 OBJETIVOS ........................................................................................................ 12

1.4.1 Objetivo geral ................................................................................................. 12

1.4.2 Objetivos espec√≠ficos ..................................................................................... 12

1.5 JUSTIFICATIVA .................................................................................................. 13

2 FUNDAMENTA√á√ÉO TE√ìRICA ............................................................................. 14

2.1 S√âRIES TEMPORAIS ......................................................................................... 14

2.1.1 Conceitos fundamentais e defini√ß√µes .......................................................... 14

2.1.2 Caracter√≠sticas principais .............................................................................. 14

2.1.3 Classifica√ß√µes de s√©ries temporais .............................................................. 15

2.1.4 Exemplos de aplica√ß√£o .................................................................................. 16

2.2 M√âTODO THETA ................................................................................................ 16

2.2.1 Descri√ß√£o geral e origem ............................................................................... 17

2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros .......................................................... 17

2.2.3 Equa√ß√£o da linha Theta ................................................................................. 18

2.2.4 Express√µes aditivas e multiplicativas .......................................................... 18

2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros ..................... 18

2.2.6 Exemplos pr√°ticos de uso ............................................................................. 19

2.3 MODELO ARIMA ................................................................................................ 20

2.3.1 Defini√ß√£o e estrutura do modelo ARIMA ...................................................... 20

2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA ........................................... 21

2.3.3 Como o modelo ARIMA funciona para prever dados futuros? .................. 21

2.3.4 Casos pr√°ticos e exemplos na literatura ...................................................... 22

2.4 SUAVIZA√á√ÉO EXPONENCIAL ........................................................................... 23

2.4.1 Defini√ß√£o e estrutura do m√©todo .................................................................. 23

2.4.2 Vantagens e limita√ß√µes na previs√£o de dados ............................................ 24

2.4.3 Aplica√ß√µes e estudos de caso ...................................................................... 25

2.5 XGBOOST ........................................................................................................... 26

2.5.1 Vis√£o geral do Extreme Gradient Boosting .................................................. 26


---

# Page 9

9

2.5.2 Caracter√≠sticas e conceitos do XGBoost ..................................................... 27

2.5.3 Como o XGBoost prev√™ dados futuros ........................................................ 27

2.5.4 Exemplos pr√°ticos de uso do XGBoost ........................................................ 29

3 METODOLOGIA .................................................................................................... 30

3.1 METODOLOGIA DE TRABALHO ....................................................................... 30

3.1.1 Defini√ß√£o do problema e objetivos da previs√£o .......................................... 31

3.1.2 Coleta e integra√ß√£o dos dados ..................................................................... 31

3.1.3 Pr√©-processamento e transforma√ß√µes dos dados Erro! Indicador n√£o definido.

3.1.4 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal ............................... 38

3.2 MODELOS DE PREVIS√ÉO UTILIZADOS ........................................................... 47

3.2.1 ARIMA .............................................................................................................. 48

3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente ............................... 48

3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal ................................... 49

3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o ............................................ 50

3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste ........................................ 51

3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q ................................................................. 51

3.2.1.6 Treinamento do modelo ................................................................................. 52

3.2.1.7 Valida√ß√£o do modelo e ajustes finos ............................................................. 53

3.2.1.8 An√°lise residual ............................................................................................. 54

3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura ............................. 54

3.2.2 XGBoost .......................................................................................................... 64

3.2.2.1 Prepara√ß√£o e engenharia de vari√°veis .......................................................... 65

3.2.2.2 Divis√£o dos dados em treino e teste ............................................................. 65

3.2.2.3 Normaliza√ß√£o e tratamento dos dados .......................................................... 65

3.2.2.4 Configura√ß√£o dos hiper par√¢metros iniciais ................................................... 65

3.2.2.5 Treinamento inicial do modelo ....................................................................... 66

3.2.2.6 Avalia√ß√£o inicial de desempenho .................................................................. 67

3.2.2.7 Busca e ajuste de hiper par√¢metros .............................................................. 67

3.2.2.8 Valida√ß√£o cruzada e an√°lise de resultados ................................................... 67

3.2.2.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados .................. 67

3.2.3 Suaviza√ß√£o exponencial .......................................... Erro! Indicador n√£o definido.

3.2.3.1 Prepara√ß√£o dos dados ..................................... Erro! Indicador n√£o definido.

3.2.3.2 An√°lise explorat√≥ria e estrutura da s√©rie temporalErro!

Indicador

n√£o

definido.


---

# Page 10

10

3.2.3.3 Divis√£o em conjunto de treino e teste............... Erro! Indicador n√£o definido.

3.2.3.4 Sele√ß√£o do tipo de suaviza√ß√£o exponencial e par√¢metrosErro! Indicador n√£o

definido.

3.2.3.5 Treinamento inicial do modelo .......................... Erro! Indicador n√£o definido.

3.2.3.6 Gera√ß√£o das previs√µes ..................................... Erro! Indicador n√£o definido.

3.2.3.7 Avalia√ß√£o do desempenho ............................... Erro! Indicador n√£o definido.

3.2.3.8 Ajuste fino e revalida√ß√£o .................................. Erro! Indicador n√£o definido.

3.2.3.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados ............. Erro!

Indicador n√£o definido.

3.2.4 Theta .......................................................................... Erro! Indicador n√£o definido.

3.2.4.1 Organiza√ß√£o e pr√©-condi√ß√µes dos dados ......... Erro! Indicador n√£o definido.

3.2.4.2 An√°lise inicial e sazonalidade ........................... Erro! Indicador n√£o definido.

3.2.4.3 Separa√ß√£o temporal para avalia√ß√£o ................. Erro! Indicador n√£o definido.

3.2.4.4 Configura√ß√£o e execu√ß√£o do algoritmo ............ Erro! Indicador n√£o definido.

3.2.4.5 Produ√ß√£o das previs√µes e p√≥s-processamento Erro! Indicador n√£o definido.

3.2.4.6 Avalia√ß√£o quantitativa e diagn√≥stico ................ Erro! Indicador n√£o definido.

3.2.4.7 Itera√ß√£o e consolida√ß√£o dos resultados ........... Erro! Indicador n√£o definido.

3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS .............................................. 68

3.4 CRONOGRAMA .................................................................................................. 68

REFER√äNCIAS ......................................................................................................... 69


---

# Page 11

11

## 1 INTRODU√á√ÉO

A previs√£o de vendas, no contexto atual da transforma√ß√£o digital e da crescente

demanda por decis√µes empresariais baseadas em dados, se estabelece como um dos

grandes desafios e diferenciais competitivos para organiza√ß√µes de todos os portes.

Com mercados cada vez mais din√¢micos e suscet√≠veis a varia√ß√µes econ√¥micas,

tecnol√≥gicas e comportamentais, a precis√£o nas estimativas de faturamento assume

papel central no planejamento, controle de estoques, log√≠stica, defini√ß√£o de metas e

estrat√©gias comerciais. Este cen√°rio impulsionou o avan√ßo de diferentes m√©todos de

previs√£o, desde t√©cnicas estat√≠sticas tradicionais at√© abordagens inovadoras de

aprendizado de m√°quina, que v√™m transformando a forma como as empresas

analisam e projetam seus resultados futuros.

O uso disseminado de ferramentas de BI, como o Power BI, trouxe grandes

avan√ßos para a visualiza√ß√£o e interpreta√ß√£o dos dados hist√≥ricos das empresas,

permitindo a elabora√ß√£o de dashboards customizados para acompanhamento do

desempenho de vendas. Contudo, muitos desses sistemas ainda utilizam m√©todos de

previs√£o relativamente simples, que podem n√£o captar integralmente a complexidade

dos padr√µes temporais, sazonalidades e vari√°veis ex√≥genas presentes nos dados

(ENSAFI et al., 2022). Paralelamente, algoritmos de ML, como o XGBoost, v√™m sendo

destacados na literatura por sua elevada acur√°cia preditiva, robustez e flexibilidade

na incorpora√ß√£o de m√∫ltiplos fatores ao processo de modelagem, sendo escolhido

frequentemente em cen√°rios reais e competi√ß√µes internacionais (CHEN; GUESTRIN,

2016).

Diante desse contexto, torna-se pertinente avaliar, sob uma perspectiva

aplicada e comparativa, se modelos de ML podem efetivamente aprimorar as

previs√µes de faturamento realizadas por solu√ß√µes j√° consolidadas no ambiente

empresarial, como o Power BI, contribuindo para a gera√ß√£o de insights mais robustos

e embasados para a tomada de decis√£o.

## 1.1 TEMA

O presente trabalho aborda o tema da previs√£o de vendas utilizando s√©ries

temporais, com foco na compara√ß√£o entre m√©todos tradicionais e modernos de

modelagem preditiva aplicados a dados reais de faturamento empresarial.


---

# Page 12

12

## 1.2 DELIMITA√á√ÉO DO TEMA

A pesquisa concentra-se na an√°lise comparativa do desempenho de diferentes

modelos de previs√£o utilizando dados hist√≥ricos extra√≠dos de um banco de dados. O

estudo limita-se √† previs√£o de faturamento mensal, simulando o contexto pr√°tico

enfrentado por empresas que necessitam estimar o resultado do m√™s corrente com

base em informa√ß√µes parciais, do primeiro dia do m√™s at√© o momento da consulta.

## 1.3 PROBLEMA

O problema que orienta este trabalho √©: Modelos avan√ßados de aprendizado

de m√°quina podem proporcionar previs√µes mais precisas de faturamento, quando

comparados √† abordagem utilizada em dashboards de Power BI? A investiga√ß√£o

busca responder se a ado√ß√£o de modelos de aprendizado de m√°quina como XGBoost,

ARIMA, Suaviza√ß√£o Exponencial e Theta pode, de fato, melhorar a acur√°cia das

proje√ß√µes realizadas atualmente pela empresa, promovendo maior confiabilidade e

valor estrat√©gico √†s informa√ß√µes disponibilizadas.

## 1.4 OBJETIVOS

1.4.1 Objetivo geral

Avaliar, de forma comparativa, o desempenho de diferentes abordagens de

previs√£o de vendas, sejam elas tradicionais ou baseadas em ML, aplicadas a dados

reais de faturamento, verificando se algum dos modelos apresenta desempenho

superior ao m√©todo atualmente utilizado em dashboards de Power BI.

1.4.2 Objetivos espec√≠ficos

a) Revisar e contextualizar os principais conceitos de s√©ries temporais,

m√©todos estat√≠sticos cl√°ssicos e t√©cnicas de ML voltadas √† previs√£o de

vendas, conforme descrito por autores como Bezerra (2006), Makridakis,

Wheelwright e Hyndman (1999) e Ensafi et al. (2022);


---

# Page 13

13

b) Estruturar e pr√©-processar os dados hist√≥ricos de faturamento de acordo

com as exig√™ncias de cada modelo preditivo, assegurando anonimiza√ß√£o,

integridade e conformidade com boas pr√°ticas de ci√™ncia de dados;

c) Implementar, treinar e validar modelos de previs√£o ARIMA, Theta,

Suaviza√ß√£o Exponencial e XGBoost, utilizando m√©tricas estat√≠sticas

padronizadas para avalia√ß√£o do desempenho;

d) Analisar comparativamente os resultados obtidos e discutir as vantagens,

limita√ß√µes e possibilidades pr√°ticas para ado√ß√£o dos m√©todos preditivos no

contexto empresarial.

Acredita-se que essa abordagem possibilite uma an√°lise abrangente e rigorosa,

identificando as oportunidades e desafios envolvidos na transi√ß√£o para modelos

preditivos mais avan√ßados no ambiente corporativo.

## 1.5 JUSTIFICATIVA

A relev√¢ncia deste estudo se justifica tanto pelo avan√ßo recente das t√©cnicas

de an√°lise preditiva quanto pela necessidade real de organiza√ß√µes aprimorarem seus

processos de tomada de decis√£o frente a cen√°rios de incerteza e competitividade. Do

ponto de vista acad√™mico, h√° uma lacuna na literatura nacional sobre aplica√ß√µes

pr√°ticas e comparativas de modelos de machine learning em ambientes de BI

amplamente adotados por empresas brasileiras, como o Power BI (ENSAFI et al.,

2022; SHIRI et al., 2024). Internacionalmente, pesquisas v√™m demonstrando o

potencial de algoritmos como XGBoost na supera√ß√£o de m√©todos tradicionais de

previs√£o, especialmente em s√©ries temporais com padr√µes complexos e influ√™ncias

externas (CHEN; GUESTRIN, 2016).

No √¢mbito empresarial, a ado√ß√£o de modelos mais precisos pode representar

ganhos substanciais em planejamento, controle financeiro e competitividade,

permitindo que decis√µes sejam tomadas com maior base quantitativa e menor risco.

Este trabalho, ao propor uma an√°lise comparativa fundamentada, contribui para

aproximar a teoria e a pr√°tica, orientando gestores e profissionais de dados quanto √†

melhor escolha de m√©todos para suas demandas espec√≠ficas.


---

# Page 14

14

## 2 FUNDAMENTA√á√ÉO TE√ìRICA

Neste cap√≠tulo, apresenta-se o embasamento te√≥rico indispens√°vel ao

desenvolvimento do presente estudo. Ser√£o discutidos os conceitos fundamentais

relacionados √† previs√£o de dados, contemplando tanto a aplica√ß√£o de algoritmos de

aprendizado de m√°quina quanto a utiliza√ß√£o de c√°lculos no Power BI. A partir dessa

fundamenta√ß√£o, busca-se sustentar o estudo de caso realizado, evidenciando as

principais vantagens e limita√ß√µes de cada abordagem na an√°lise e proje√ß√£o de

informa√ß√µes.

## 2.1 S√âRIES TEMPORAIS

A an√°lise de s√©ries temporais √© uma importante √°rea da estat√≠stica, dedicada √†

compreens√£o, modelagem e previs√£o de fen√¥menos que s√£o observados de forma

sequencial no tempo. Conforme Bezerra (2006), a utiliza√ß√£o da an√°lise de s√©ries

temporais √© amplamente difundida em diversas √°reas, como economia, meteorologia,

sa√∫de, controle de processos industriais, vendas e finan√ßas, devido √† capacidade de

identificar padr√µes de comportamento e realizar previs√µes futuras com base em dados

hist√≥ricos.

2.1.1 Conceitos fundamentais e defini√ß√µes

De acordo com Parzen (1961), uma s√©rie temporal pode ser entendida como

um conjunto de observa√ß√µes dispostas cronologicamente, sendo representada

matematicamente como um processo estoc√°stico, no qual cada valor observado

corresponde a um instante espec√≠fico no tempo.

2.1.2 Caracter√≠sticas principais

Entre os principais conceitos e caracter√≠sticas envolvidos na an√°lise de s√©ries

temporais, destacam-se:

a) Estacionariedade: Segundo Bezerra (2006), a estacionariedade ocorre

quando as propriedades estat√≠sticas, tais como m√©dia, vari√¢ncia e

covari√¢ncia, permanecem constantes ao longo do tempo. A condi√ß√£o de


---

# Page 15

15

estacionariedade √© importante para aplica√ß√£o correta de diversos modelos,

como os modelos ARIMA.

b) Tend√™ncia: Refere-se √† dire√ß√£o predominante da s√©rie ao longo do tempo,

podendo ser crescente, decrescente ou est√°vel. Segundo Makridakis,

Wheelwright e Hyndman (1999), a tend√™ncia √© fundamental para entender o

comportamento das s√©ries e escolher modelos adequados.

c) Sazonalidade: Corresponde √†s varia√ß√µes peri√≥dicas e regulares que

ocorrem em intervalos fixos, como mensal ou anual, devido a fatores

externos

ou

eventos

recorrentes

## (MAKRIDAKIS,

## WHEELWRIGHT;

## HYNDMAN, 1999).

d) Autocorrela√ß√£o: Representa a correla√ß√£o da s√©rie consigo mesma em

diferentes momentos do tempo (lags). De acordo com Parzen (1961), esse

conceito √© fundamental para identificar e compreender o comportamento das

s√©ries temporais.

e) Ru√≠do branco: Para Bezerra (2006), √© a parcela aleat√≥ria da s√©rie

temporal, composta por erros aleat√≥rios independentes com m√©dia zero e

vari√¢ncia constante, que n√£o apresentam qualquer tipo de padr√£o previs√≠vel.

2.1.3 Classifica√ß√µes de s√©ries temporais

Makridakis, Wheelwright e Hyndman (1999) classificam as s√©ries temporais em

tipos distintos:

a) S√©ries estacion√°rias: Caracterizam-se por apresentar m√©dia e vari√¢ncia

constantes ao longo do tempo. S√£o frequentemente observadas em s√©ries

financeiras de retorno.

b) S√©ries n√£o estacion√°rias: S√£o s√©ries cujas propriedades estat√≠sticas, como

m√©dia e/ou vari√¢ncia, alteram-se com o tempo. Exemplos comuns incluem

s√©ries econ√¥micas como PIB e infla√ß√£o.

c) S√©ries lineares e n√£o lineares: S√©ries lineares podem ser modeladas por

t√©cnicas tradicionais, como ARIMA, enquanto s√©ries n√£o lineares exigem

modelos mais avan√ßados, como redes neurais artificiais (SHIRI et al., 2024).


---

# Page 16

16

2.1.4 Exemplos de aplica√ß√£o

V√°rios estudos demonstram a aplica√ß√£o pr√°tica das s√©ries temporais em

diversos contextos:

a) Previs√£o de vendas no varejo: Ensafi et al. (2022) compararam t√©cnicas

tradicionais como SARIMA e Suaviza√ß√£o Exponencial com m√©todos

avan√ßados como redes neurais LSTM e CNN para previs√£o das vendas

sazonais de m√≥veis. Os resultados mostraram que as redes neurais LSTM

apresentaram maior precis√£o na captura de padr√µes complexos e sazonais.

b) Previs√£o de vendas semanais em lojas de departamento: Pao e Sullivan

(2014) utilizaram t√©cnicas como √°rvores de decis√£o, STL+ARIMA e redes

neurais feed-forward com entradas temporais defasadas, concluindo que as

redes neurais tiveram um desempenho superior, capturando com efici√™ncia

as sazonalidades das vendas semanais.

c) Aplica√ß√£o de Deep Learning em s√©ries temporais complexas: Shiri et al.

(2024) realizaram uma revis√£o abrangente sobre o uso de modelos de deep

learning, como CNN, RNN, LSTM e Transformer, em s√©ries temporais. O

estudo apontou que t√©cnicas modernas baseadas em deep learning t√™m se

mostrado superiores √†s t√©cnicas tradicionais, principalmente em s√©ries

complexas e com grandes volumes de dados.

## 2.2 M√âTODO THETA

O m√©todo Theta ganhou popularidade ao vencer a competi√ß√£o M3 de previs√µes

de s√©ries temporais devido √† sua simplicidade e efici√™ncia em gerar previs√µes precisas

para diversos tipos de dados. Desde ent√£o, este m√©todo tem sido amplamente

estudado e aprimorado, resultando em diferentes variantes que exploram seu

potencial para aplica√ß√µes autom√°ticas e mais robustas. (ASSIMAKOPOULOS;

## NIKILOPOULOS, 2000).


---

# Page 17

17

2.2.1 Descri√ß√£o geral e origem

O m√©todo Theta √© uma t√©cnica de previs√£o uni variada que decomp√µe a s√©rie

temporal original em componentes denominados "linhas Theta". Cada linha Theta √©

obtida ajustando-se a curvatura dos dados originais atrav√©s de um par√¢metro Œ∏

aplicado √†s segundas diferen√ßas da s√©rie original. (ASSIMAKOPOULOS;

## NIKILOPOULOS, 2000; SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020). A

combina√ß√£o dessas linhas Theta gera previs√µes que equilibram tend√™ncias de curto e

longo prazo. (ASSIMAKOPOULOS; NIKILOPOULOS, 2000).

2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros

As principais caracter√≠sticas do m√©todo Theta incluem:

a) Decomposi√ß√£o da s√©rie temporal: a s√©rie original √© dividida em m√∫ltiplas

linhas Theta, destacando diferentes caracter√≠sticas como tend√™ncias de

curto e longo prazo (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000).

b) Par√¢metro Œ∏ (Theta): controla a curvatura das linhas, com ùúÉ< 1 enfatizando

tend√™ncias de longo prazo e ùúÉ> 1 destacando varia√ß√µes de curto prazo.

## (ASSIMAKOPOULOS;

## NIKOLOPOULOS,

2000;

## SPILIOTIS;

## ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

c) Combina√ß√£o de previs√µes: as previs√µes geradas a partir das linhas Theta

s√£o combinadas usando pondera√ß√µes espec√≠ficas para gerar resultados

mais robustos e precisos (FIORUCCI et al., 2016).

d) Flexibilidade e robustez: permite ajuste e adapta√ß√£o autom√°tica dos

par√¢metros para diferentes s√©ries temporais, tornando-o vers√°til para

diversos contextos (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

e) Efici√™ncia computacional: destaca-se pela simplicidade computacional,

sendo f√°cil e r√°pido de implementar, especialmente quando comparado com

m√©todos mais complexos como ARIMA ou redes neurais (FIORUCCI et al.,

2016).

f) Capacidade de generaliza√ß√£o: √© aplic√°vel em s√©ries temporais com

diferentes padr√µes, como tend√™ncias lineares, n√£o lineares, s√©ries com


---

# Page 18

18

comportamento

sazonal

e

s√©ries

irregulares

## (SPILIOTIS;

## ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

g) Simplicidade na interpreta√ß√£o: oferece resultados facilmente interpret√°veis,

facilitando seu uso pr√°tico em ambientes corporativos e industriais

(FIORUCCI et al., 2016).

2.2.3 Equa√ß√£o da linha Theta

Segundo Spiliotis, Assimakopoulos e Makridakis (2020), o m√©todo Theta pode

ser matematicamente descrito da seguinte forma:

Seja ùëåùë° uma s√©rie temporal observada no tempo ùë°. Uma linha Theta ùëçùë°(ùúÉ) √©

obtida pela express√£o:

‚àá2ùëçùë°(ùúÉ) = ùúÉ‚àá2ùëåùë°= ùúÉ(ùëåùë°‚àí2ùëå(ùë°‚àí1) + ùëå(ùë°+2)),

ùë°= 3, ‚Ä¶ , ùëõ

onde ‚àá2ùëåùë° √© o operador das segundas diferen√ßas da s√©rie original ùëå no ponto ùë°.

2.2.4 Express√µes aditivas e multiplicativas

No m√©todo Theta, as previs√µes podem ser realizadas utilizando express√µes

aditivas ou multiplicativas:

a) Modelo aditivo: √© o modelo original do m√©todo Theta, no qual as previs√µes

s√£o obtidas pela combina√ß√£o linear aditiva das linhas Theta ajustadas

## (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000).

b) Modelo multiplicativo: √© uma extens√£o recente do m√©todo, permitindo

modelar situa√ß√µes em que componentes como sazonalidade e tend√™ncia

interagem de forma multiplicativa, sendo especialmente √∫til em s√©ries com

tend√™ncia

exponencial

ou

comportamento

sazonal

multiplicativo

## (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros

Para prever dados futuros, o m√©todo Theta realiza as seguintes etapas

## (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000; FIORUCCI, 2016):


---

# Page 19

19

a) Decomposi√ß√£o: a s√©rie temporal √© decomposta em linhas Theta com

diferentes curvaturas.

b) Extrapola√ß√£o: cada linha √© extrapolada individualmente, frequentemente

usando m√©todos simples, como suaviza√ß√£o exponencial simples (SES) para

tend√™ncias de curto prazo e regress√£o linear para tend√™ncias de longo

prazo.

c) Combina√ß√£o das linhas: as previs√µes individuais s√£o combinadas,

geralmente com pesos iguais ou otimizados, produzindo uma previs√£o final

robusta.

2.2.6 Exemplos pr√°ticos de uso

O m√©todo Theta tem sido amplamente aplicado em diversas √°reas,

demonstrando sua robustez:

a) Competi√ß√£o M3: a vers√£o cl√°ssica do m√©todo Theta alcan√ßou resultados

superiores √†s demais t√©cnicas na competi√ß√£o M3, uma famosa competi√ß√£o

internacional focada em m√©todos de previs√£o de s√©ries temporais,

especialmente em s√©ries mensais e microecon√¥micas, destacando-se por

sua precis√£o e simplicidade (MAKRIDAKIS; HIBON, 2000).

b) Diagn√≥stico automotivo: Lozia (2022) utilizou o m√©todo Theta na avalia√ß√£o

diagn√≥stica de amortecedores automotivos, demonstrando a efic√°cia do

m√©todo em modelar e prever o comportamento din√¢mico de sistemas

mec√¢nicos complexos.

c) Previs√£o autom√°tica: Spiliotis, Assimakopoulos e Makridakis (2020)

propuseram generaliza√ß√µes do m√©todo Theta capazes de selecionar

automaticamente a forma mais apropriada (aditiva ou multiplicativa) e ajustar

a inclina√ß√£o das tend√™ncias, superando outros algoritmos autom√°ticos em

competi√ß√µes recentes (como M4), especialmente em s√©ries anuais.


---

# Page 20

20

## 2.3 MODELO ARIMA

O modelo ARIMA √© uma t√©cnica estat√≠stica amplamente utilizada para an√°lise

e previs√£o de s√©ries temporais, desenvolvido por Box e Jenkins (1970). √â

especialmente indicado para s√©ries cujos valores passados e erros hist√≥ricos podem

ser utilizados para prever valores futuros (NEWBOLD, 1983).

2.3.1 Defini√ß√£o e estrutura do modelo ARIMA

O modelo ARIMA √© uma combina√ß√£o dos modelos autorregressivos (AR),

integrados (I) e de m√©dias m√≥veis (MA), definidos pela seguinte nota√ß√£o geral ARIMA

(p, d, q), onde (NEWBOLD, 1983):

a) p: ordem do termo autorregressivo (AR), representa a rela√ß√£o linear entre a

observa√ß√£o atual e as anteriores.

b) d: n√∫mero de diferencia√ß√µes necess√°rias para tornar a s√©rie estacion√°ria.

c) q: ordem dos termos de m√©dia m√≥vel (MA), que refletem os erros anteriores

do modelo.

Matematicamente, o modelo ARIMA (p, d, q) pode ser expresso da seguinte

forma (NEWBOLD, 1983):

ùëåùë°=  ùõø + ùúô1ùëåùë°‚àí1 + ùúô2ùëåùë°‚àí2 + ‚Ä¶ + ùúôùëùùëåùë°‚àíùëù‚àí ùúÉ1ùúÄùë°‚àí1 ‚àí ùúÉ2ùúÄùë°‚àí2 ‚àí ‚Ä¶ ‚àí ùúÉùëûùúÄùë°‚àíùëû+ ùúÄùë°

Onde:

‚Ä¢

ùëåùë°: valor atual da s√©rie temporal.

‚Ä¢

ùëåùë°‚àí1, ùëåùë°‚àí2,..., ùëåùë°‚àíùëù : valores anteriores da s√©rie temporal (termos AR).

‚Ä¢

ùúÄùë°: erro aleat√≥rio (res√≠duos) com distribui√ß√£o normal, m√©dia zero e vari√¢ncia

constante (ru√≠do branco).

‚Ä¢

ùúÄùë°‚àí1, ùúÄùë°‚àí2, ..., ùúÄùë°‚àíùëû: erros anteriores da s√©rie (termos MA).

‚Ä¢

ùõø: constante.

‚Ä¢

ùúô1, ùúô2, ‚Ä¶ , ùúôùëù: coeficientes do termo autorregressivo.

‚Ä¢

ùúÉ1, ùúÉ2, ‚Ä¶ , ùúÉùëû: coeficientes do termo de m√©dia m√≥vel.


---

# Page 21

21

2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA

As principais caracter√≠sticas do modelo ARIMA incluem (BOX; JENKINS, 1970;

FATTAH et al., 2018):

a) Flexibilidade: Pode ajustar-se a diversas s√©ries temporais, incorporando

tend√™ncia, ciclos e sazonalidade.

b) Necessidade de estacionariedade: S√©ries temporais precisam ser

estacion√°rias para utiliza√ß√£o correta do modelo. A estacionariedade √©

geralmente obtida por diferencia√ß√£o sucessiva das s√©ries temporais.

c) Simplicidade: F√°cil de compreender e implementar, apresentando

resultados robustos em previs√µes de curto prazo.

Para verificar se uma s√©rie √© estacion√°ria, frequentemente s√£o utilizados testes

estat√≠sticos como o teste Dickey-Fuller (ADF) e o teste KPSS (MURAT et al., 2018).

2.3.3 Como o modelo ARIMA funciona para prever dados futuros?

O processo de constru√ß√£o do modelo ARIMA segue a metodologia Box-

Jenkins, que possui as seguintes etapas (BOX; JENKINS, 1970; MONDAL et al.,

2014):

a) Identifica√ß√£o do modelo: Determina√ß√£o das ordens p, d e q, com base na

an√°lise gr√°fica das fun√ß√µes de autocorrela√ß√£o (ACF) e autocorrela√ß√£o

parcial (PACF).

b) Estima√ß√£o dos par√¢metros: Os coeficientes do modelo s√£o estimados,

normalmente utilizando o m√©todo da m√°xima verossimilhan√ßa.

c) Diagn√≥stico do modelo: Verifica√ß√£o da adequa√ß√£o do modelo por meio da

an√°lise dos res√≠duos (erros), usando testes como o teste de Ljung-Box e

crit√©rios estat√≠sticos como AIC (Crit√©rio de Informa√ß√£o de Akaike).

d) Previs√£o: Realiza√ß√£o da previs√£o de valores futuros utilizando o modelo

ajustado.


---

# Page 22

22

2.3.4 Casos pr√°ticos e exemplos na literatura

O modelo ARIMA tem diversas aplica√ß√µes pr√°ticas, como evidenciado em

diferentes estudos acad√™micos:

a) Previs√£o de demanda em ind√∫strias aliment√≠cias: Fattah et al. (2018)

mostraram que o modelo ARIMA (1,0,1) foi eficaz em prever a demanda

futura, ajudando a empresa na gest√£o eficiente de estoques e redu√ß√£o de

custos.

b) Previs√£o de vendas no e-commerce: Um modelo h√≠brido combinando

ARIMA com redes neurais LSTM foi utilizado para previs√£o precisa em

ambientes com alta volatilidade, como o com√©rcio eletr√¥nico (VAVLIAKIS et

al., 2021).

c) Previs√£o no mercado farmac√™utico: Fourkiotis e Tsadiras (2024) utilizaram

ARIMA em combina√ß√£o com t√©cnicas de aprendizado de m√°quina para

prever a demanda por produtos farmac√™uticos, mostrando sua efic√°cia em

capturar efeitos sazonais. Para enfrentar esse desafio, Fourkiotis e Tsadiras

(2024) utilizaram t√©cnicas de an√°lise uni variada de s√©ries temporais para

desenvolver previs√µes mais precisas. Os autores analisaram uma base de

dados real contendo 600.000 registros hist√≥ricos de vendas provenientes de

uma farm√°cia online, abrangendo um per√≠odo entre 2014 e 2019. A

metodologia proposta envolveu as etapas de pr√©-processamento e limpeza

de dados, segmenta√ß√£o dos dados, an√°lise explorat√≥ria e identifica√ß√£o dos

padr√µes temporais, aplica√ß√£o e compara√ß√£o do modelo ARIMA com

modelos avan√ßados de ML como LSTM e XGBoost e, por fim, avalia√ß√£o do

modelo com m√©tricas espec√≠ficas. Os resultados demonstraram que o

modelo ARIMA apresentou uma boa capacidade preditiva ao capturar

adequadamente a sazonalidade e tend√™ncias lineares de vendas. Contudo,

os autores destacaram que modelos de ML avan√ßados, especialmente o

XGBoost, tiveram um desempenho ainda superior. Em particular, o XGBoost

obteve as menores taxas de erro absoluto percentual m√©dio (MAPE). Apesar

da boa performance dos modelos avan√ßados de Machine Learning, o

modelo ARIMA ainda obteve desempenho competitivo e foi considerado


---

# Page 23

23

eficaz especialmente em s√©ries temporais com forte componente linear e

sazonalidade bem definida.

d) Previs√£o de pre√ßos no mercado financeiro: Mondal et al. (2014) utilizaram

ARIMA para prever pre√ßos de a√ß√µes, destacando sua simplicidade e

robustez na previs√£o de tend√™ncias.

## 2.4 SUAVIZA√á√ÉO EXPONENCIAL

O m√©todo de suaviza√ß√£o exponencial tem recebido grande aten√ß√£o no contexto

de previs√µes estat√≠sticas devido √† sua efic√°cia, simplicidade e adaptabilidade na

previs√£o de s√©ries temporais. Sua popularidade adv√©m da capacidade intr√≠nseca de

atribuir pesos maiores √†s observa√ß√µes mais recentes em detrimento das observa√ß√µes

mais antigas, permitindo r√°pidas adapta√ß√µes √†s mudan√ßas na din√¢mica dos dados

## (GARDNER, 1985; CIPRA, 1992).

Essa t√©cnica tornou-se uma abordagem padr√£o em diversos campos pr√°ticos,

incluindo gest√£o de estoques, controle de processos industriais, finan√ßas e gest√£o de

cadeias de suprimentos. Sua ampla ado√ß√£o se d√° pela facilidade computacional e

pela interpreta√ß√£o de suas previs√µes em compara√ß√£o com m√©todos mais complexos

como modelos ARIMA e redes neurais (MCKENZIE, 1984).

2.4.1 Defini√ß√£o e estrutura do m√©todo

O m√©todo de exponential smoothing √© uma t√©cnica recursiva para previs√£o de

s√©ries temporais que se baseia na pondera√ß√£o exponencial decrescente das

observa√ß√µes passadas. Formalmente, uma previs√£o futura √© constru√≠da como uma

combina√ß√£o linear entre a observa√ß√£o mais recente e a previs√£o feita anteriormente.

Essa caracter√≠stica de atualiza√ß√£o recursiva confere simplicidade e efici√™ncia

computacional ao m√©todo (BROWN, 1962; MCKENZIE, 1984).

Matematicamente, para o SES, a previs√£o do valor da s√©rie temporal ùëãùë°+1 pode

ser expressa por:

ùëãÃÇùë°+1 = ùõºùëãùë°+ (1 ‚àíùõº)ùëãÃÇùë°

Onde:

‚Ä¢

ùëãÃÇùë°+1: valor previsto para o pr√≥ximo per√≠odo;


---

# Page 24

24

‚Ä¢

ùëãùë°: valor observado no per√≠odo atual;

‚Ä¢

ùëãÃÇùë°: previs√£o feita anteriormente para o per√≠odo atual;

‚Ä¢

ùõº: constante de suaviza√ß√£o 0 < ùõº< 1, que define o grau de pondera√ß√£o

aplicado ao dado mais recente (BROWN, 1962).

J√° m√©todos mais avan√ßados, como o m√©todo de Holt-Winters, consideram

explicitamente os componentes de n√≠vel, tend√™ncia e sazonalidade da s√©rie temporal.

Segundo Gardner (1985), para s√©ries com comportamento sazonal e tend√™ncia linear,

a previs√£o futura para ‚Ñé passos √† frente √© dada pela express√£o geral do m√©todo de

Holt-Winters multiplicativo:

ùëãÃÇùë°+‚Ñé= (ùêøùë°+ ‚Ñé √ó ùëèùë°) √ó  ùëÜùë°+‚Ñé‚àíùëö(ùëò+1)

Onde:

‚Ä¢

ùêøùë° √© o n√≠vel estimado da s√©rie no tempo ùë°;

‚Ä¢

ùëèùë° √© a tend√™ncia estimada no tempo ùë°;

‚Ä¢

ùëÜùë°+‚Ñé‚àíùëö(ùëò+1) √© o fator sazonal estimado no tempo correspondente;

‚Ä¢

‚Ñé representa o horizonte futuro da previs√£o (quantidade de per√≠odos √† frente);

‚Ä¢

ùëö √© o per√≠odo sazonal da s√©rie (por exemplo, ùëö= 12 para s√©ries mensais

anuais);

‚Ä¢

ùëò √© o n√∫mero de ciclos completos transcorridos.

Esses m√©todos avan√ßados permitem previs√µes mais precisas em s√©ries

complexas, com tend√™ncias claras ou padr√µes sazonais fortes, superando m√©todos

mais simples como m√©dias m√≥veis ou o pr√≥prio exponential smoothing simples

## (MCKENZIE, 1984; GARDNER, 1985).

2.4.2 Vantagens e limita√ß√µes na previs√£o de dados

Entre as caracter√≠sticas fundamentais do m√©todo de exponential smoothing

destacam-se:

a) Adaptabilidade: capacidade de responder rapidamente √†s altera√ß√µes

estruturais na s√©rie temporal, atribuindo pesos exponenciais aos dados

recentes (GARDNER, 1985).


---

# Page 25

25

b) Simplicidade computacional: a estrutura recursiva dos c√°lculos torna o

m√©todo atrativo em aplica√ß√µes pr√°ticas, especialmente onde √© necess√°ria

atualiza√ß√£o constante das previs√µes (BROWN, 1962).

c) Flexibilidade estrutural: diferentes vers√µes, como simples, dupla e tripla

(Holt-Winters), permitem modelar comportamentos como tend√™ncia e

sazonalidade com efici√™ncia (MCKENZIE, 1984).

d) Robustez: vers√µes robustas do m√©todo, que usam a minimiza√ß√£o dos

desvios absolutos ou m√©todos M-estimadores ao inv√©s de m√≠nimos

quadrados, t√™m maior resist√™ncia a dados at√≠picos e s√©ries temporais com

distribui√ß√µes assim√©tricas ou de caudas pesadas (CIPRA, 1992).

2.4.3 Aplica√ß√µes e estudos de caso

a) Impacto da suaviza√ß√£o exponencial no Efeito Bullwhip: Chen, Ryan e

Simchi-Levi (2000) investigaram como a utiliza√ß√£o do exponential smoothing

na previs√£o de demanda pode intensificar o efeito bullwhip, fen√¥meno no

qual pequenas varia√ß√µes na demanda s√£o ampliadas ao longo da cadeia de

suprimentos. Eles demonstraram que, ao utilizar previs√µes com exponential

smoothing, as varia√ß√µes nas demandas observadas pelos fabricantes se

tornam significativamente maiores do que as percebidas pelos varejistas,

aumentando os desafios de gest√£o e planejamento log√≠stico nas

organiza√ß√µes.

b) Robustez a outliers em s√©ries temporais: Cipra (1992) avaliou o

desempenho de vers√µes robustas do m√©todo de exponential smoothing em

s√©ries temporais contaminadas por outliers e distribui√ß√µes de caudas longas.

Utilizando minimiza√ß√£o dos desvios absolutos (norma ùêø1) em vez dos

m√≠nimos quadrados, Cipra verificou experimentalmente que essas vers√µes

robustas forneceram previs√µes significativamente mais est√°veis e precisas

na presen√ßa de valores extremos, superando m√©todos tradicionais

especialmente em s√©ries financeiras e industriais onde valores at√≠picos s√£o

comuns.

c) Aplica√ß√µes em controle de estoques: Gardner (1985) destacou o uso bem-

sucedido de exponential smoothing no controle e previs√£o para gest√£o de

estoques. Nesse contexto, foram aplicadas varia√ß√µes do m√©todo para prever


---

# Page 26

26

demandas futuras e determinar n√≠veis √≥timos de estoque, reduzindo custos

relacionados √† manuten√ß√£o excessiva ou insuficiente de produtos em

invent√°rio. Esse exemplo demonstra claramente como o exponential

smoothing pode auxiliar gestores a otimizarem recursos financeiros e

log√≠sticos nas organiza√ß√µes.

d) Previs√µes de demanda em s√©ries sazonais e com tend√™ncia: McKenzie

(1984) apresentou exemplos pr√°ticos demonstrando a efic√°cia do

exponential smoothing para s√©ries temporais com forte comportamento

sazonal e tend√™ncia definida. Em seu estudo, foi utilizado o m√©todo Holt-

Winters para capturar esses componentes, proporcionando previs√µes mais

precisas que outros m√©todos tradicionais como m√©dias m√≥veis simples e

modelos ARIMA em s√©ries complexas, especialmente no contexto de

demanda sazonal de varejo e setores produtivos.

## 2.5 XGBOOST

O XGBoost tornou-se um dos m√©todos mais populares e eficazes no √¢mbito da

previs√£o e classifica√ß√£o em machine learning, devido √† sua capacidade de lidar

eficientemente com grandes quantidades de dados e produzir modelos altamente

precisos. Originalmente proposto por Chen e Guestrin em 2016, o XGBoost combina

otimiza√ß√µes algor√≠tmicas e t√©cnicas avan√ßadas de engenharia de sistemas para

aprimorar significativamente o desempenho de previs√µes e classifica√ß√µes em diversas

√°reas (CHEN; GUESTRIN, 2016).

2.5.1 Vis√£o geral do Extreme Gradient Boosting

O XGBoost √© uma implementa√ß√£o otimizada do algoritmo Gradient Boosting,

baseado em √°rvores de decis√£o sequenciais. Diferentemente das abordagens

tradicionais, que utilizam √°rvores independentes (como o Random Forest), o XGBoost

constr√≥i √°rvores de maneira iterativa, com cada √°rvore subsequente aprendendo dos

res√≠duos e erros das anteriores. A combina√ß√£o final das √°rvores resulta em um modelo

robusto e altamente eficiente para prever valores futuros e classificar dados

complexos (MALIK; HARODE; KUNWAR, 2020).


---

# Page 27

27

2.5.2 Caracter√≠sticas e conceitos do XGBoost

Entre as caracter√≠sticas fundamentais do XGBoost destacam-se:

a) Boosting: M√©todo de aprendizado de m√°quina que cria um modelo forte por

meio da combina√ß√£o sequencial de modelos fracos. Cada novo modelo tenta

corrigir os erros dos modelos anteriores (MALIK; HARODE; KUNWAR,

2020).

b) Regulariza√ß√£o: O XGBoost incorpora penalidades ao modelo para evitar o

ajuste excessivo (overfitting), limitando a complexidade atrav√©s de

par√¢metros como profundidade m√°xima das √°rvores, penaliza√ß√£o por

complexidade (gamma) e regulariza√ß√£o dos pesos das folhas (lambda).

Essa abordagem resulta em modelos mais generaliz√°veis (CHEN;

## GUESTRIN, 2016).

c) Sparsity-aware Split Finding: Um algoritmo que otimiza o processo de

divis√£o das √°rvores levando em conta a esparsidade dos dados,

economizando recursos computacionais ao ignorar valores ausentes ou

zerados durante a constru√ß√£o das √°rvores (CHEN; GUESTRIN, 2016).

d) Paraleliza√ß√£o e computa√ß√£o distribu√≠da: O XGBoost √© projetado para ser

executado em m√∫ltiplas CPUs, permitindo o processamento paralelo dos

dados e acelerando significativamente o treinamento de grandes modelos

## (CHEN; GUESTRIN, 2016).

e) Shrinking e Column Subsampling: T√©cnicas adicionais que ajudam a

controlar a complexidade do modelo. Shrinking reduz o impacto individual

de cada √°rvore, enquanto Column Subsampling seleciona aleatoriamente

um subconjunto de atributos para cada √°rvore, aumentando a robustez e a

velocidade do modelo (CHEN; GUESTRIN, 2016).

2.5.3 Como o XGBoost prev√™ dados futuros

O funcionamento do XGBoost para previs√µes ocorre de maneira iterativa,

seguindo os passos:


---

# Page 28

28

a) Inicializa√ß√£o: O processo se inicia com a defini√ß√£o de uma previs√£o inicial,

que geralmente corresponde √† m√©dia dos valores reais presentes nos dados

de treinamento, no caso de problemas de regress√£o. Essa previs√£o inicial

serve como ponto de partida para o modelo e representa a estimativa mais

simples poss√≠vel sem considerar ainda as rela√ß√µes complexas entre as

vari√°veis (CHEN; GUESTRIN, 2016; NIELSEN, 2016).

b) C√°lculo dos res√≠duos: Ap√≥s a obten√ß√£o da previs√£o inicial, calcula-se a

diferen√ßa entre os valores previstos e os valores reais, gerando assim os

res√≠duos. Esses res√≠duos indicam o quanto o modelo atual est√° errando na

previs√£o. O objetivo do XGBoost √© reduzir esses res√≠duos a cada nova

itera√ß√£o, corrigindo gradualmente as falhas do modelo anterior (NIELSEN,

2016; ZHANG et al., 2021).

c) Treinamento iterativo das √°rvores: Em cada itera√ß√£o, uma nova √°rvore de

decis√£o √© treinada, n√£o para prever diretamente os valores finais, mas sim

para modelar os res√≠duos obtidos na etapa anterior. Ou seja, cada √°rvore

seguinte busca aprender e corrigir os erros cometidos pelo conjunto das

√°rvores anteriores, ajustando-se a padr√µes ainda n√£o capturados (XIE;

## ZHANG, 2021; NIELSEN, 2016).

d) Atualiza√ß√£o das previs√µes: As previs√µes do modelo s√£o atualizadas

somando as previs√µes das novas √°rvores treinadas √†s previs√µes

acumuladas das √°rvores anteriores. Com isso, o modelo torna-se

progressivamente mais preciso a cada ciclo, pois incorpora sucessivamente

corre√ß√µes dos erros passados. Ao final do processo, a previs√£o final √©

composta pela soma ponderada de todas as √°rvores criadas durante as

itera√ß√µes, representando assim uma combina√ß√£o de m√∫ltiplos aprendizados

parciais (CHEN; GUESTRIN, 2016; XIE; ZHANG, 2021).

A fun√ß√£o objetivo otimizada no processo √©:

ùêø(ùúë) = ‚àëùëô(ùë¶ÃÇùë¶, ùë¶ùëñ)

ùëñ

+ ‚àëŒ©(ùëìùëò)

ùëò

onde:

ùëô(ùë¶ÃÇùë¶, ùë¶ùëñ) representa a fun√ß√£o de perda (e.g., erro quadr√°tico m√©dio);


---

# Page 29

29

Œ©(ùëìùëò) representa o termo de regulariza√ß√£o que controla a complexidade

do modelo (CHEN; GUESTRIN, 2016).

2.5.4 Exemplos pr√°ticos de uso do XGBoost

a) Utilidades: Segundo Noorunnahar et al. (apud Kontopoulou et al., 2023), no

campo de utilidades, foi conduzido um estudo com o objetivo de prever a

produ√ß√£o anual de arroz em Bangladesh. Os autores compararam a

precis√£o das previs√µes feitas por um m√©todo ARIMA otimizado,

fundamentado no crit√©rio AIC, e pelo algoritmo XGBoost. Para a avalia√ß√£o

dos modelos, foram consideradas m√©tricas de erro como MAE, MPE, RMSE

e MAPE. Os resultados indicaram que o modelo XGBoost obteve um

desempenho superior em rela√ß√£o ao ARIMA no conjunto de teste,

demonstrando maior efic√°cia na previs√£o da produ√ß√£o de arroz para o

contexto analisado.

b) Previs√£o de volume de vendas no varejo: No setor de utilidades e com√©rcio,

o XGBoost tem se mostrado eficaz na previs√£o de volumes de vendas. A

pesquisa de Dairu e Shilong (2021) √© um exemplo, onde o modelo XGBoost

foi utilizado para prever o volume de vendas no varejo, comparando seus

resultados com o ARIMA cl√°ssico, o algoritmo GBDT, um modelo de LSTM

e a ferramenta de previs√£o Prophet. Os resultados desse estudo indicaram

que as abordagens baseadas em √°rvores, treinadas com caracter√≠sticas de

clima e temperatura, ofereceram o melhor desempenho de previs√£o entre os

cinco modelos, enquanto o ARIMA apresentou o pior desempenho.

Notavelmente, o XGBoost exigiu significativamente menos itera√ß√µes de

treinamento do que o GBDT e, juntamente com o GBDT, necessitou de

menos dados e recursos em contraste com os modelos de LSTM. Al√©m

disso, os autores propuseram um modelo de previs√£o de vendas baseado

em XGBoost para um conjunto de dados de bens de varejo do Walmart,

demonstrando bom desempenho com menor tempo de computa√ß√£o e

recursos de mem√≥ria.


---

# Page 30

30

## 3 METODOLOGIA

Este cap√≠tulo apresenta os procedimentos metodol√≥gicos adotados para a

realiza√ß√£o da presente pesquisa, detalhando de forma sistem√°tica as etapas que

orientaram o desenvolvimento do estudo. S√£o descritos o tipo de pesquisa, a

abordagem utilizada, os m√©todos de coleta e an√°lise dos dados, bem como os crit√©rios

que fundamentaram as escolhas metodol√≥gicas. O objetivo √© conferir transpar√™ncia e

fundamenta√ß√£o cient√≠fica ao percurso investigativo, garantindo a validade e a

confiabilidade dos resultados obtidos.

## 3.1 METODOLOGIA DE TRABALHO

Com o intuito de proporcionar uma vis√£o geral do percurso metodol√≥gico

adotado, a figura a seguir apresenta, de forma esquem√°tica, as principais etapas e

procedimentos desenvolvidos ao longo deste trabalho. O diagrama tem como objetivo

ilustrar, de maneira clara e objetiva, a estrutura metodol√≥gica geral que orientou a

condu√ß√£o da pesquisa.

Fonte: elaborado pelo autor

Figura 1 - Metodologia geral do trabalho


---

# Page 31

31

3.1.1 Defini√ß√£o do problema e objetivos da previs√£o

Este trabalho tem como ponto de partida uma necessidade pr√°tica observada

em um dos produtos desenvolvidos pela empresa onde atuo, voltado √† an√°lise e

visualiza√ß√£o de dados corporativos. Especificamente, trata-se de um dashboard

constru√≠do na ferramenta Power BI, que apresenta diversas an√°lises de desempenho,

incluindo uma medida respons√°vel por estimar o faturamento do m√™s corrente com

base nos dados registrados desde o primeiro dia do m√™s at√© o momento da consulta.

O problema que este trabalho prop√µe a investigar consiste em avaliar se √©

poss√≠vel aprimorar essa estimativa por meio da aplica√ß√£o de modelos de aprendizado

de m√°quina. Para isso, ser√£o desenvolvidos diferentes modelos preditivos utilizando

os mesmos dados utilizados atualmente no dashboard, buscando simular o contexto

real de previs√£o. Em seguida, ser√° avaliado o desempenho de cada modelo com base

em m√©tricas estat√≠sticas, e comparado o resultado mais eficaz com a previs√£o

atualmente gerada pelo Power BI.

O objetivo principal deste estudo √© verificar se algum dos modelos testados

apresenta desempenho superior ao c√°lculo de previs√£o utilizado hoje no produto da

empresa. Caso isso ocorra, a ado√ß√£o do modelo poder√° resultar em previs√µes mais

precisas e na gera√ß√£o de insights mais robustos e estrat√©gicos.

3.1.2 Coleta e pr√©-processamento dos dados

A coleta e a o pr√©-processamento dos dados utilizados neste trabalho foram

realizadas atrav√©s da ferramenta Visual Studio Code. Os dados empregados

correspondem √†s s√©ries hist√≥ricas de faturamento dispon√≠veis em um produto interno

da empresa, sendo originalmente utilizados em um dashboard desenvolvido em

Power BI.

Os dados utilizados neste estudo consistiram em registros transacionais de

vendas contendo 37.425 transa√ß√µes no per√≠odo de 2014 a 2025. Os campos principais

inclu√≠ram a data de emiss√£o do pedido, valor l√≠quido da venda, identifica√ß√£o do cliente

e tipo de opera√ß√£o comercial.

O pipeline implementado seguiu uma abordagem sistem√°tica dividida em

etapas distintas, conforme mostra figura abaixo, cada uma com objetivos espec√≠ficos

para preparar os dados para diferentes tipos de modelos de machine learning.


---

# Page 32

32

Fonte: elaborado pelo autor

3.1.2.1 Cria√ß√£o da vari√°vel target

A primeira etapa do pipeline de pr√©-processamento consistiu na defini√ß√£o e

cria√ß√£o da vari√°vel dependente para os modelos preditivos. O processo realizou a

filtragem exclusiva de transa√ß√µes classificadas como "VENDA", excluindo devolu√ß√µes

e outros tipos de opera√ß√µes comerciais.

O valor l√≠quido das vendas foi ent√£o estabelecido como vari√°vel target,

representando a quantidade que os modelos tentariam prever. Esta escolha foi

justificada pela relev√¢ncia direta do valor monet√°rio para decis√µes de neg√≥cio e

planejamento financeiro.

3.1.2.2 Cria√ß√£o de features temporais

A segunda etapa foi a implementa√ß√£o da extra√ß√£o e engenharia de

caracter√≠sticas temporais a partir da data das transa√ß√µes. Este processo foi

Figura 2 - Metodologia do pr√©-processamento


---

# Page 33

33

fundamental pois padr√µes temporais foram cruciais em previs√£o de vendas,

capturando sazonalidades, tend√™ncias e ciclos de neg√≥cio.

O sistema extraiu features lineares tradicionais como ano, m√™s, dia, dia da

semana, trimestre, dia do ano e semana do ano. Estas vari√°veis capturaram diferentes

granularidades temporais que puderam influenciar o comportamento de vendas.

Adicionalmente, implementou-se codifica√ß√£o trigonom√©trica (cyclical encoding)

para vari√°veis temporais c√≠clicas. Esta t√©cnica matem√°tica utilizou fun√ß√µes seno e

cosseno para representar a natureza circular de vari√°veis como m√™s e dia da semana.

Por exemplo, dezembro e janeiro s√£o numericamente distantes (12 e 1) mas

temporalmente adjacentes. A codifica√ß√£o trigonom√©trica preservou esta proximidade,

permitindo que os modelos compreendessem corretamente as transi√ß√µes c√≠clicas.

3.1.2.3 Tratamento de valores ausentes

O tratamento de valores ausentes foi implementado atrav√©s de estrat√©gias

diferenciadas por tipo de dados, reconhecendo que diferentes tipos de vari√°veis

requereram abordagens distintas.

Para vari√°veis categ√≥ricas, adotou-se o preenchimento com valor constante

"Desconhecido", preservando a informa√ß√£o de aus√™ncia como categoria espec√≠fica.

Esta abordagem evitou a perda de registros e permitiu que os modelos aprendessem

padr√µes associados √† aus√™ncia de informa√ß√£o.

Para vari√°veis num√©ricas, utilizou-se preenchimento com zero como valor

padr√£o, considerando que em contexto de vendas, aus√™ncia de informa√ß√£o

frequentemente indicou aus√™ncia de atividade comercial.

3.1.2.4 Remo√ß√£o de registros duplicados

A identifica√ß√£o e remo√ß√£o de duplicatas foi realizada mantendo a primeira

ocorr√™ncia de registros id√™nticos. Esta etapa foi cr√≠tica para evitar vi√©s nos modelos

causado por registros repetidos que poderiam inflar artificialmente certas

caracter√≠sticas dos dados, levando a overfitting e previs√µes incorretas.

O processo examinou todas as colunas simultaneamente para identificar

registros completamente id√™nticos, garantindo que apenas duplicatas verdadeiras

fossem removidas, preservando varia√ß√µes leg√≠timas nos dados.


---

# Page 34

34

3.1.2.5 Cria√ß√£o de features agregadas

Esta etapa implementou engenharia de caracter√≠sticas avan√ßada, criando

features derivadas que capturaram padr√µes temporais e comportamentais essenciais

para previs√£o de s√©ries temporais.

As features de lag (defasagem temporal) capturaram depend√™ncias hist√≥ricas

ao incluir valores passados como preditores. Implementaram-se lags de 1, 2, 3, 6 e

12 per√≠odos, permitindo que os modelos identificassem padr√µes de depend√™ncia

temporal em diferentes horizontes. Por exemplo, lag de 12 meses capturou

sazonalidade anual, enquanto lags menores capturaram tend√™ncias de curto prazo.

As m√©dias m√≥veis foram calculadas para janelas de 3, 6 e 12 per√≠odos,

suavizando flutua√ß√µes aleat√≥rias e destacando tend√™ncias subjacentes. Estas

features foram particularmente valiosas para modelos de machine learning que

pudessem ter dificuldade em capturar automaticamente padr√µes temporais

suavizados.

Features agregadas por cliente foram criadas calculando estat√≠sticas

descritivas do comportamento hist√≥rico de cada cliente. Estas inclu√≠ram valor m√©dio

de compras, desvio padr√£o (indicando variabilidade do comportamento), frequ√™ncia

de compras e valor total acumulado. Estas caracter√≠sticas permitiram que os modelos

personalizassem previs√µes baseadas no perfil espec√≠fico de cada cliente.

3.1.2.6 Codifica√ß√£o de vari√°veis categ√≥ricas e processo de anonimiza√ß√£o

O processo de codifica√ß√£o foi implementado de forma adaptativa baseada na

cardinalidade das vari√°veis categ√≥ricas, reconhecendo que diferentes t√©cnicas foram

apropriadas para diferentes cen√°rios.

Para vari√°veis de baixa cardinalidade (at√© 50 categorias √∫nicas), utilizou-se

One-Hot Encoding, criando vari√°veis dummy bin√°rias para cada categoria. Esta

abordagem preservou completamente a informa√ß√£o categ√≥rica sem impor rela√ß√µes

ordinais artificiais.

Para vari√°veis de alta cardinalidade (mais de 50 categorias), aplicou-se Label

Encoding, convertendo categorias para valores num√©ricos ordinais. Esta escolha

equilibrou a preserva√ß√£o de informa√ß√£o com efici√™ncia computacional, evitando


---

# Page 35

35

explos√£o dimensional que ocorreria com One-Hot Encoding em vari√°veis muito

categ√≥ricas.

O processo de anonimiza√ß√£o foi implementado utilizando fun√ß√£o de hash

criptogr√°fico MD5 para transformar identifica√ß√µes de clientes em c√≥digos an√¥nimos.

Este processo garantiu tr√™s propriedades essenciais: consist√™ncia (mesmo cliente

sempre recebeu o mesmo ID an√¥nimo), anonimiza√ß√£o irrevers√≠vel (identidade original

n√£o p√¥de ser recuperada) e formato padronizado.

O sistema gerou identificadores no formato "CLIENTE_####" onde os quatro

d√≠gitos foram derivados deterministicamente do hash do nome original. Esta

abordagem protegeu a privacidade dos clientes enquanto preservou a capacidade de

an√°lise por cliente individual.

3.1.2.7 Remo√ß√£o de colunas irrelevantes

Removeram-se colunas que se tornaram redundantes ap√≥s o processamento,

incluindo a coluna de data original (substitu√≠da por features temporais derivadas),

coluna de valor original (substitu√≠da pela vari√°vel target processada) e coluna de

opera√ß√£o (ap√≥s filtragem por vendas). Esta limpeza reduziu dimensionalidade e

eliminou informa√ß√µes redundantes que poderiam confundir os algoritmos de

aprendizado.

3.1.2.7 Aplica√ß√£o de normaliza√ß√£o

Implementou-se normaliza√ß√£o robusta das vari√°veis num√©ricas utilizando

t√©cnica baseada em mediana e quartis ao inv√©s de m√©dia e desvio padr√£o. Esta

escolha foi justificada pela resist√™ncia a outliers, particularmente importante em dados

de vendas que frequentemente apresentaram valores extremos devido a transa√ß√µes

excepcionalmente grandes ou pequenas.

A normaliza√ß√£o padronizou as escalas das diferentes vari√°veis, garantindo que

features com magnitudes diferentes contribu√≠ssem equitativamente para o

aprendizado dos modelos. Vari√°veis como a target e features temporais discretas

foram exclu√≠das da normaliza√ß√£o para preservar suas interpreta√ß√µes originais.


---

# Page 36

36

3.1.2.7 Consolida√ß√£o final dos dados

A etapa final realizou valida√ß√£o e limpeza final dos dados processados.

Qualquer valor ausente remanescente foi tratado atrav√©s de preenchimento com zero,

garantindo uma base de dados completa para os modelos.

3.1.2.8 Valida√ß√£o de qualidade dos dados

Como filtragem final, removeram-se transa√ß√µes com valores inv√°lidos (zero ou

negativos), garantindo que apenas transa√ß√µes comerciais leg√≠timas fossem utilizadas

no treinamento dos modelos. Este filtro foi aplicado com valor m√≠nimo de 0,01 reais

para eliminar registros potencialmente problem√°ticos.

3.1.2.9 Sa√≠da do processo de pr√©-processamento

O pipeline de pr√©-processamento gerou uma base de dados final otimizada

contendo aproximadamente 35.000 transa√ß√µes v√°lidas de venda, mais de 40 vari√°veis

preditoras, dados mensais agregados cobrindo per√≠odo do ano de 2014 a 2025,

formato padronizado sem valores ausentes ou duplicatas e vari√°veis normalizadas

apropriadamente para machine learning.

3.1.2.10 Formata√ß√£o espec√≠fica por tipo de modelo

Ap√≥s a conclus√£o do pipeline principal de pr√©-processamento, os dados foram

formatados de maneiras distintas para atender √†s necessidades espec√≠ficas de cada

categoria de modelo implementado neste estudo. Esta etapa foi fundamental pois

diferentes algoritmos de machine learning requerem estruturas de dados particulares

para funcionamento otimizado.

3.1.2.10.1 Formato de s√©ries temporais

Para os modelos ARIMA, Theta e Suaviza√ß√£o Exponencial, os dados foram

transformados em formato de s√©ries temporais univariadas. Este processo envolveu

a agrega√ß√£o temporal dos dados transacionais em per√≠odos mensais, utilizando a

soma dos valores de vendas como m√©todo de agrega√ß√£o.


---

# Page 37

37

O procedimento consistiu em agrupar todas as transa√ß√µes por m√™s e ano,

calculando o valor total de vendas para cada per√≠odo mensal. Esta agrega√ß√£o foi

necess√°ria pois os modelos de s√©ries temporais operam com observa√ß√µes

sequenciais regularmente espa√ßadas no tempo, diferentemente dos dados

transacionais originais que apresentavam m√∫ltiplas observa√ß√µes por per√≠odo.

A s√©rie temporal resultante apresentou frequ√™ncia mensal cobrindo o per√≠odo

completo dos dados, com cada observa√ß√£o representando o faturamento total do m√™s

correspondente.

Os dados foram ent√£o convertidos para o formato espec√≠fico da biblioteca

Darts, utilizada para implementa√ß√£o dos modelos de s√©ries temporais. Esta convers√£o

incluiu a defini√ß√£o adequada do √≠ndice temporal e a estrutura√ß√£o dos dados em objeto

TimeSeries compat√≠vel com os algoritmos implementados.

3.1.2.10.2 Formato tabular para XGBoost

Para o modelo XGBoost, os dados foram mantidos em formato tabular

expandido, preservando todas as features engenheiradas durante o pr√©-

processamento. Esta abordagem foi necess√°ria pois algoritmos de gradient boosting,

como o XGBoost, requerem m√∫ltiplas vari√°veis explicativas em formato tabular para

construir √°rvores de decis√£o.

A base de dados tabular final conteve 45+ features derivadas das etapas de

pr√©-processamento, incluindo:

a) Features temporais originais: Ano, m√™s, dia, trimestre, dia da semana, e

suas respectivas codifica√ß√µes trigonom√©tricas (seno e cosseno) para

capturar padr√µes c√≠clicos.

b) Features de depend√™ncia temporal: Lags de 1, 2, 3, 6 e 12 per√≠odos que

permitiram ao modelo acessar valores hist√≥ricos como preditores,

essenciais para capturar depend√™ncias temporais em formato tabular.

c) Features de suaviza√ß√£o: M√©dias m√≥veis calculadas para janelas de 3, 6 e

12 per√≠odos, fornecendo vers√µes suavizadas da s√©rie que destacam

tend√™ncias subjacentes.


---

# Page 38

38

d) Features estat√≠sticas: Medidas de dispers√£o como desvio padr√£o, valores

m√≠nimos e m√°ximos calculados em janelas deslizantes, capturando a

variabilidade local dos dados.

e) Features de tend√™ncia: Diferen√ßas primeiro-ordem e varia√ß√µes percentuais

que quantificaram mudan√ßas direcionais na s√©rie, permitindo ao modelo

identificar padr√µes de crescimento ou decr√©scimo.

f) Features comportamentais: Estat√≠sticas agregadas por cliente (m√©dia,

desvio padr√£o, frequ√™ncia e soma total) que personalizaram as previs√µes

baseadas no perfil hist√≥rico de cada cliente.

g) Features de intera√ß√£o: Combina√ß√µes multiplicativas entre vari√°veis

temporais (m√™s √ó ano, trimestre √ó ano) que capturaram efeitos de intera√ß√£o

temporal.

Cada linha da base de dados tabular representou uma observa√ß√£o temporal

com todas as features calculadas para aquele per√≠odo espec√≠fico. A vari√°vel target foi

mantida como coluna separada, preservando sua escala original para facilitar

interpreta√ß√£o dos resultados.

3.1.3 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal

A an√°lise explorat√≥ria de dados (EDA) constitui uma etapa fundamental no

processo de modelagem de s√©ries temporais, precedendo a aplica√ß√£o de modelos

preditivos e fornecendo insights essenciais sobre a estrutura, padr√µes e

caracter√≠sticas dos dados hist√≥ricos. Conforme destacado por Bezerra (2006), a

compreens√£o adequada do comportamento temporal dos dados √© crucial para a

sele√ß√£o e parametriza√ß√£o apropriada de modelos de previs√£o, influenciando

diretamente a qualidade e confiabilidade dos resultados obtidos.

No contexto de s√©ries temporais de vendas, a EDA assume particular

import√¢ncia devido √† complexidade inerente desses dados, que frequentemente

apresentam componentes de tend√™ncia, sazonalidade, ciclos econ√¥micos e varia√ß√µes

irregulares. Segundo Makridakis, Wheelwright e Hyndman (1999), a identifica√ß√£o

precisa desses componentes atrav√©s de t√©cnicas explorat√≥rias adequadas √©

fundamental para orientar as decis√µes metodol√≥gicas subsequentes, incluindo a


---

# Page 39

39

escolha de modelos estat√≠sticos apropriados e a defini√ß√£o de estrat√©gias de pr√©-

processamento.

3.1.3.1 Vis√£o geral da s√©rie temporal

A an√°lise explorat√≥ria foi implementada atrav√©s de um sistema automatizado

de visualiza√ß√µes desenvolvido em Python, utilizando bibliotecas especializadas em

an√°lise de s√©ries temporais. Os dados utilizados correspondem √† s√©rie temporal de

vendas mensais no per√≠odo de janeiro de 2014 a setembro de 2024, totalizando 133

observa√ß√µes ap√≥s o pr√©-processamento e agrega√ß√£o temporal mensal.

A estrutura√ß√£o dos dados seguiu as diretrizes estabelecidas por Parzen (1961),

que define uma s√©rie temporal como um conjunto de observa√ß√µes dispostas

cronologicamente, representada matematicamente como um processo estoc√°stico.

Para garantir a adequa√ß√£o dos dados √† an√°lise temporal, foi implementada uma

verifica√ß√£o rigorosa da ordena√ß√£o cronol√≥gica, tratamento de valores ausentes e

valida√ß√£o da consist√™ncia temporal.

A primeira an√°lise apresenta uma vis√£o geral abrangente da s√©rie temporal,

incluindo a evolu√ß√£o das vendas ao longo do tempo com linha de tend√™ncia,

distribui√ß√£o dos valores por ano atrav√©s de gr√°ficos de boxplot, an√°lise das vendas

acumuladas e volatilidade temporal. Esta vis√£o panor√¢mica revelou uma tend√™ncia de

crescimento consistente de 2014 a 2022, seguida por um decl√≠nio significativo entre

os anos 2023 e 2024, com valores variando de aproximadamente R$ 8 milh√µes em

2014 para um pico de R$ 400 milh√µes em 2022. A an√°lise de tend√™ncia linear mostrou

um coeficiente de determina√ß√£o (R¬≤) de 0,966, indicando que 96,6% da varia√ß√£o dos

dados √© explicada pela tend√™ncia temporal.


---

# Page 40

40

Fonte: elaborado pelo autor

3.1.3.2 Decomposi√ß√£o STL

A decomposi√ß√£o STL (Seasonal-Trend using Loess) foi aplicada para separar

os componentes estruturais da s√©rie temporal. A decomposi√ß√£o confirmou a presen√ßa

de uma tend√™ncia de longo prazo bem definida e padr√µes sazonais consistentes, com

a s√©rie original mostrando crescimento exponencial at√© 2022, seguido por decl√≠nio

acentuado. O componente sazonal revelou padr√µes regulares de varia√ß√£o mensal

com amplitude m√©dia de aproximadamente R$ 15 milh√µes, enquanto o res√≠duo indicou

per√≠odos de maior volatilidade, especialmente durante os anos de transi√ß√£o

econ√¥mica.

Figura 3 - Vis√£o geral da s√©rie temporal


---

# Page 41

41

Fonte: elaborado pelo autor

3.1.3.3 An√°lise de sazonalidade

A an√°lise sazonal detalhada examinou os padr√µes mensais e de autocorrela√ß√£o

da s√©rie temporal. Foram calculadas as m√©dias mensais hist√≥ricas, revelando que os

meses de janeiro (R$ 125 milh√µes), maio (R$ 112 milh√µes) e dezembro (R$ 118

milh√µes) apresentam consistentemente os maiores volumes de vendas, enquanto

fevereiro (R$ 87 milh√µes) e junho (R$ 94 milh√µes) mostram os menores valores. A

an√°lise de autocorrela√ß√£o identificou depend√™ncias temporais significativas at√© o lag

12, confirmando a presen√ßa de sazonalidade anual na s√©rie.

Figura 4 ‚Äì Decomposi√ß√£o da s√©rie temporal


---

# Page 42

42

Fonte: elaborado pelo autor

3.1.3.4 Propriedades estat√≠sticas

A an√°lise das propriedades estat√≠sticas incluiu o c√°lculo das fun√ß√µes de

autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial (PACF), fundamentais para a

parametriza√ß√£o de modelos ARIMA. A ACF mostrou correla√ß√µes significativas nos

primeiros lags (0,95 no lag 1), decaindo gradualmente at√© o lag 12, enquanto a PACF

apresentou cortes abruptos ap√≥s o primeiro lag (PACF‚ÇÅ = 0,95, PACF‚ÇÇ = 0,15),

sugerindo caracter√≠sticas autorregressivas na s√©rie. A an√°lise da s√©rie diferenciada

(primeira diferen√ßa) confirmou a remo√ß√£o da tend√™ncia, tornando a s√©rie mais

adequada para modelagem estat√≠stica.

Figura 5 - An√°lise da sazonalidade


---

# Page 43

43

Fonte: elaborado pelo autor

3.1.3.5 An√°lise de distribui√ß√£o

A an√°lise de distribui√ß√£o dos valores de vendas incluiu histograma com

sobreposi√ß√£o de distribui√ß√£o normal, gr√°fico Q-Q para teste de normalidade, box plot

para identifica√ß√£o de outliers, e compara√ß√£o de densidade. Os resultados indicaram

que a distribui√ß√£o das vendas n√£o segue uma distribui√ß√£o normal, apresentando

assimetria positiva (skewness = 1,85) e presen√ßa de valores extremos.

Figura 6 - Propriedades estat√≠sticas da s√©rie temporal


---

# Page 44

44

Fonte: elaborado pelo autor

3.1.3.6 Evolu√ß√£o temporal detalhada

A an√°lise de evolu√ß√£o temporal examinou as taxas de crescimento anual,

padr√µes sazonais por ano, e tend√™ncia linear geral. O c√°lculo das taxas de

crescimento revelou crescimento superior a 200% em 2015, estabiliza√ß√£o em torno

de 20 a 40% nos anos intermedi√°rios, e decl√≠nios acentuados de -15% a -48% nos

anos finais. A an√°lise de regress√£o linear confirmou a equa√ß√£o: Vendas = -2.470.000

√ó Ano + 5.000.000.000, com R¬≤ = 0,966.

Figura 7 - An√°lise de distribui√ß√£o


---

# Page 45

45

Fonte: elaborado pelo autor

3.1.3.7 An√°lise de correla√ß√£o temporal

A an√°lise de correla√ß√£o incluiu correla√ß√µes com lags de 1 a 12 meses,

autocorrela√ß√£o parcial detalhada, matriz de correla√ß√£o para lags selecionados e

correla√ß√£o com componentes temporais (ano, trimestre, m√™s). Os resultados

mostraram correla√ß√µes elevadas (>0,8) para os primeiros lags, decaindo

gradualmente at√© o lag 12. A matriz de correla√ß√£o dos lags selecionados revelou

padr√µes de depend√™ncia temporal que orientaram a configura√ß√£o dos modelos

preditivos.

Figura 8 - Evolu√ß√£o temporal das vendas


---

# Page 46

46

Fonte: elaborado pelo autor

3.1.3.8 Insights para modelagem

Com base nesta an√°lise explorat√≥ria abrangente, foram identificados os

seguintes resultados fundamentais para a modelagem preditiva:

a) Estacionariedade: A s√©rie original n√£o √© estacion√°ria devido √† forte

tend√™ncia, requerendo diferencia√ß√£o para modelos ARIMA (d = 1);

b) Sazonalidade: Presen√ßa confirmada de sazonalidade anual (per√≠odo 12)

com padr√µes consistentes;

c) Autocorrela√ß√£o: Depend√™ncias temporais significativas at√© 12 lags,

orientando a parametriza√ß√£o dos modelos;

d) Distribui√ß√£o: Dados n√£o seguem distribui√ß√£o normal;

e) Tend√™ncia: Tend√™ncia de longo prazo bem definida (R¬≤ = 0,966);

Figura 9 - An√°lise de correla√ß√£o temporal


---

# Page 47

47

f) Volatilidade: Redu√ß√£o da volatilidade ao longo do tempo, indicando maior

estabilidade nos padr√µes recentes.

Estes resultados orientaram diretamente a configura√ß√£o dos par√¢metros para

cada modelo preditivo, a escolha das t√©cnicas de pr√©-processamento espec√≠ficas, e

as estrat√©gias de valida√ß√£o temporal adotadas nas etapas subsequentes.

## 3.2 MODELOS DE PREVIS√ÉO UTILIZADOS

A modelagem preditiva √© a etapa central deste trabalho, sendo respons√°vel por

transformar os dados estruturados em previs√µes quantitativas para o faturamento do

produto analisado. Considerando as diferentes abordagens e caracter√≠sticas dos

dados, ser√£o selecionados m√∫ltiplos modelos de previs√£o, cada um com suas pr√≥prias

vantagens, desvantagens e requisitos espec√≠ficos de pr√©-processamento.

Os modelos escolhidos para este estudo incluem t√©cnicas tradicionais de s√©ries

temporais, como ARIMA e Theta, bem como algoritmos mais recentes e avan√ßados,

como XGBoost, que s√£o amplamente utilizados em aplica√ß√µes empresariais para

problemas de previs√£o com s√©ries temporais. Cada um desses modelos foi avaliado

quanto √† sua capacidade de capturar padr√µes hist√≥ricos, prever tend√™ncias futuras e

lidar com os desafios t√≠picos desse tipo de dado, como sazonalidade, tend√™ncia e

varia√ß√µes irregulares.

Para garantir uma an√°lise comparativa robusta, foram considerados fatores

como a facilidade de implementa√ß√£o, complexidade computacional e a precis√£o das

previs√µes geradas. Al√©m disso, cada modelo ser√° treinado e validado com os mesmos

conjuntos de dados, permitindo uma compara√ß√£o justa e direta de seu desempenho.

Nos subt√≥picos a seguir, cada modelo √© apresentado individualmente, incluindo

os requisitos espec√≠ficos para pr√©-processamento dos dados e o diagrama do fluxo

metodol√≥gico correspondente.


---

# Page 48

48

## 3.2.1 ARIMA

A figura a seguir mostra a metodologia utilizada para o modelo.

Fonte: elaborado pelo autor

3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente

A implementa√ß√£o do modelo ARIMA foi realizada utilizando o Visual Studio

Code como ambiente de desenvolvimento integrado, garantindo controle de vers√£o e

reprodutibilidade do c√≥digo. O ambiente Python foi configurado com as seguintes

bibliotecas essenciais:

Figura 10 - Metodologia do modelo ARIMA


---

# Page 49

49

a) Darts: Biblioteca especializada em s√©ries temporais que forneceu o m√≥dulo

AutoARIMA/SARIMA, algoritmos de sele√ß√£o autom√°tica de par√¢metros,

m√©todos de divis√£o temporal apropriados para s√©ries temporais e fun√ß√µes

integradas de avalia√ß√£o e diagn√≥stico.

b) Pandas: Utilizado para manipula√ß√£o e estrutura√ß√£o inicial dos dados,

convers√£o de tipos de dados temporais, e opera√ß√µes de agrega√ß√£o e

filtragem durante o pr√©-processamento.

c) Matplotlib e Seaborn: Empregados para gera√ß√£o de visualiza√ß√µes

diagn√≥sticas, incluindo gr√°ficos de s√©rie temporal, correlogramas, an√°lise

de res√≠duos e compara√ß√µes entre valores observados e previstos.

Esta prepara√ß√£o foi fundamental para garantir que todas as opera√ß√µes

subsequentes fossem executadas de forma padronizada e rastre√°vel.

3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal

O processo de ingest√£o iniciou com o carregamento dos dados de faturamento

mensal previamente processados na etapa 3.1.2, obtidos do arquivo CSV estruturado

com 133 observa√ß√µes mensais (janeiro 2014 a setembro 2024). Os dados foram

validados quanto √†:

a) Integridade temporal: Verifica√ß√£o de continuidade mensal sem lacunas,

confirma√ß√£o da ordena√ß√£o cronol√≥gica correta, e valida√ß√£o do formato de

datas no padr√£o ISO (YYYY-MM-DD).

b) Qualidade dos valores: Identifica√ß√£o de valores nulos, negativos ou

extremos que poderiam comprometer a modelagem, e confirma√ß√£o da

escala monet√°ria consistente (valores em reais).

c) Estrutura adequada: Configura√ß√£o do √≠ndice temporal como DatetimeIndex

do Pandas, garantindo opera√ß√µes temporais apropriadas.

A convers√£o para o objeto TimeSeries da Darts foi realizada especificando a

coluna de valores (faturamento mensal), o √≠ndice temporal (datas mensais), e a

frequ√™ncia da s√©rie ('M' para mensal). Esta estrutura otimizada permitiu que o modelo

ARIMA acessasse funcionalidades avan√ßadas como detec√ß√£o autom√°tica de


---

# Page 50

50

periodicidade sazonal, aplica√ß√£o de transforma√ß√µes temporais (diferencia√ß√£o), e

gera√ß√£o de previs√µes de forma eficiente.

3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o

A avalia√ß√£o de estacionariedade foi conduzida considerando os achados da

an√°lise explorat√≥ria que evidenciaram forte tend√™ncia n√£o linear (crescimento

exponencial at√© 2022, seguido de decl√≠nio acentuado) e padr√µes sazonais anuais

consistentes.

a) Testes de estacionariedade: Embora o AutoARIMA realize testes internos,

foram realizadas verifica√ß√µes complementares utilizando o teste ADF para

detectar a presen√ßa de raiz unit√°ria, e o teste KPSS para confirmar

estacionariedade ao redor de uma tend√™ncia determin√≠stica.

b) Estrat√©gia de diferencia√ß√£o: O AutoARIMA foi configurado para explorar

automaticamente:

a. Diferencia√ß√£o n√£o sazonal (d): Testadas ordens de 0 a 2, sendo d =

1 (primeira diferen√ßa) a mais comum para remover tend√™ncia linear,

e d = 2 para tend√™ncias mais complexas.

b. Diferencia√ß√£o sazonal (D): Avaliada com per√≠odo 12 (sazonalidade

anual), testando D = 0 (sem diferencia√ß√£o sazonal) e D = 1 (uma

diferencia√ß√£o sazonal para remover padr√µes sazonais n√£o

estacion√°rios).

O processo de diferencia√ß√£o foi crucial para transformar a s√©rie n√£o

estacion√°ria original em uma s√©rie com propriedades estat√≠sticas est√°veis, evitando

regress√µes ileg√≠timas e garantindo a validade dos pressupostos do modelo ARIMA. A

biblioteca Darts aplicou estas transforma√ß√µes de forma autom√°tica e revers√≠vel para

as previs√µes finais.


---

# Page 51

51

3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste

A divis√£o temporal foi implementada seguindo rigorosamente o princ√≠pio de

n√£o-sobreposi√ß√£o temporal, essencial para valida√ß√£o real√≠stica de modelos de s√©ries

temporais. A estrat√©gia adotada foi:

a) Conjunto de treino: Primeiros 107 meses da s√©rie (janeiro 2014 a novembro

2022), representando aproximadamente 80% dos dados dispon√≠veis. Este

per√≠odo incluiu a fase de crescimento consistente e o pico hist√≥rico das

vendas, fornecendo ao modelo informa√ß√£o suficiente sobre tend√™ncias de

longo prazo e padr√µes sazonais estabelecidos.

b) Conjunto de teste: √öltimos 26 meses da s√©rie (dezembro 2022 a setembro

2024), correspondendo a aproximadamente 20% dos dados. Este per√≠odo

capturou a fase de decl√≠nio das vendas, representando um desafio real de

generaliza√ß√£o para o modelo.

c) Justificativa da divis√£o: A propor√ß√£o 80/20 foi escolhida para garantir

quantidade suficiente de dados para o treinamento (especialmente

importante para capturar m√∫ltiplos ciclos sazonais anuais), ao mesmo

tempo que preservou um horizonte de teste representativo para avaliar

performance preditiva em condi√ß√µes adversas.

A implementa√ß√£o utilizou m√©todos da Darts, que garantiu preserva√ß√£o da

estrutura temporal e evitou vazamento de informa√ß√µes futuras para o conjunto de

treino.

3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q

A parametriza√ß√£o do modelo foi conduzida atrav√©s do AutoARIMA da Darts,

que implementou uma busca sistem√°tica e otimizada pelos melhores par√¢metros

SARIMA(p,d,q)(P,D,Q)s. Os par√¢metros foram definidos como:


---

# Page 52

52

a) Par√¢metros n√£o sazonais:

a. p (ordem autorregressiva): N√∫mero de lags da s√©rie defasada

utilizados como preditores. Testadas ordens de 0 a 5, onde p = 1

indica depend√™ncia do valor anterior, p = 2 inclui os dois valores

anteriores etc.

b. d (ordem de diferencia√ß√£o): N√∫mero de diferencia√ß√µes aplicadas

para tornar a s√©rie estacion√°ria. Avaliadas ordens de 0 a 2, baseadas

nos testes de estacionariedade.

c. q (ordem de m√©dia m√≥vel): N√∫mero de erros de previs√£o defasados

inclu√≠dos no modelo. Testadas ordens de 0 a 5, capturando

depend√™ncias nos termos de erro.

b) Par√¢metros sazonais (per√≠odo s = 12):

a. P (autorregressivo sazonal): Depend√™ncia de valores sazonais

defasados (ex.: mesmo m√™s do ano anterior). Testadas ordens de 0

a 2.

b. D (diferencia√ß√£o sazonal): Diferencia√ß√£o aplicada com per√≠odo

sazonal para remover n√£o estacionariedade sazonal. Avaliadas

ordens de 0 a 1.

c. Q (m√©dia m√≥vel sazonal): Erros sazonais defasados inclu√≠dos no

modelo. Testadas ordens de 0 a 2.

Para crit√©rio de sele√ß√£o, o AutoARIMA utilizou o AIC para balancear qualidade

do ajuste com parcim√¥nia do modelo, selecionando automaticamente a configura√ß√£o

que minimizou o AIC. O algoritmo implementou busca stepwise para efici√™ncia

computacional, explorando configura√ß√µes vizinhas de forma inteligente.

3.2.1.6 Treinamento do modelo

O processo de treinamento foi executado ap√≥s a sele√ß√£o autom√°tica dos

melhores par√¢metros utilizando os algoritmos de estima√ß√£o implementados na Darts.

O treinamento envolveu:


---

# Page 53

53

a) Estima√ß√£o por m√°xima verossimilhan√ßa: Os coeficientes do modelo foram

estimados atrav√©s da maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa, que

encontrou os par√¢metros que melhor explicaram os dados observados no

conjunto de treino.

b) Otimiza√ß√£o num√©rica: O processo utilizou algoritmos de otimiza√ß√£o n√£o

linear para encontrar os valores √≥timos dos coeficientes, iniciando de

valores iniciais estimados e iterando at√© converg√™ncia.

c) Ajuste

da

componente

sazonal:

## O

modelo

## SARIMA

ajustou

simultaneamente os padr√µes n√£o sazonais (tend√™ncia de curto prazo,

depend√™ncias de lags pr√≥ximos) e sazonais (padr√µes anuais, depend√™ncias

de per√≠odos equivalentes em anos anteriores).

d) Valida√ß√£o do ajuste: Durante o treinamento, foram monitoradas m√©tricas de

converg√™ncia e estabilidade dos coeficientes estimados para garantir

adequa√ß√£o do processo de otimiza√ß√£o.

O resultado foi um modelo completamente parametrizado, capaz de capturar

tanto as depend√™ncias temporais de curto prazo quanto os padr√µes sazonais anuais

identificados na an√°lise explorat√≥ria.

3.2.1.7 Valida√ß√£o do modelo e ajustes finos

A etapa de valida√ß√£o consistiu na gera√ß√£o de previs√µes para todo o horizonte

do conjunto de teste (26 per√≠odos futuros) e avalia√ß√£o sistem√°tica da performance

preditiva:

a) Gera√ß√£o de previs√µes: O modelo treinado foi utilizado para produzir

previs√µes recursivas, onde cada previs√£o utilizou apenas informa√ß√µes

dispon√≠veis at√© aquele ponto temporal. Este processo simulou fielmente o

cen√°rio real de previs√£o operacional.

b) Intervalos de confian√ßa: Foram gerados intervalos de previs√£o (tipicamente

95% de confian√ßa) baseados na vari√¢ncia estimada dos erros do modelo,

fornecendo medida de incerteza associada a cada previs√£o.

c) M√©tricas de avalia√ß√£o: A performance foi avaliada atrav√©s do conjunto

padronizado de m√©tricas:


---

# Page 54

54

a. MAE: Erro absoluto m√©dio em reais, interpret√°vel diretamente na

escala do problema.

b. RMSE: Raiz do erro quadr√°tico m√©dio, penalizando mais fortemente

grandes desvios.

c. MAPE: Erro percentual absoluto m√©dio, permitindo interpreta√ß√£o

relativa independente da escala.

d. R¬≤: Coeficiente de determina√ß√£o, medindo propor√ß√£o da vari√¢ncia

explicada pelo modelo.

e. Acur√°cia Direcional: Propor√ß√£o de acertos na dire√ß√£o de varia√ß√£o

(crescimento/decrescimento) entre per√≠odos consecutivos.

d) An√°lise temporal das previs√µes: Foi conduzida an√°lise per√≠odo a per√≠odo

para identificar padr√µes nos erros, sazonalidade residual, e performance

diferencial ao longo do horizonte de previs√£o.

3.2.1.8 An√°lise residual

Uma an√°lise detalhada dos res√≠duos do modelo foi conduzida para verificar se

os erros de previs√£o se distribu√≠ram de forma aleat√≥ria, sem padr√µes sistem√°ticos n√£o

modelados. Foram gerados gr√°ficos de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial

(PACF) dos res√≠duos, buscando confirmar comportamento pr√≥ximo ao ru√≠do branco.

Res√≠duos com padr√µes significativos indicaram que o modelo n√£o conseguiu

capturar completamente as rela√ß√µes temporais nos dados. Adicionalmente, a an√°lise

incluiu inspe√ß√£o visual da distribui√ß√£o dos res√≠duos e identifica√ß√£o de outliers ou

eventos at√≠picos que poderiam comprometer a precis√£o das previs√µes futuras. Esta

valida√ß√£o foi essencial para confirmar a adequa√ß√£o do modelo selecionado.

3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura

Foram geradas visualiza√ß√µes espec√≠ficas para documentar o desempenho do

modelo ARIMA, incluindo gr√°ficos de s√©rie temporal comparando valores observados

e previstos, an√°lise de res√≠duos ao longo do tempo e representa√ß√£o gr√°fica da

estrutura de correla√ß√£o do conjunto de dados para diagn√≥stico.


---

# Page 55

55

Os resultados do modelo ARIMA, incluindo previs√µes, m√©tricas de

desempenho, par√¢metros selecionados e diagn√≥sticos foram salvos de forma

estruturada para posterior compara√ß√£o com os demais modelos (Theta, Suaviza√ß√£o

Exponencial e XGBoost) e com as previs√µes atualmente utilizadas no Power BI. Esta

documenta√ß√£o foi essencial para a an√°lise comparativa final e escolha da abordagem

preditiva mais adequada ao contexto empresarial.

3.2.2 Suaviza√ß√£o Exponencial

A figura a seguir mostra a metodologia utilizada para o modelo.

Fonte: elaborado pelo autor

Figura 11 ‚Äì Metodologia do modelo Suaviza√ß√£o Exponencial


---

# Page 56

56

O modelo de Suaviza√ß√£o Exponencial compartilhou grande parte da

metodologia com o ARIMA, diferindo principalmente na abordagem de modelagem e

nos crit√©rios de sele√ß√£o do modelo. As etapas de importa√ß√£o de bibliotecas, ingest√£o

e convers√£o de dados e a divis√£o treino/teste foram executadas de forma id√™ntica ao

ARIMA, utilizando a mesma biblioteca Darts, mesma estrutura TimeSeries, e mesma

propor√ß√£o 80/20 com divis√£o temporal rigorosa.

3.2.2.1 An√°lise de componentes para sele√ß√£o do modelo

Diferentemente do ARIMA, que se baseou em testes de estacionariedade e

an√°lise de correlogramas, o modelo de Suaviza√ß√£o Exponencial utilizou os resultados

da decomposi√ß√£o STL j√° realizada na an√°lise explorat√≥ria para orientar a sele√ß√£o do

tipo apropriado de modelo.

Com base nos componentes j√° extra√≠dos na EDA, foram calculadas m√©tricas

quantitativas espec√≠ficas para Suaviza√ß√£o Exponencial:

a) For√ßa da tend√™ncia: Este c√°lculo utilizou os componentes da decomposi√ß√£o

STL previamente realizada.

b) For√ßa da sazonalidade: Novamente utilizando os resultados da EDA.

c) L√≥gica de sele√ß√£o autom√°tica: A biblioteca Darts implementou crit√©rios

autom√°ticos para escolha entre:

a. Suaviza√ß√£o Exponencial Simples (SES): Para s√©ries sem tend√™ncia

ou sazonalidade significativas

b. M√©todo de Holt: Para s√©ries com tend√™ncia forte, mas sazonalidade

fraca

c. M√©todo de Holt-Winters: Para s√©ries com ambos os componentes

significativos (caso esperado desta s√©rie)


---

# Page 57

57

3.2.2.2 Decis√£o entre modelo aditivo e multiplicativo

Uma etapa espec√≠fica da Suaviza√ß√£o Exponencial foi a escolha entre formula√ß√µes

aditiva e multiplicativa, baseada na an√°lise dos componentes sazonais da EDA:

a) Modelo Aditivo: Selecionado quando a amplitude da sazonalidade

permaneceu relativamente constante ao longo do tempo.

b) Modelo Multiplicativo: Selecionado quando a amplitude da sazonalidade

variou proporcionalmente ao n√≠vel da s√©rie.

A decis√£o foi automatizada pela Darts baseada na an√°lise da vari√¢ncia relativa

dos componentes sazonais j√° extra√≠dos na EDA, evitando recompila√ß√£o

desnecess√°ria.

3.2.2.3 Configura√ß√£o e otimiza√ß√£o de par√¢metros

Ao contr√°rio do ARIMA, que utilizou par√¢metros discretos (p, d, q), a Suaviza√ß√£o

Exponencial otimizou par√¢metros cont√≠nuos de suaviza√ß√£o:

a) Par√¢metros do modelo Holt-Winters:

a. Œ± (alfa): Par√¢metro de suaviza√ß√£o do n√≠vel (0 < Œ± ‚â§ 1)

b. Œ≤ (beta): Par√¢metro de suaviza√ß√£o da tend√™ncia (0 ‚â§ Œ≤ ‚â§ 1)

c. Œ≥ (gama): Par√¢metro de suaviza√ß√£o sazonal (0 ‚â§ Œ≥ ‚â§ 1)

b) Per√≠odo sazonal: Fixado em 12 meses conforme evidenciado na EDA

c) Processo de otimiza√ß√£o: A Darts utilizou algoritmos de minimiza√ß√£o

num√©rica para encontrar os valores √≥timos que minimizaram o erro

quadr√°tico m√©dio no conjunto de treino, diferindo do crit√©rio AIC usado no

## ARIMA.


---

# Page 58

58

3.2.2.4 Treinamento por suaviza√ß√£o recursiva

## O

processo

de

treinamento

diferiu

fundamentalmente

do

## ARIMA

por

utilizar suaviza√ß√£o exponencial recursiva ao inv√©s de estima√ß√£o de m√°xima

verossimilhan√ßa:

a) Inicializa√ß√£o dos componentes:

a. N√≠vel inicial: Estimado como m√©dia dos primeiros per√≠odos

b. Tend√™ncia inicial: Calculada como diferen√ßa m√©dia inicial

b) √çndices sazonais: Estimados atrav√©s dos primeiros ciclos da s√©rie

c) Atualiza√ß√£o recursiva: Para cada per√≠odo t do treino, os componentes foram

atualizados:

a. N√≠vel suavizado atrav√©s de combina√ß√£o ponderada do valor

observado e n√≠vel anterior projetado

b. Tend√™ncia suavizada atrav√©s de combina√ß√£o da diferen√ßa de n√≠vel

recente e tend√™ncia anterior

c. √çndice sazonal atualizado com base no desvio sazonal observado

Este processo iterativo permitiu ao modelo adaptar-se gradualmente aos

padr√µes, diferindo da estima√ß√£o simult√¢nea de todos os par√¢metros no ARIMA.

3.2.2.5 Gera√ß√£o de previs√µes diretas

A gera√ß√£o de previs√µes na Suaviza√ß√£o Exponencial utilizou abordagem direta (n√£o

recursiva) baseada nos componentes finais:

1. Mec√¢nica de previs√£o: Para cada horizonte h:

a. N√≠vel futuro projetado adicionando tend√™ncia √ó h ao √∫ltimo n√≠vel

b. Componente sazonal obtido do √≠ndice correspondente ao per√≠odo do

ano

c. Previs√£o final atrav√©s de combina√ß√£o aditiva ou multiplicativa


---

# Page 59

59

Esta abordagem diferiu das previs√µes recursivas do ARIMA, sendo mais

apropriada para modelos de suaviza√ß√£o.

3.2.2.6 An√°lise residual espec√≠fica para suaviza√ß√£o

A an√°lise residual seguiu protocolo similar ao ARIMA (se√ß√£o 3.2.1.8), mas com focos

espec√≠ficos:

a) Valida√ß√£o de componentes: Al√©m da an√°lise de aleatoriedade dos res√≠duos,

foi verificada a tend√™ncia e sazonalidade.

b) Estabilidade dos par√¢metros: Foram analisados os valores otimizados de Œ±,

Œ≤ e Œ≥ para confirmar estabilidade num√©rica (valores n√£o pr√≥ximos aos limites

0 ou 1, que indicariam problemas de converg√™ncia).

c) Adequa√ß√£o do modelo selecionado: Foi confirmada a escolha entre

aditivo/multiplicativo atrav√©s de an√°lise visual dos res√≠duos padronizados e

m√©tricas de ajuste.

3.2.3 Theta

O modelo Theta compartilhou as etapas fundamentais de prepara√ß√£o com os

modelos anteriores, diferindo principalmente na abordagem de decomposi√ß√£o e

extrapola√ß√£o. As etapas de importa√ß√£o de bibliotecas, ingest√£o e convers√£o de dados

e divis√£o treino/teste foram executadas de forma id√™ntica ao ARIMA, utilizando a

mesma biblioteca Darts, mesma estrutura TimeSeries, e mesma divis√£o temporal

80/20.

A figura a seguir mostra a metodologia utilizada para o modelo.


---

# Page 60

60

Fonte: elaborado pelo autor

3.2.3.1 Verifica√ß√£o de pr√©-condi√ß√µes do m√©todo Theta

O m√©todo Theta na biblioteca Darts exigiu verifica√ß√µes espec√≠ficas antes da aplica√ß√£o,

diferindo dos modelos anteriores:

a) Valida√ß√£o da s√©rie temporal: Foi confirmada a aus√™ncia de valores nulos na

s√©rie, pois o Theta da Darts n√£o possui tratamento autom√°tico para dados

Figura 12 ‚Äì Metodologia do modelo Theta


---

# Page 61

61

ausentes, diferentemente do ARIMA que pode interpolar valores durante o

ajuste.

b) Verifica√ß√£o de univari√¢ncia: O m√©todo foi aplicado exclusivamente √† s√©rie

temporal univariada de faturamento mensal, sem vari√°veis explicativas

adicionais,

seguindo

a

natureza

original

do

m√©todo

proposto

por Assimakopoulos e Nikolopoulos (2000).

c) Confirma√ß√£o de regularidade temporal: Foi verificada a frequ√™ncia mensal

constante da s√©rie (133 observa√ß√µes consecutivas), requisito para a

decomposi√ß√£o Theta funcionar adequadamente.

3.2.3.2 Configura√ß√£o autom√°tica vs. manual do modelo

O m√©todo Theta da Darts ofereceu configura√ß√£o totalmente autom√°tica:

a) Par√¢metro Theta (Œ∏): A Darts implementou sele√ß√£o autom√°tica do par√¢metro

Œ∏, que controla a curvatura das linhas Theta. Valores Œ∏ < 1 enfatizam

tend√™ncias de longo prazo, enquanto Œ∏ > 1 destacam varia√ß√µes de curto

prazo, conforme Spiliotis, Assimakopoulos e Makridakis (2020).

b) Detec√ß√£o autom√°tica de sazonalidade: O Theta detectou automaticamente

a presen√ßa e o per√≠odo da sazonalidade (12 meses) com base nos padr√µes

da s√©rie.

c) Configura√ß√£o de decomposi√ß√£o: O modelo foi configurado para aplicar

decomposi√ß√£o autom√°tica da s√©rie em componentes Theta, sem

necessidade de especifica√ß√£o manual de ordens ou tipos de componentes.

3.2.3.3 Decomposi√ß√£o e cria√ß√£o das linhas Theta

Esta etapa foi espec√≠fica do m√©todo Theta e diferiu fundamentalmente dos outros

modelos:


---

# Page 62

62

a) Aplica√ß√£o das segundas diferen√ßas: O m√©todo aplicou o operador de

segundas diferen√ßas √† s√©rie original conforme a formula√ß√£o matem√°tica

de Assimakopoulos e Nikolopoulos (2000).

b) Gera√ß√£o das linhas Theta: Foram criadas m√∫ltiplas linhas Theta atrav√©s de

transforma√ß√µes matem√°ticas.

c) Extra√ß√£o de componentes: O processo extraiu automaticamente:

a. Linha Theta 0 (Œ∏ = 0): Representa tend√™ncia linear de longo prazo

b. Linha Theta 2 (Œ∏ = 2): Captura varia√ß√µes de curto prazo e

sazonalidade

c. Linhas

intermedi√°rias:

Quando

aplic√°vel,

para

capturar

caracter√≠sticas espec√≠ficas da s√©rie

3.2.3.4 Treinamento e ajuste das componentes

O processo de treinamento do Theta diferiu dos modelos de suaviza√ß√£o exponencial

e ARIMA:

a) Ajuste das linhas individuais: Cada linha Theta foi ajustada separadamente

utilizando m√©todos apropriados:

a. Linha Theta 0: Ajustada por regress√£o linear para capturar tend√™ncia

de longo prazo

b. Linha Theta 2: Ajustada por Suaviza√ß√£o Exponencial Simples (SES)

para varia√ß√µes de curto prazo

b) Otimiza√ß√£o autom√°tica: A Darts implementou otimiza√ß√£o autom√°tica dos

par√¢metros de cada componente, incluindo constantes de suaviza√ß√£o para

as linhas de curto prazo e coeficientes de tend√™ncia para linhas de longo

prazo.

c) Valida√ß√£o da decomposi√ß√£o: O processo verificou a adequa√ß√£o da

decomposi√ß√£o atrav√©s de an√°lise dos componentes extra√≠dos e sua

capacidade de reconstruir a s√©rie original.


---

# Page 63

63

3.2.3.5 Combina√ß√£o de previs√µes e extrapola√ß√£o

A gera√ß√£o de previs√µes seguiu abordagem √∫nica de combina√ß√£o de extrapola√ß√µes:

a) Extrapola√ß√£o individual: Cada linha Theta foi extrapolada separadamente

para o horizonte de teste:

a. Tend√™ncia de longo prazo: Extrapolada linearmente baseada na

linha Theta 0

b. Componente de curto prazo: Extrapolada atrav√©s do √∫ltimo n√≠vel

suavizado da linha Theta 2

b) Combina√ß√£o ponderada: As previs√µes finais foram obtidas atrav√©s de

combina√ß√£o das extrapola√ß√µes individuais, tipicamente com pesos iguais

(0,5 para cada componente) ou pesos otimizados baseados na performance

hist√≥rica, seguindo Fiorucci et al. (2016).

c) Tratamento de sazonalidade: Quando presente, a sazonalidade foi

incorporada atrav√©s da extrapola√ß√£o da linha Theta 2, que capturou padr√µes

de curto prazo incluindo varia√ß√µes sazonais.

3.2.3.6 Avalia√ß√£o e diagn√≥sticos espec√≠ficos

A avalia√ß√£o seguiu protocolo similar aos modelos anteriores, com an√°lises

espec√≠ficas:

a) Valida√ß√£o das linhas Theta: Foi verificada a adequa√ß√£o da decomposi√ß√£o

atrav√©s de:

a. An√°lise da suavidade das linhas extra√≠das

b. Verifica√ß√£o da capacidade de reconstru√ß√£o da s√©rie original

c. Avalia√ß√£o da interpretabilidade das componentes (tend√™ncia vs.

varia√ß√µes)


---

# Page 64

64

d. An√°lise de estabilidade: Foram examinados os par√¢metros

otimizados de cada linha para confirmar converg√™ncia e estabilidade

num√©rica.

3.2.4 XGBoost

A figura 3 mostra a metodologia utilizada para o modelo.

Fonte: elaborado pelo autor

Figura 13 ‚Äì Metodologia do modelo XGBoost


---

# Page 65

65

3.2.4.1 Prepara√ß√£o e engenharia de vari√°veis

Diferentemente do ARIMA, cuja entrada √© a pr√≥pria s√©rie temporal univariada,

o XGBoost exige que a s√©rie seja transformada em uma base tabular. Ser√£o criadas

vari√°veis defasadas, m√©dias m√≥veis e estat√≠sticas que descrevam a s√©rie ao longo do

tempo. Al√©m disso, poder√£o ser adicionadas vari√°veis de calend√°rio (m√™s, dia da

semana, feriados etc.), enriquecendo o conjunto de treinamento com informa√ß√µes

contextuais. Esta etapa √© exclusiva e essencial para o XGBoost, pois permite ao

modelo explorar depend√™ncias temporais e efeitos sazonais/ex√≥genos.

3.2.4.2 Divis√£o dos dados em treino e teste

Assim como no ARIMA, os dados ser√£o divididos em conjuntos de treino e

teste, sempre respeitando a ordem cronol√≥gica para evitar vazamento de informa√ß√µes

futuras.

3.2.4.3 Normaliza√ß√£o e tratamento dos dados

Esta etapa, embora similar √† limpeza realizada no ARIMA, ser√° orientada para

o contexto tabular. Ser√£o tratados valores ausentes gerados na cria√ß√£o de lags e

m√©dias m√≥veis por meio de imputa√ß√£o ou exclus√£o. Se necess√°rio, as vari√°veis

poder√£o ser normalizadas ou padronizadas para garantir melhor desempenho do

algoritmo.

3.2.4.4 Configura√ß√£o dos hiper par√¢metros iniciais

Diferentemente do ARIMA, em que os par√¢metros de configura√ß√£o s√£o (p, d, q)

definidos com base em an√°lise de autocorrela√ß√£o da pr√≥pria s√©rie temporal, o modelo

XGBoost depende de um conjunto mais amplo de hiper par√¢metros que controlam

tanto a complexidade quanto o desempenho do algoritmo de √°rvores de decis√£o.

Entre os principais hiper par√¢metros que dever√£o ser configurados inicialmente,

destacam-se:

a) n_estimators (n√∫mero de √°rvores): Define quantas √°rvores de decis√£o ser√£o

criadas e combinadas pelo modelo.


---

# Page 66

66

b) max_depth (profundidade m√°xima): Limita a quantidade de divis√µes que

cada √°rvore pode fazer, afetando a capacidade de capturar padr√µes

complexos sem sobre ajuste.

c) learning_rate (taxa de aprendizado): Controla o peso de cada nova √°rvore

adicionada no processo de boosting, influenciando diretamente a velocidade

e a estabilidade do treinamento.

d) subsample (amostragem): Determina a fra√ß√£o de exemplos utilizados para

treinar cada √°rvore, o que pode aumentar a generaliza√ß√£o do modelo.

e) colsample_bytree: Define a propor√ß√£o de vari√°veis consideradas em cada

divis√£o, reduzindo a chance de sobre ajuste.

A sele√ß√£o inicial desses hiper par√¢metros poder√£o ser realizadas com base em

estudos pr√©vios, valores sugeridos na literatura ou ainda com valores padr√£o do

pr√≥prio XGBoost. √â importante salientar que, diferentemente do ARIMA, o XGBoost

permite grande flexibilidade na escolha e combina√ß√£o desses hiper par√¢metros,

tornando o processo de ajuste potencialmente mais complexo e exigente em termos

de experimenta√ß√£o.

3.2.4.5 Treinamento inicial do modelo

O processo de treinamento inicial do XGBoost se diferencia substancialmente

do ARIMA, principalmente pela estrutura dos dados e pelo mecanismo de

aprendizado.

Enquanto o ARIMA utiliza uma s√©rie temporal univariada e ajusta seus

par√¢metros para capturar padr√µes autorregressivos e de m√©dia m√≥vel, o XGBoost ir√°

trabalhar sobre uma base tabular composta por m√∫ltiplas features, incluindo vari√°veis

defasadas (lags), m√©dias m√≥veis, vari√°veis sazonais e de calend√°rio, entre outras. O

modelo ser√° treinado utilizando o conjunto de treino previamente definido, buscando

construir sucessivas √°rvores de decis√£o (de acordo com o n√∫mero definido em

n_estimators) que, em conjunto, minimizar√£o o erro de previs√£o.

Durante esse processo, cada nova √°rvore ser√° constru√≠da para corrigir os erros

cometidos pelas √°rvores anteriores, em um procedimento iterativo chamado boosting.

O ajuste do modelo ser√° realizado at√© que todos os dados de treino tenham sido


---

# Page 67

67

utilizados para aprender os padr√µes relevantes da s√©rie temporal e de suas vari√°veis

derivadas.

Ao final do treinamento inicial, o modelo estar√° preparado para realizar

previs√µes sobre o conjunto de teste, e os resultados obtidos servir√£o como base para

a avalia√ß√£o inicial de desempenho e para eventuais ajustes de hiper par√¢metros em

etapas subsequentes.

3.2.4.6 Avalia√ß√£o inicial de desempenho

A avalia√ß√£o do desempenho inicial ser√° realizada de maneira an√°loga ao

ARIMA, por meio de m√©tricas como RMSE, MAE ou MAPE, aplicadas ao conjunto de

teste. A an√°lise dos erros tamb√©m poder√° indicar a necessidade de ajuste nas features

ou nos hiper par√¢metros.

3.2.4.7 Busca e ajuste de hiper par√¢metros

Enquanto o ajuste de par√¢metros do ARIMA envolve os valores de p, d, q, no

XGBoost ser√° realizada uma busca sistem√°tica para identificar os melhores hiper

par√¢metros do modelo, como taxa de aprendizado, n√∫mero de √°rvores e profundidade

m√°xima.

3.2.4.8 Valida√ß√£o cruzada e an√°lise de resultados

Assim como no ARIMA, ser√° empregada valida√ß√£o cruzada adequada a s√©ries

temporais, assegurando a robustez dos resultados e a aus√™ncia de sobre ajuste. Os

resultados da valida√ß√£o ser√£o analisados quanto √† consist√™ncia e poss√≠veis padr√µes

residuais.

3.2.4.9 Gera√ß√£o das previs√µes finais e armazenamento dos resultados

Por fim, as previs√µes finais geradas pelo modelo XGBoost ser√£o armazenadas

para compara√ß√£o direta com os resultados do ARIMA, dos demais modelos avaliados

e com as previs√µes atualmente geradas pelo Power BI.


---

# Page 68

68

## 3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS

Ap√≥s o ajuste e valida√ß√£o de todos os modelos preditivos considerados neste

trabalho, ser√° realizada uma compara√ß√£o quantitativa do desempenho de cada

modelo utilizando as seguintes m√©tricas estat√≠sticas, recomendadas pela literatura

para problemas de previs√£o de s√©ries temporais:

a) Erro M√©dio Absoluto (MAE);

b) Raiz do Erro Quadr√°tico M√©dio (RMSE);

c) Erro Percentual Absoluto M√©dio (MAPE).

Essas m√©tricas ser√£o calculadas para o conjunto de teste de cada modelo. O

modelo que apresentar o menor valor de erro (considerando principalmente MAE e

RMSE), ser√° selecionado como o modelo de melhor desempenho, conforme

abordagem utilizada por Hyndman et al. (1999) e Gardner (1985).

Na sequ√™ncia, o modelo de melhor desempenho ser√° comparado diretamente

ao m√©todo de previs√£o atualmente empregado no Power BI. Essa compara√ß√£o ser√°

realizada utilizando as mesmas m√©tricas, com o objetivo de identificar se a abordagem

baseada em aprendizado de m√°quina ou m√©todos estat√≠sticos apresenta ganhos

significativos de acur√°cia em rela√ß√£o √† solu√ß√£o j√° adotada no produto da empresa.

A escolha final do modelo ser√° baseada n√£o apenas no desempenho

quantitativo, mas tamb√©m na sua viabilidade de implementa√ß√£o e integra√ß√£o √†

plataforma existente, conforme recomendam Gardner (1985) e Hyndman et al. (1999).


---

# Page 69

69

## REFER√äNCIAS

ASSIMAKOPOULOS, V.; NIKOLOPOULOS, K. The Theta model: a decomposition

approach to forecasting. International Journal of Forecasting, v. 16, n. 4, p. 521‚Äì

530, out. 2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00066-2.

BEZERRA, Manoel Ivanildo Silvestre. Apostila de An√°lise de S√©ries Temporais.

S√£o Paulo: UNESP, 2006. Dispon√≠vel em:

https://www.ibilce.unesp.br/Home/Departamentos/MatematicaEstatistica/apostila_ser

ies_temporais_unesp.pdf.

BOX, G. E. P. et al. Time series analysis: forecasting and control. Hoboken, New

Jersey: John Wiley & Sons, 2015.

CHEN, T.; GUESTRIN, C. XGBoost: a Scalable Tree Boosting System. Proceedings

of the 22nd ACM SIGKDD International Conference on Knowledge Discovery

and Data Mining - KDD ‚Äô16, v. 1, n. 1, p. 785‚Äì794, 13 ago. 2016. Dispon√≠vel em:

https://doi.org/10.1145/2939672.2939785.


---

# Page 70

70

DAIRU, X.; SHILONG, Z. Machine Learning Model for Sales Forecasting by

Using XGBoost. Dispon√≠vel em:

https://doi.org/10.1109/ICCECE51280.2021.9342304.

ENSAFI, Y. et al. Time-series forecasting of seasonal items sales using machine

learning ‚Äì A comparative analysis. International Journal of Information

Management Data Insights, v. 2, n. 1, p. 100058, abr. 2022. Dispon√≠vel em:

https://doi.org/10.1016/j.jjimei.2022.100058.

FATTAH, J. et al. Forecasting of demand using ARIMA model. International Journal

of Engineering Business Management, v. 10, n. 1, p. 184797901880867, jan.

2018. Dispon√≠vel em: https://journals.sagepub.com/doi/10.1177/1847979018808673.

FIORUCCI, J. A. et al. Models for optimising the theta method and their relationship

to state space models. International Journal of Forecasting, v. 32, n. 4, p. 1151‚Äì

1161, out. 2016. Dispon√≠vel em: https://doi.org/10.1016/j.ijforecast.2016.02.005.

FOURKIOTIS, K. P.; TSADIRAS, A. Applying Machine Learning and Statistical

Forecasting Methods for Enhancing Pharmaceutical Sales Predictions. Forecasting,

v. 6, n. 1, p. 170‚Äì186, 1 mar. 2024. Dispon√≠vel em:

https://doi.org/10.3390/forecast6010010.

GARDNER, E. S. Exponential smoothing: The state of the art. Journal of

Forecasting, v. 4, n. 1, p. 1‚Äì28, 1985. Dispon√≠vel em:

https://doi.org/10.1002/for.3980040103.

KONTOPOULOU, V. I. et al. A Review of ARIMA vs. Machine Learning Approaches

for Time Series Forecasting in Data Driven Networks. Future Internet, v. 15, n. 8, p.

255, 1 ago. 2023. Dispon√≠vel em: https://doi.org/10.3390/fi15080255.

LOZIA, Z. Application of modelling and simulation to evaluate the theta method used

in diagnostics of automotive shock absorbers. The Archives of Automotive


---

# Page 71

71

Engineering ‚Äì Archiwum Motoryzacji, v. 96, n. 2, p. 5‚Äì30, 30 jun. 2022. Dispon√≠vel

em: https://doi.org/10.14669/AM/150823.

MAKRIDAKIS, S.; HIBON, M. The M3-Competition: results, conclusions and

implications. International Journal of Forecasting, v. 16, n. 4, p. 451‚Äì476, out.

2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00057-1.

MAKRIDAKIS, S.; WHEELWRIGHT, S. C.; HYNDMAN, R. J. Forecasting: Methods

and Applications. In: Elements of Forecasting. Oxfordshire: Taylor & Francis, 1999.

p. 345‚Äì346. Dispon√≠vel em:

https://www.researchgate.net/publication/52008212_Forecasting_Methods_and_Appl

ications.

MALIK, Shubham; HARODE, Rohan; KUNWAR, Akash Singh. XGBoost: a deep

dive into boosting. Medium Blog, 2020. Dispon√≠vel em:

http://dx.doi.org/10.13140/RG.2.2.15243.64803.

MCKENZIE, ED. General exponential smoothing and the equivalent arma

process. Journal of Forecasting, v. 3, n. 3, p. 333‚Äì344, jul. 1984. Dispon√≠vel em:

https://doi.org/10.1002/for.3980030312.

MONDAL, P.; SHIT, L.; GOSWAMI, S. Study of Effectiveness of Time Series

Modeling (Arima) in Forecasting Stock Prices. International Journal of Computer

Science, Engineering and Applications, v. 4, n. 2, p. 13‚Äì29, 30 abr. 2014.

Dispon√≠vel em: https://doi.org/10.5121/ijcsea.2014.4202.

MURAT, M. et al. Forecasting daily meteorological time series using ARIMA and

regression models. International Agrophysics, v. 32, n. 2, p. 253‚Äì264, 1 abr. 2018.

Dispon√≠vel em: https://doi.org/10.1515/intag-2017-0007.

NEWBOLD, P. ARIMA model building and the time series analysis approach to

forecasting. Journal of Forecasting, v. 2, n. 1, p. 23‚Äì35, jan. 1983. Dispon√≠vel em:

https://doi.org/10.1002/for.3980020104.


---

# Page 72

72

PAO, James J.; SULLIVAN, Danielle S. Time series sales forecasting. Final year

project, Computer Science, Stanford Univ., Stanford, CA, USA, 2017. Dispon√≠vel em:

https://cs229.stanford.edu/proj2017/final-reports/5244336.pdf.

PARZEN, E. An Approach to Time Series Analysis. The Annals of Mathematical

Statistics, v. 32, n. 4, p. 951‚Äì989, 1961. Dispon√≠vel em:

https://www.jstor.org/stable/2237900.

SHIRI, F. M. et al. A Comprehensive Overview and Comparative Analysis on Deep

Learning Models. Journal on Artificial Intelligence, v. 6, n. 1, p. 301‚Äì360, 2024.

Dispon√≠vel em: https://doi.org/10.32604/jai.2024.054314.

SPILIOTIS, E.; ASSIMAKOPOULOS, V.; MAKRIDAKIS, S. Generalizing the Theta

method for automatic forecasting. European Journal of Operational Research, jan.

2020. Dispon√≠vel em: http://dx.doi.org/10.1016/j.ejor.2020.01.007.

VAVLIAKIS, K.; SIAILIS, A.; SYMEONIDIS, A. Optimizing Sales Forecasting in e-

Commerce with ARIMA and LSTM Models. Proceedings of the 17th International

Conference on Web Information Systems and Technologies, 2021. Dispon√≠vel

em: https://doi.org/10.5220/0010659500003058.
