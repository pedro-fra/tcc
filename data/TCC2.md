## UNIVERSIDADE DO VALE DO RIO DOS SINOS (UNISINOS)

## UNIDADE ACAD√äMICA DE GRADUA√á√ÉO CURSO DE ENGENHARIA DA

## COMPUTA√á√ÉO

## PEDRO DELAVALD FR√Å

## COMPARA√á√ÉO DE MODELOS PREDITIVOS PARA PREVIS√ÉO DE VENDAS:

Uma An√°lise entre T√©cnicas Estat√≠sticas, Machine Learning e Power BI

S√£o Leopoldo

2025


---

# Page 2

2

## PEDRO DELAVALD FR√Å

## COMPARA√á√ÉO DE MODELOS PREDITIVOS PARA PREVIS√ÉO DE VENDAS:

Uma An√°lise entre T√©cnicas Estat√≠sticas, Machine Learning e Power BI

Trabalho de Conclus√£o de Curso apresentado como requisito parcial para obten√ß√£o do t√≠tulo de Bacharel em

Engenharia da Computa√ß√£o, pelo Curso de Engenharia da Computa√ß√£o da Universidade do Vale do Rio dos Sinos

## (UNISINOS)

Orientador: Prof. MSc. Jean Schmith

S√£o Leopoldo

2025


---

# Page 3

## RESUMO

Este trabalho tem como objetivo avaliar e comparar o desempenho de diferentes m√©todos de previs√£o de vendas, utilizando tanto t√©cnicas estat√≠sticas tradicionais quanto algoritmos modernos de aprendizado de m√°quina, aplicados a dados reais de faturamento extra√≠dos de um dashboard corporativo em Power BI.

Diante do aumento da competitividade e da demanda por decis√µes empresariais baseadas em dados, destaca-se a necessidade de modelos preditivos cada vez mais precisos e robustos. O estudo envolve a implementa√ß√£o dos modelos ARIMA, Theta, Suaviza√ß√£o Exponencial e XGBoost, analisando suas performances preditivas e as possibilidades de ado√ß√£o dessas abordagens no contexto empresarial. Os resultados s√£o avaliados a partir de m√©tricas estat√≠sticas padronizadas, permitindo identificar se algum modelo apresenta desempenho superior ao m√©todo atualmente empregado.

Os achados indicam que a Suaviza√ß√£o Exponencial obteve o melhor desempenho entre os modelos de aprendizado de m√°quina testados, com MAPE de 23,99%, por√©m ainda foi superada pelo m√©todo h√≠brido implementado no Power BI (21,82% de MAPE). Este resultado evidencia que, para a s√©rie temporal analisada, o m√©todo existente em produ√ß√£o demonstrou maior acur√°cia que os algoritmos avan√ßados testados, sugerindo que a sofistica√ß√£o algor√≠tmica n√£o necessariamente resulta em melhor desempenho para este contexto espec√≠fico.

A pesquisa contribui para a aproxima√ß√£o entre teoria e pr√°tica, oferecendo subs√≠dios para a escolha de m√©todos de previs√£o mais adequados √†s necessidades das organiza√ß√µes e potencializando o valor estrat√©gico das an√°lises de vendas.

Palavras-chave: Previs√£o de Vendas; S√©ries Temporais; Aprendizado de M√°quina;

Power BI; ARIMA; XGBoost; Suaviza√ß√£o Exponencial; M√©todo Theta; Business

Intelligence.


---

# Page 4

## LISTA DE FIGURAS

Figura 1 - Metodologia geral do trabalho ................................................................... 31

Figura 2 - Metodologia do pr√©-processamento .......................................................... 33

Figura 3 - Vis√£o geral da s√©rie temporal ................................................................... 37

Figura 4 ‚Äì Decomposi√ß√£o da s√©rie temporal ............................................................. 38

Figura 5 - An√°lise da sazonalidade ........................................................................... 39

Figura 6 - Propriedades estat√≠sticas da s√©rie temporal ............................................. 40

Figura 7 - An√°lise de distribui√ß√£o .............................................................................. 41

Figura 8 - Evolu√ß√£o temporal das vendas ................................................................. 42

Figura 9 - An√°lise de correla√ß√£o temporal ................................................................. 43

Figura 10 - Metodologia do modelo ARIMA .............................................................. 45

Figura 11 ‚Äì Metodologia do modelo Suaviza√ß√£o Exponencial .................................. 52

Figura 12 ‚Äì Metodologia do modelo Theta ................................................................ 56

Figura 13 ‚Äì Metodologia do modelo XGBoost ........................................................... 59


---

# Page 5

5

## LISTA DE QUADROS

Quadro 1 - Resultados das M√©tricas do Modelo ARIMA ........................................... 67

Quadro 2 - Resultados das M√©tricas do Modelo Suaviza√ß√£o Exponencial ............... 68

Quadro 3 - Resultados das M√©tricas do Modelo Theta ............................................. 69

Quadro 4 - Resultados das M√©tricas do Modelo XGBoost Ultimate ........................................ 69

Quadro 5 - Tabela Comparativa dos Modelos ........................................................... 70

Quadro 6 - Tabela Comparativa entre Power BI e Suaviza√ß√£o Exponencial ..................................... 71


---

# Page 6

## LISTA DE SIGLAS

## CNN

Convolutional Neural Network

## RNN

Recurrent Neural Network

## ARIMA

Auto Regressive Integrated Moving Average

XGBoost

X Gradient Boost

## ML

Machine Learning

## PIB

Produto Interno Bruto

## SARIMA

Seasonal Auto Regressive Integrated Moving Average

## LSTM

Long Short-Term Memory

## STL

Seasonal and Trend decomposition using LOESS

## AIC

Akaike Information Criterion

## AR

Auto Regressive

## MA

Moving Average

## SES

Simple Exponential Smoothing

## ACF

Autocorrelation Function

## PACF

Parcial Autocorrelation Function

## KPSS

Kwiatkowski-Phillips-Schmidt-Shin

## ADF

Augmented Dickey Fuller

## RMSSE

Root Mean Squared Scaled Error

## RMSE

Root Mean Squared Error

## MAE

Mean Absolute Error

## BI

Business Intelligence

## GBDT

Gradient Boosting Decision Tree

## MM6

M√©dia M√≥vel de 6 meses

YoY

Year-over-Year

## ISO

International Organization for Standardization

## MD5

Message Digest 5

## EDA

Exploratory Data Analysis

## CSV

Comma-Separated Values


---

# Page 7

## SUM√ÅRIO

1 INTRODU√á√ÉO ....................................................................................................... 11

1.1 TEMA .................................................................................................................. 11

1.2 DELIMITA√á√ÉO DO TEMA ................................................................................... 12

1.3 PROBLEMA ........................................................................................................ 12

1.4 OBJETIVOS ........................................................................................................ 12

1.4.1 Objetivo geral ................................................................................................. 12

1.4.2 Objetivos espec√≠ficos ..................................................................................... 12

1.5 JUSTIFICATIVA .................................................................................................. 13

2 FUNDAMENTA√á√ÉO TE√ìRICA ............................................................................. 14

2.1 S√âRIES TEMPORAIS ......................................................................................... 14

2.1.1 Conceitos fundamentais e defini√ß√µes .......................................................... 14

2.1.2 Caracter√≠sticas principais .............................................................................. 14

2.1.3 Classifica√ß√µes de s√©ries temporais .............................................................. 15

2.1.4 Exemplos de aplica√ß√£o .................................................................................. 16

2.2 M√âTODO THETA ................................................................................................ 16

2.2.1 Descri√ß√£o geral e origem ............................................................................... 17

2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros .......................................................... 17

2.2.3 Equa√ß√£o da linha Theta ................................................................................. 18

2.2.4 Express√µes aditivas e multiplicativas .......................................................... 18

2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros ..................... 19

2.2.6 Exemplos pr√°ticos de uso ............................................................................. 19

2.3 MODELO ARIMA ................................................................................................ 20

2.3.1 Defini√ß√£o e estrutura do modelo ARIMA ...................................................... 20

2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA ........................................... 21

2.3.3 Como o modelo ARIMA funciona para prever dados futuros? .................. 21

2.3.4 Casos pr√°ticos e exemplos na literatura ...................................................... 22

2.4 SUAVIZA√á√ÉO EXPONENCIAL ........................................................................... 23

2.4.1 Defini√ß√£o e estrutura do m√©todo .................................................................. 23

2.4.2 Vantagens e limita√ß√µes na previs√£o de dados ............................................ 25

2.4.3 Aplica√ß√µes e estudos de caso ...................................................................... 25

2.5 XGBOOST ........................................................................................................... 26

2.5.1 Vis√£o geral do Extreme Gradient Boosting .................................................. 27


---

# Page 8

8

2.5.2 Caracter√≠sticas e conceitos do XGBoost ..................................................... 27

2.5.3 Como o XGBoost prev√™ dados futuros ........................................................ 28

2.5.4 Exemplos pr√°ticos de uso do XGBoost ........................................................ 29

3 METODOLOGIA .................................................................................................... 31

3.1 METODOLOGIA DE TRABALHO ....................................................................... 31

3.1.1 Defini√ß√£o do problema e objetivos da previs√£o .......................................... 32

3.1.2 Coleta e pr√©-processamento dos dados ...................................................... 32

3.1.2.1 Filtragem e agrega√ß√£o inicial ......................................................................... 33

3.1.2.3 Agrega√ß√£o temporal mensal .......................................................................... 34

3.1.2.4 Convers√£o para formato Darts ...................................................................... 34

3.1.2.5 Considera√ß√µes sobre engenharia de features ............................................... 35

3.1.3 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal ............................... 35

3.1.3.1 Vis√£o geral da s√©rie temporal ........................................................................ 36

3.1.3.2 Decomposi√ß√£o STL ....................................................................................... 37

3.1.3.3 An√°lise de sazonalidade ................................................................................ 38

3.1.3.4 Propriedades estat√≠sticas .............................................................................. 39

3.1.3.5 An√°lise de distribui√ß√£o ................................................................................... 40

3.1.3.6 Evolu√ß√£o temporal detalhada ........................................................................ 41

3.1.3.7 An√°lise de correla√ß√£o temporal ..................................................................... 42

Fonte: elaborado pelo autor ...................................................................................... 43

3.1.3.8 Insights para modelagem .............................................................................. 43

3.2 MODELOS DE PREVIS√ÉO UTILIZADOS ........................................................... 44

3.2.1 ARIMA .............................................................................................................. 45

3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente ............................... 45

3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal ................................... 46

3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o ............................................ 47

3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste ........................................ 47

3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q ................................................................. 48

3.2.1.6 Treinamento do modelo ................................................................................. 49

3.2.1.7 Valida√ß√£o do modelo e ajustes finos ............................................................. 50

3.2.1.8 An√°lise residual ............................................................................................. 51

3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura ............................. 51

3.2.2 Suaviza√ß√£o Exponencial ................................................................................ 52

3.2.2.1 An√°lise de componentes para sele√ß√£o do modelo ........................................ 53


---

# Page 9

9

3.2.2.2 Decis√£o entre modelo aditivo e multiplicativo ................................................ 53

3.2.2.3 Configura√ß√£o e otimiza√ß√£o de par√¢metros .................................................... 54

3.2.2.4 Treinamento por suaviza√ß√£o recursiva .......................................................... 54

3.2.2.5 Gera√ß√£o de previs√µes diretas ........................................................................ 55

3.2.2.6 An√°lise residual espec√≠fica para suaviza√ß√£o ................................................. 55

3.2.3 Theta ................................................................................................................ 55

3.2.3.1 Verifica√ß√£o de pr√©-condi√ß√µes do m√©todo Theta ............................................ 56

3.2.3.2 Configura√ß√£o autom√°tica vs. manual do modelo ........................................... 57

3.2.3.3 Decomposi√ß√£o e cria√ß√£o das linhas Theta .................................................... 57

3.2.3.4 Treinamento e ajuste das componentes ........................................................ 58

3.2.3.5 Combina√ß√£o de previs√µes e extrapola√ß√£o ..................................................... 58

3.2.3.6 Avalia√ß√£o e diagn√≥sticos espec√≠ficos ............................................................ 58

3.2.4 XGBoost .......................................................................................................... 59

3.2.4.1 Prepara√ß√£o e integra√ß√£o com Darts .............................................................. 59

3.2.4.2 Divis√£o dos dados em treino e teste Engenharia autom√°tica de features ..... 60

3.2.4.3 Engenharia autom√°tica de features ............................................................... 60

3.2.4.4 Configura√ß√£o dos hiper par√¢metros iniciais ................................................... 61

3.2.4.5 Treinamento do modelo ................................................................................. 62

3.2.4.6 Avalia√ß√£o inicial de desempenho .................................................................. 63

3.2.4.7 Valida√ß√£o e an√°lise de resultados ................................................................. 63

3.2.4.8 Gera√ß√£o das previs√µes finais e armazenamento dos resultados .................. 63

3.2.5 Power BI .......................................................................................................... 63

3.2.5.1 Estrutura da solu√ß√£o no Power BI ................................................................. 63

3.2.5.2 C√°lculo da previs√£o h√≠brida ........................................................................... 64

3.2.5.3 Extra√ß√£o de dados e compara√ß√£o com modelos de ML ................................ 65

3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS .............................................. 65

3.3.1 Compara√ß√£o entre os modelos de aprendizado de m√°quina e estat√≠sticos

.................................................................................................................................. 66

3.3.2 Compara√ß√£o do melhor modelo de ML versus m√©todo Power BI .............. 66

4 AN√ÅLISE DOS RESULTADOS ............................................................................. 67

4.1 RESULTADOS DOS MODELOS DE APRENDIZADO DE M√ÅQUINA E ESTAT√çSTICOS ........................................................................................................ 67

4.1.1 ARIMA .............................................................................................................. 67

4.1.2 Suaviza√ß√£o Exponencial ................................................................................ 68


---

# Page 10

10

4.1.3 Theta ................................................................................................................ 68

4.1.4 XGBoost .......................................................................................................... 69

4.2 RESUMO COMPARATIVO DOS MODELOS DE ML .......................................... 70

4.3 COMPARA√á√ÉO: MODELO XGBOOST VERSUS M√âTODO POWER BI ........... 70

4.4 LIMITA√á√ïES E DESAFIOS T√âCNICOS ............................................................. 71

5 CONCLUS√ÉO ........................................................................................................ 73

REFER√äNCIAS ......................................................................................................... 76


---

# Page 11

11

## 1 INTRODU√á√ÉO

A previs√£o de vendas, no contexto atual da transforma√ß√£o digital e da crescente demanda por decis√µes empresariais baseadas em dados, se estabelece como um dos grandes desafios e diferenciais competitivos para organiza√ß√µes de todos os portes.

Com mercados cada vez mais din√¢micos e suscet√≠veis a varia√ß√µes econ√¥micas, tecnol√≥gicas e comportamentais, a precis√£o nas estimativas de faturamento assume papel central no planejamento, controle de estoques, log√≠stica, defini√ß√£o de metas e estrat√©gias comerciais. Este cen√°rio impulsionou o avan√ßo de diferentes m√©todos de previs√£o, desde t√©cnicas estat√≠sticas tradicionais at√© abordagens inovadoras de aprendizado de m√°quina, que v√™m transformando a forma como as empresas analisam e projetam seus resultados futuros.

O uso disseminado de ferramentas de BI, como o Power BI, trouxe grandes avan√ßos para a visualiza√ß√£o e interpreta√ß√£o dos dados hist√≥ricos das empresas, permitindo a elabora√ß√£o de dashboards customizados para acompanhamento do desempenho de vendas. Contudo, muitos desses sistemas ainda utilizam m√©todos de previs√£o relativamente simples, que podem n√£o captar integralmente a complexidade dos padr√µes temporais, sazonalidades e vari√°veis ex√≥genas presentes nos dados

(ENSAFI et al., 2022). Paralelamente, algoritmos de ML, como o XGBoost, v√™m sendo destacados na literatura por sua elevada acur√°cia preditiva, robustez e flexibilidade na incorpora√ß√£o de m√∫ltiplos fatores ao processo de modelagem, sendo escolhido frequentemente em cen√°rios reais e competi√ß√µes internacionais (CHEN; GUESTRIN,

2016).

Diante desse contexto, torna-se pertinente avaliar, sob uma perspectiva aplicada e comparativa, se modelos de ML podem efetivamente aprimorar as previs√µes de faturamento realizadas por solu√ß√µes j√° consolidadas no ambiente empresarial, como o Power BI, contribuindo para a gera√ß√£o de insights mais robustos e embasados para a tomada de decis√£o.

## 1.1 TEMA

O presente trabalho aborda o tema da previs√£o de vendas utilizando s√©ries temporais, com foco na compara√ß√£o entre m√©todos tradicionais e modernos de modelagem preditiva aplicados a dados reais de faturamento empresarial.


---

# Page 12

12

## 1.2 DELIMITA√á√ÉO DO TEMA

A pesquisa concentra-se na an√°lise comparativa do desempenho de diferentes modelos de previs√£o utilizando dados hist√≥ricos extra√≠dos de um banco de dados. O

estudo limita-se √† previs√£o de faturamento mensal, simulando o contexto pr√°tico enfrentado por empresas que necessitam estimar o resultado do m√™s corrente com base em informa√ß√µes parciais, do primeiro dia do m√™s at√© o momento da consulta.

## 1.3 PROBLEMA

O problema que orienta este trabalho √©: Modelos de aprendizado de m√°quina conseguem superar o desempenho do m√©todo h√≠brido atualmente implementado no Power BI para previs√£o de vendas? A investiga√ß√£o busca responder se as t√©cnicas de ML como XGBoost, ARIMA, Suaviza√ß√£o Exponencial e Theta produzem resultados com maior acur√°cia do que a abordagem existente no dashboard corporativo, servindo como baseline de compara√ß√£o. O estudo compara diretamente o desempenho dos modelos de ML contra o m√©todo em produ√ß√£o no Power BI, avaliando se h√° ganhos significativos em precis√£o que justifiquem a ado√ß√£o de algoritmos mais complexos.

## 1.4 OBJETIVOS

1.4.1 Objetivo geral

Avaliar, de forma comparativa, o desempenho de diferentes abordagens de previs√£o de vendas, sejam elas tradicionais ou baseadas em ML, aplicadas a dados reais de faturamento, verificando se algum dos modelos apresenta desempenho superior ao m√©todo atualmente utilizado em dashboards de Power BI.

1.4.2 Objetivos espec√≠ficos a) Revisar e contextualizar os principais conceitos de s√©ries temporais, m√©todos estat√≠sticos cl√°ssicos e t√©cnicas de ML voltadas √† previs√£o de vendas, conforme descrito por autores como Bezerra (2006), Makridakis,

Wheelwright e Hyndman (1999) e Ensafi et al. (2022);


---

# Page 13

13

b) Estruturar e pr√©-processar os dados hist√≥ricos de faturamento de acordo com as exig√™ncias de cada modelo preditivo, assegurando anonimiza√ß√£o, integridade e conformidade com boas pr√°ticas de ci√™ncia de dados;

c) Implementar, treinar e validar modelos de previs√£o ARIMA, Theta,

Suaviza√ß√£o Exponencial e XGBoost, utilizando m√©tricas estat√≠sticas padronizadas para avalia√ß√£o do desempenho;

d) Analisar comparativamente os resultados obtidos e discutir as vantagens, limita√ß√µes e possibilidades pr√°ticas para ado√ß√£o dos m√©todos preditivos no contexto empresarial.

Acredita-se que essa abordagem possibilite uma an√°lise abrangente e rigorosa, identificando as oportunidades e desafios envolvidos na transi√ß√£o para modelos preditivos mais avan√ßados no ambiente corporativo.

## 1.5 JUSTIFICATIVA

A relev√¢ncia deste estudo se justifica tanto pelo avan√ßo recente das t√©cnicas de an√°lise preditiva quanto pela necessidade real de organiza√ß√µes aprimorarem seus processos de tomada de decis√£o frente a cen√°rios de incerteza e competitividade. Do ponto de vista acad√™mico, h√° uma lacuna na literatura nacional sobre aplica√ß√µes pr√°ticas e comparativas de modelos de machine learning em ambientes de BI

amplamente adotados por empresas brasileiras, como o Power BI (ENSAFI et al.,

2022; SHIRI et al., 2024). Internacionalmente, pesquisas v√™m demonstrando o potencial de algoritmos como XGBoost na supera√ß√£o de m√©todos tradicionais de previs√£o, especialmente em s√©ries temporais com padr√µes complexos e influ√™ncias externas (CHEN; GUESTRIN, 2016).

No √¢mbito empresarial, a ado√ß√£o de modelos mais precisos pode representar ganhos substanciais em planejamento, controle financeiro e competitividade, permitindo que decis√µes sejam tomadas com maior base quantitativa e menor risco.

Este trabalho, ao propor uma an√°lise comparativa fundamentada, contribui para aproximar a teoria e a pr√°tica, orientando gestores e profissionais de dados quanto √†

melhor escolha de m√©todos para suas demandas espec√≠ficas.


---

# Page 14

14

## 2 FUNDAMENTA√á√ÉO TE√ìRICA

Neste cap√≠tulo, apresenta-se o embasamento te√≥rico indispens√°vel ao desenvolvimento do presente estudo. Ser√£o discutidos os conceitos fundamentais relacionados √† previs√£o de dados, contemplando tanto a aplica√ß√£o de algoritmos de aprendizado de m√°quina quanto a utiliza√ß√£o de c√°lculos no Power BI. A partir dessa fundamenta√ß√£o, busca-se sustentar o estudo de caso realizado, evidenciando as principais vantagens e limita√ß√µes de cada abordagem na an√°lise e proje√ß√£o de informa√ß√µes.

## 2.1 S√âRIES TEMPORAIS

A an√°lise de s√©ries temporais √© uma importante √°rea da estat√≠stica, dedicada √†

compreens√£o, modelagem e previs√£o de fen√¥menos que s√£o observados de forma sequencial no tempo. Conforme Bezerra (2006), a utiliza√ß√£o da an√°lise de s√©ries temporais √© amplamente difundida em diversas √°reas, como economia, meteorologia, sa√∫de, controle de processos industriais, vendas e finan√ßas, devido √† capacidade de identificar padr√µes de comportamento e realizar previs√µes futuras com base em dados hist√≥ricos.

2.1.1 Conceitos fundamentais e defini√ß√µes

De acordo com Parzen (1961), uma s√©rie temporal pode ser entendida como um conjunto de observa√ß√µes dispostas cronologicamente, sendo representada matematicamente como um processo estoc√°stico, no qual cada valor observado corresponde a um instante espec√≠fico no tempo.

2.1.2 Caracter√≠sticas principais

Entre os principais conceitos e caracter√≠sticas envolvidos na an√°lise de s√©ries temporais, destacam-se:

a) Estacionariedade: Segundo Bezerra (2006), a estacionariedade ocorre quando as propriedades estat√≠sticas, tais como m√©dia, vari√¢ncia e covari√¢ncia, permanecem constantes ao longo do tempo. A condi√ß√£o de


---

# Page 15

15

estacionariedade √© importante para aplica√ß√£o correta de diversos modelos, como os modelos ARIMA;

b) Tend√™ncia: Refere-se √† dire√ß√£o predominante da s√©rie ao longo do tempo, podendo ser crescente, decrescente ou est√°vel. Segundo Makridakis,

Wheelwright e Hyndman (1999), a tend√™ncia √© fundamental para entender o comportamento das s√©ries e escolher modelos adequados;

c) Sazonalidade: Corresponde √†s varia√ß√µes peri√≥dicas e regulares que ocorrem em intervalos fixos, como mensal ou anual, devido a fatores externos ou eventos recorrentes

## (MAKRIDAKIS,

## WHEELWRIGHT;

## HYNDMAN, 1999);

d) Autocorrela√ß√£o: Representa a correla√ß√£o da s√©rie consigo mesma em diferentes momentos do tempo (lags). De acordo com Parzen (1961), esse conceito √© fundamental para identificar e compreender o comportamento das s√©ries temporais;

e) Ru√≠do branco: Para Bezerra (2006), √© a parcela aleat√≥ria da s√©rie temporal, composta por erros aleat√≥rios independentes com m√©dia zero e vari√¢ncia constante, que n√£o apresentam qualquer tipo de padr√£o previs√≠vel.

2.1.3 Classifica√ß√µes de s√©ries temporais

Makridakis, Wheelwright e Hyndman (1999) classificam as s√©ries temporais em tipos distintos:

a) S√©ries estacion√°rias: Caracterizam-se por apresentar m√©dia e vari√¢ncia constantes ao longo do tempo. S√£o frequentemente observadas em s√©ries financeiras de retorno;

b) S√©ries n√£o estacion√°rias: S√£o s√©ries cujas propriedades estat√≠sticas, como m√©dia e/ou vari√¢ncia, alteram-se com o tempo. Exemplos comuns incluem s√©ries econ√¥micas como PIB e infla√ß√£o;

c) S√©ries lineares e n√£o lineares: S√©ries lineares podem ser modeladas por t√©cnicas tradicionais, como ARIMA, enquanto s√©ries n√£o lineares exigem modelos mais avan√ßados, como redes neurais artificiais (SHIRI et al., 2024).


---

# Page 16

16

2.1.4 Exemplos de aplica√ß√£o

V√°rios estudos demonstram a aplica√ß√£o pr√°tica das s√©ries temporais em diversos contextos:

a) Previs√£o de vendas no varejo: Ensafi et al. (2022) compararam t√©cnicas tradicionais como SARIMA e Suaviza√ß√£o Exponencial com m√©todos avan√ßados como redes neurais LSTM e CNN para previs√£o das vendas sazonais de m√≥veis. Os resultados mostraram que as redes neurais LSTM

apresentaram maior precis√£o na captura de padr√µes complexos e sazonais;

b) Previs√£o de vendas semanais em lojas de departamento: Pao e Sullivan

(2014) utilizaram t√©cnicas como √°rvores de decis√£o, STL+ARIMA e redes neurais feed-forward com entradas temporais defasadas, concluindo que as redes neurais tiveram um desempenho superior, capturando com efici√™ncia as sazonalidades das vendas semanais;

c) Aplica√ß√£o de Deep Learning em s√©ries temporais complexas: Shiri et al.

(2024) realizaram uma revis√£o abrangente sobre o uso de modelos de deep learning, como CNN, RNN, LSTM e Transformer, em s√©ries temporais. O

estudo apontou que t√©cnicas modernas baseadas em deep learning t√™m se mostrado superiores √†s t√©cnicas tradicionais, principalmente em s√©ries complexas e com grandes volumes de dados.

## 2.2 M√âTODO THETA

O m√©todo Theta ganhou popularidade ao vencer a competi√ß√£o M3 de previs√µes de s√©ries temporais devido √† sua simplicidade e efici√™ncia em gerar previs√µes precisas para diversos tipos de dados. Desde ent√£o, este m√©todo tem sido amplamente estudado e aprimorado, resultando em diferentes variantes que exploram seu potencial para aplica√ß√µes autom√°ticas e mais robustas. (ASSIMAKOPOULOS;

## NIKILOPOULOS, 2000).


---

# Page 17

17

2.2.1 Descri√ß√£o geral e origem

O m√©todo Theta √© uma t√©cnica de previs√£o uni variada que decomp√µe a s√©rie temporal original em componentes denominados "linhas Theta". Cada linha Theta √©

obtida ajustando-se a curvatura dos dados originais atrav√©s de um par√¢metro Œ∏

aplicado √†s segundas diferen√ßas da s√©rie original. (ASSIMAKOPOULOS;

## NIKILOPOULOS, 2000; SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020). A

combina√ß√£o dessas linhas Theta gera previs√µes que equilibram tend√™ncias de curto e longo prazo. (ASSIMAKOPOULOS; NIKILOPOULOS, 2000).

2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros

As principais caracter√≠sticas do m√©todo Theta incluem:

a) Decomposi√ß√£o da s√©rie temporal: a s√©rie original √© dividida em m√∫ltiplas linhas Theta, destacando diferentes caracter√≠sticas como tend√™ncias de curto e longo prazo (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000);

b) Par√¢metro Œ∏ (Theta): controla a curvatura das linhas, com ùúÉ< 1 enfatizando tend√™ncias de longo prazo e ùúÉ> 1 destacando varia√ß√µes de curto prazo.

## (ASSIMAKOPOULOS;

## NIKOLOPOULOS,

2000;

## SPILIOTIS;

## ASSIMAKOPOULOS; MAKRIDAKIS, 2020);

c) Combina√ß√£o de previs√µes: as previs√µes geradas a partir das linhas Theta s√£o combinadas usando pondera√ß√µes espec√≠ficas para gerar resultados mais robustos e precisos (FIORUCCI et al., 2016);

d) Flexibilidade e robustez: permite ajuste e adapta√ß√£o autom√°tica dos par√¢metros para diferentes s√©ries temporais, tornando-o vers√°til para diversos contextos (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020);

e) Efici√™ncia computacional: destaca-se pela simplicidade computacional, sendo f√°cil e r√°pido de implementar, especialmente quando comparado com m√©todos mais complexos como ARIMA ou redes neurais (FIORUCCI et al.,

2016);

f) Capacidade de generaliza√ß√£o: √© aplic√°vel em s√©ries temporais com diferentes padr√µes, como tend√™ncias lineares, n√£o lineares, s√©ries com


---

# Page 18

18

comportamento sazonal e s√©ries irregulares

## (SPILIOTIS;

## ASSIMAKOPOULOS; MAKRIDAKIS, 2020);

g) Simplicidade na interpreta√ß√£o: oferece resultados facilmente interpret√°veis, facilitando seu uso pr√°tico em ambientes corporativos e industriais

(FIORUCCI et al., 2016).

2.2.3 Equa√ß√£o da linha Theta

Segundo Spiliotis, Assimakopoulos e Makridakis (2020), o m√©todo Theta pode ser matematicamente descrito da seguinte forma:

Seja ùëåùë° uma s√©rie temporal observada no tempo ùë°. Uma linha Theta ùëçùë°(ùúÉ) √©

obtida pela express√£o:

‚àá2ùëçùë°(ùúÉ) = ùúÉ‚àá2ùëåùë°= ùúÉ(ùëåùë°‚àí2ùëå(ùë°‚àí1) + ùëå(ùë°+2)),

ùë°= 3, ‚Ä¶ , ùëõ

Onde ‚àá2ùëåùë° √© o operador das segundas diferen√ßas da s√©rie original ùëå no ponto

ùë°.

2.2.4 Express√µes aditivas e multiplicativas

No m√©todo Theta, as previs√µes podem ser realizadas utilizando express√µes aditivas ou multiplicativas:

a) Modelo aditivo: √© o modelo original do m√©todo Theta, no qual as previs√µes s√£o obtidas pela combina√ß√£o linear aditiva das linhas Theta ajustadas

## (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000);

b) Modelo multiplicativo: √© uma extens√£o recente do m√©todo, permitindo modelar situa√ß√µes em que componentes como sazonalidade e tend√™ncia interagem de forma multiplicativa, sendo especialmente √∫til em s√©ries com tend√™ncia exponencial ou comportamento sazonal multiplicativo

## (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).


---

# Page 19

19

2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros

Para prever dados futuros, o m√©todo Theta realiza as seguintes etapas

## (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000; FIORUCCI, 2016):

a) Decomposi√ß√£o: a s√©rie temporal √© decomposta em linhas Theta com diferentes curvaturas;

b) Extrapola√ß√£o: cada linha √© extrapolada individualmente, frequentemente usando m√©todos simples, como suaviza√ß√£o exponencial simples (SES) para tend√™ncias de curto prazo e regress√£o linear para tend√™ncias de longo prazo;

c) Combina√ß√£o das linhas: as previs√µes individuais s√£o combinadas, geralmente com pesos iguais ou otimizados, produzindo uma previs√£o final robusta.

2.2.6 Exemplos pr√°ticos de uso

O m√©todo Theta tem sido amplamente aplicado em diversas √°reas, demonstrando sua robustez:

a) Competi√ß√£o M3: a vers√£o cl√°ssica do m√©todo Theta alcan√ßou resultados superiores √†s demais t√©cnicas na competi√ß√£o M3, uma famosa competi√ß√£o internacional focada em m√©todos de previs√£o de s√©ries temporais, especialmente em s√©ries mensais e microecon√¥micas, destacando-se por sua precis√£o e simplicidade (MAKRIDAKIS; HIBON, 2000);

b) Diagn√≥stico automotivo: Lozia (2022) utilizou o m√©todo Theta na avalia√ß√£o diagn√≥stica de amortecedores automotivos, demonstrando a efic√°cia do m√©todo em modelar e prever o comportamento din√¢mico de sistemas mec√¢nicos complexos;

c) Previs√£o autom√°tica: Spiliotis, Assimakopoulos e Makridakis (2020)

propuseram generaliza√ß√µes do m√©todo Theta capazes de selecionar automaticamente a forma mais apropriada (aditiva ou multiplicativa) e ajustar a inclina√ß√£o das tend√™ncias, superando outros algoritmos autom√°ticos em competi√ß√µes recentes (como M4), especialmente em s√©ries anuais.


---

# Page 20

20

## 2.3 MODELO ARIMA

O modelo ARIMA √© uma t√©cnica estat√≠stica amplamente utilizada para an√°lise e previs√£o de s√©ries temporais, desenvolvido por Box e Jenkins (1970). √â

especialmente indicado para s√©ries cujos valores passados e erros hist√≥ricos podem ser utilizados para prever valores futuros (NEWBOLD, 1983).

2.3.1 Defini√ß√£o e estrutura do modelo ARIMA

O modelo ARIMA √© uma combina√ß√£o dos modelos autorregressivos (AR), integrados (I) e de m√©dias m√≥veis (MA), definidos pela seguinte nota√ß√£o geral ARIMA

(p, d, q), onde (NEWBOLD, 1983):

a) p: ordem do termo autorregressivo (AR), representa a rela√ß√£o linear entre a observa√ß√£o atual e as anteriores;

b) d: n√∫mero de diferencia√ß√µes necess√°rias para tornar a s√©rie estacion√°ria;

c) q: ordem dos termos de m√©dia m√≥vel (MA), que refletem os erros anteriores do modelo.

Matematicamente, o modelo ARIMA (p, d, q) pode ser expresso da seguinte forma (NEWBOLD, 1983):

ùëåùë°=  ùõø + ùúô1ùëåùë°‚àí1 + ùúô2ùëåùë°‚àí2 + ‚Ä¶ + ùúôùëùùëåùë°‚àíùëù‚àí ùúÉ1ùúÄùë°‚àí1 ‚àí ùúÉ2ùúÄùë°‚àí2 ‚àí ‚Ä¶ ‚àí ùúÉùëûùúÄùë°‚àíùëû+ ùúÄùë°

Onde:

‚Ä¢ ùëåùë°: valor atual da s√©rie temporal.

‚Ä¢ ùëåùë°‚àí1, ùëåùë°‚àí2,..., ùëåùë°‚àíùëù : valores anteriores da s√©rie temporal (termos AR).

‚Ä¢ ùúÄùë°: erro aleat√≥rio (res√≠duos) com distribui√ß√£o normal, m√©dia zero e vari√¢ncia constante (ru√≠do branco).

‚Ä¢ ùúÄùë°‚àí1, ùúÄùë°‚àí2, ..., ùúÄùë°‚àíùëû: erros anteriores da s√©rie (termos MA).

‚Ä¢ ùõø: constante.

‚Ä¢ ùúô1, ùúô2, ‚Ä¶ , ùúôùëù: coeficientes do termo autorregressivo.

‚Ä¢ ùúÉ1, ùúÉ2, ‚Ä¶ , ùúÉùëû: coeficientes do termo de m√©dia m√≥vel.


---

# Page 21

21

2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA

As principais caracter√≠sticas do modelo ARIMA incluem (BOX; JENKINS, 1970;

FATTAH et al., 2018):

a) Flexibilidade: Pode ajustar-se a diversas s√©ries temporais, incorporando tend√™ncia, ciclos e sazonalidade;

b) Necessidade de estacionariedade: S√©ries temporais precisam ser estacion√°rias para utiliza√ß√£o correta do modelo. A estacionariedade √©

geralmente obtida por diferencia√ß√£o sucessiva das s√©ries temporais;

c) Simplicidade: F√°cil de compreender e implementar, apresentando resultados robustos em previs√µes de curto prazo.

Para verificar se uma s√©rie √© estacion√°ria, frequentemente s√£o utilizados testes estat√≠sticos como o teste Dickey-Fuller (ADF) e o teste KPSS (MURAT et al., 2018).

2.3.3 Como o modelo ARIMA funciona para prever dados futuros?

O processo de constru√ß√£o do modelo ARIMA segue a metodologia Box-

Jenkins, que possui as seguintes etapas (BOX; JENKINS, 1970; MONDAL et al.,

2014):

a) Identifica√ß√£o do modelo: Determina√ß√£o das ordens p, d e q, com base na an√°lise gr√°fica das fun√ß√µes de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial (PACF);

b) Estima√ß√£o dos par√¢metros: Os coeficientes do modelo s√£o estimados, normalmente utilizando o m√©todo da m√°xima verossimilhan√ßa;

c) Diagn√≥stico do modelo: Verifica√ß√£o da adequa√ß√£o do modelo por meio da an√°lise dos res√≠duos (erros), usando testes como o teste de Ljung-Box e crit√©rios estat√≠sticos como AIC (Crit√©rio de Informa√ß√£o de Akaike);

d) Previs√£o: Realiza√ß√£o da previs√£o de valores futuros utilizando o modelo ajustado.


---

# Page 22

22

2.3.4 Casos pr√°ticos e exemplos na literatura

O modelo ARIMA tem diversas aplica√ß√µes pr√°ticas, como evidenciado em diferentes estudos acad√™micos:

a) Previs√£o de demanda em ind√∫strias aliment√≠cias: Fattah et al. (2018)

mostraram que o modelo ARIMA (1,0,1) foi eficaz em prever a demanda futura, ajudando a empresa na gest√£o eficiente de estoques e redu√ß√£o de custos;

b) Previs√£o de vendas no e-commerce: Um modelo h√≠brido combinando

ARIMA com redes neurais LSTM foi utilizado para previs√£o precisa em ambientes com alta volatilidade, como o com√©rcio eletr√¥nico (VAVLIAKIS et al., 2021);

c) Previs√£o no mercado farmac√™utico: Fourkiotis e Tsadiras (2024) utilizaram

ARIMA em combina√ß√£o com t√©cnicas de aprendizado de m√°quina para prever a demanda por produtos farmac√™uticos, mostrando sua efic√°cia em capturar efeitos sazonais. Para enfrentar esse desafio, Fourkiotis e Tsadiras

(2024) utilizaram t√©cnicas de an√°lise uni variada de s√©ries temporais para desenvolver previs√µes mais precisas. Os autores analisaram uma base de dados real contendo 600.000 registros hist√≥ricos de vendas provenientes de uma farm√°cia online, abrangendo um per√≠odo entre 2014 e 2019. A

metodologia proposta envolveu as etapas de pr√©-processamento e limpeza de dados, segmenta√ß√£o dos dados, an√°lise explorat√≥ria e identifica√ß√£o dos padr√µes temporais, aplica√ß√£o e compara√ß√£o do modelo ARIMA com modelos avan√ßados de ML como LSTM e XGBoost e, por fim, avalia√ß√£o do modelo com m√©tricas espec√≠ficas. Os resultados demonstraram que o modelo ARIMA apresentou uma boa capacidade preditiva ao capturar adequadamente a sazonalidade e tend√™ncias lineares de vendas. Contudo, os autores destacaram que modelos de ML avan√ßados, especialmente o XGBoost, tiveram um desempenho ainda superior. Em particular, o XGBoost obteve as menores taxas de erro absoluto percentual m√©dio (MAPE). Apesar da boa performance dos modelos avan√ßados de Machine Learning, o modelo ARIMA ainda obteve desempenho competitivo e foi considerado


---

# Page 23

23

eficaz especialmente em s√©ries temporais com forte componente linear e sazonalidade bem definida;

d) Previs√£o de pre√ßos no mercado financeiro: Mondal et al. (2014) utilizaram

ARIMA para prever pre√ßos de a√ß√µes, destacando sua simplicidade e robustez na previs√£o de tend√™ncias.

## 2.4 SUAVIZA√á√ÉO EXPONENCIAL

O m√©todo de suaviza√ß√£o exponencial tem recebido grande aten√ß√£o no contexto de previs√µes estat√≠sticas devido √† sua efic√°cia, simplicidade e adaptabilidade na previs√£o de s√©ries temporais. Sua popularidade adv√©m da capacidade intr√≠nseca de atribuir pesos maiores √†s observa√ß√µes mais recentes em detrimento das observa√ß√µes mais antigas, permitindo r√°pidas adapta√ß√µes √†s mudan√ßas na din√¢mica dos dados

## (GARDNER, 1985; CIPRA, 1992).

Essa t√©cnica tornou-se uma abordagem padr√£o em diversos campos pr√°ticos, incluindo gest√£o de estoques, controle de processos industriais, finan√ßas e gest√£o de cadeias de suprimentos. Sua ampla ado√ß√£o se d√° pela facilidade computacional e pela interpreta√ß√£o de suas previs√µes em compara√ß√£o com m√©todos mais complexos como modelos ARIMA e redes neurais (MCKENZIE, 1984).

2.4.1 Defini√ß√£o e estrutura do m√©todo

O m√©todo de Suaviza√ß√£o Exponencial √© uma t√©cnica recursiva para previs√£o de s√©ries temporais que se baseia na pondera√ß√£o exponencial decrescente das observa√ß√µes passadas. Formalmente, uma previs√£o futura √© constru√≠da como uma combina√ß√£o linear entre a observa√ß√£o mais recente e a previs√£o feita anteriormente.

Essa caracter√≠stica de atualiza√ß√£o recursiva confere simplicidade e efici√™ncia computacional ao m√©todo (BROWN, 1962; MCKENZIE, 1984).

Matematicamente, para o SES, a previs√£o do valor da s√©rie temporal ùëãùë°+1 pode ser expressa por:

ùëãÃÇùë°+1 = ùõºùëãùë°+ (1 ‚àíùõº)ùëãÃÇùë°


---

# Page 24

24

Onde:

‚Ä¢ ùëãÃÇùë°+1: valor previsto para o pr√≥ximo per√≠odo;

‚Ä¢ ùëãùë°: valor observado no per√≠odo atual;

‚Ä¢ ùëãÃÇùë°: previs√£o feita anteriormente para o per√≠odo atual;

‚Ä¢ ùõº: constante de suaviza√ß√£o 0 < ùõº< 1, que define o grau de pondera√ß√£o aplicado ao dado mais recente (BROWN, 1962).

J√° m√©todos mais avan√ßados, como o m√©todo de Holt-Winters, consideram explicitamente os componentes de n√≠vel, tend√™ncia e sazonalidade da s√©rie temporal.

Segundo Gardner (1985), para s√©ries com comportamento sazonal e tend√™ncia linear, a previs√£o futura para ‚Ñé passos √† frente √© dada pela express√£o geral do m√©todo de Holt-Winters multiplicativo:

ùëãÃÇùë°+‚Ñé= (ùêøùë°+ ‚Ñé √ó ùëèùë°) √ó  ùëÜùë°+‚Ñé‚àíùëö(ùëò+1)

Onde:

‚Ä¢ ùêøùë° √© o n√≠vel estimado da s√©rie no tempo ùë°;

‚Ä¢ ùëèùë° √© a tend√™ncia estimada no tempo ùë°;

‚Ä¢ ùëÜùë°+‚Ñé‚àíùëö(ùëò+1) √© o fator sazonal estimado no tempo correspondente;

‚Ä¢ ‚Ñé representa o horizonte futuro da previs√£o (quantidade de per√≠odos √†

frente);

‚Ä¢ ùëö √© o per√≠odo sazonal da s√©rie (por exemplo, ùëö= 12 para s√©ries mensais anuais);

‚Ä¢ ùëò √© o n√∫mero de ciclos completos transcorridos.

Esses m√©todos avan√ßados permitem previs√µes mais precisas em s√©ries complexas, com tend√™ncias claras ou padr√µes sazonais fortes, superando m√©todos mais simples como m√©dias m√≥veis ou o pr√≥prio Suaviza√ß√£o Exponencial simples

## (MCKENZIE, 1984; GARDNER, 1985).


---

# Page 25

25

2.4.2 Vantagens e limita√ß√µes na previs√£o de dados

Entre as caracter√≠sticas fundamentais do m√©todo de exponential smoothing destacam-se:

a) Adaptabilidade: capacidade de responder rapidamente √†s altera√ß√µes estruturais na s√©rie temporal, atribuindo pesos exponenciais aos dados recentes (GARDNER, 1985);

b) Simplicidade computacional: a estrutura recursiva dos c√°lculos torna o m√©todo atrativo em aplica√ß√µes pr√°ticas, especialmente onde √© necess√°ria atualiza√ß√£o constante das previs√µes (BROWN, 1962);

c) Flexibilidade estrutural: diferentes vers√µes, como simples, dupla e tripla

(Holt-Winters), permitem modelar comportamentos como tend√™ncia e sazonalidade com efici√™ncia (MCKENZIE, 1984);

d) Robustez: vers√µes robustas do m√©todo, que usam a minimiza√ß√£o dos desvios absolutos ou m√©todos M-estimadores ao inv√©s de m√≠nimos quadrados, t√™m maior resist√™ncia a dados at√≠picos e s√©ries temporais com distribui√ß√µes assim√©tricas ou de caudas pesadas (CIPRA, 1992).

2.4.3 Aplica√ß√µes e estudos de caso a) Impacto da suaviza√ß√£o exponencial no Efeito Bullwhip: Chen, Ryan e Simchi-Levi (2000) investigaram como a utiliza√ß√£o do Suaviza√ß√£o

Exponencial na previs√£o de demanda pode intensificar o efeito bullwhip, fen√¥meno no qual pequenas varia√ß√µes na demanda s√£o ampliadas ao longo da cadeia de suprimentos. Eles demonstraram que, ao utilizar previs√µes com exponential smoothing, as varia√ß√µes nas demandas observadas pelos fabricantes se tornam significativamente maiores do que as percebidas pelos varejistas, aumentando os desafios de gest√£o e planejamento log√≠stico nas organiza√ß√µes;

b) Robustez a outliers em s√©ries temporais: Cipra (1992) avaliou o desempenho de vers√µes robustas do m√©todo de Suaviza√ß√£o Exponencial em s√©ries temporais contaminadas por outliers e distribui√ß√µes de caudas longas. Utilizando minimiza√ß√£o dos desvios absolutos (norma ùêø1) em vez


---

# Page 26

26

dos m√≠nimos quadrados, Cipra verificou experimentalmente que essas vers√µes robustas forneceram previs√µes significativamente mais est√°veis e precisas na presen√ßa de valores extremos, superando m√©todos tradicionais especialmente em s√©ries financeiras e industriais onde valores at√≠picos s√£o comuns;

c) Aplica√ß√µes em controle de estoques: Gardner (1985) destacou o uso bem-

sucedido de Suaviza√ß√£o Exponencial no controle e previs√£o para gest√£o de estoques. Nesse contexto, foram aplicadas varia√ß√µes do m√©todo para prever demandas futuras e determinar n√≠veis √≥timos de estoque, reduzindo custos relacionados √† manuten√ß√£o excessiva ou insuficiente de produtos em invent√°rio. Esse exemplo demonstra claramente como o Suaviza√ß√£o

Exponencial pode auxiliar gestores a otimizarem recursos financeiros e log√≠sticos nas organiza√ß√µes;

d) Previs√µes de demanda em s√©ries sazonais e com tend√™ncia: McKenzie

(1984) apresentou exemplos pr√°ticos demonstrando a efic√°cia do Suaviza√ß√£o Exponencial para s√©ries temporais com forte comportamento sazonal e tend√™ncia definida. Em seu estudo, foi utilizado o m√©todo Holt-

Winters para capturar esses componentes, proporcionando previs√µes mais precisas que outros m√©todos tradicionais como m√©dias m√≥veis simples e modelos ARIMA em s√©ries complexas, especialmente no contexto de demanda sazonal de varejo e setores produtivos.

## 2.5 XGBOOST

O XGBoost tornou-se um dos m√©todos mais populares e eficazes no √¢mbito da previs√£o e classifica√ß√£o em machine learning, devido √† sua capacidade de lidar eficientemente com grandes quantidades de dados e produzir modelos altamente precisos. Originalmente proposto por Chen e Guestrin em 2016, o XGBoost combina otimiza√ß√µes algor√≠tmicas e t√©cnicas avan√ßadas de engenharia de sistemas para aprimorar significativamente o desempenho de previs√µes e classifica√ß√µes em diversas

√°reas (CHEN; GUESTRIN, 2016).


---

# Page 27

27

2.5.1 Vis√£o geral do Extreme Gradient Boosting

O XGBoost √© uma implementa√ß√£o otimizada do algoritmo Gradient Boosting, baseado em √°rvores de decis√£o sequenciais. Diferentemente das abordagens tradicionais, que utilizam √°rvores independentes (como o Random Forest), o XGBoost constr√≥i √°rvores de maneira iterativa, com cada √°rvore subsequente aprendendo dos res√≠duos e erros das anteriores. A combina√ß√£o final das √°rvores resulta em um modelo robusto e altamente eficiente para prever valores futuros e classificar dados complexos (MALIK; HARODE; KUNWAR, 2020).

2.5.2 Caracter√≠sticas e conceitos do XGBoost

Entre as caracter√≠sticas fundamentais do XGBoost destacam-se:

a) Boosting: M√©todo de aprendizado de m√°quina que cria um modelo forte por meio da combina√ß√£o sequencial de modelos fracos. Cada novo modelo tenta corrigir os erros dos modelos anteriores (MALIK; HARODE; KUNWAR,

2020);

b) Regulariza√ß√£o: O XGBoost incorpora penalidades ao modelo para evitar o ajuste excessivo (overfitting), limitando a complexidade atrav√©s de par√¢metros como profundidade m√°xima das √°rvores, penaliza√ß√£o por complexidade (gamma) e regulariza√ß√£o dos pesos das folhas (lambda).

Essa abordagem resulta em modelos mais generaliz√°veis (CHEN;

## GUESTRIN, 2016);

c) Sparsity-aware Split Finding: Um algoritmo que otimiza o processo de divis√£o das √°rvores levando em conta a esparsidade dos dados, economizando recursos computacionais ao ignorar valores ausentes ou zerados durante a constru√ß√£o das √°rvores (CHEN; GUESTRIN, 2016). d) Paraleliza√ß√£o e computa√ß√£o distribu√≠da: O XGBoost √© projetado para ser executado em m√∫ltiplas CPUs, permitindo o processamento paralelo dos dados e acelerando significativamente o treinamento de grandes modelos

## (CHEN; GUESTRIN, 2016);

e) Shrinking e Column Subsampling: T√©cnicas adicionais que ajudam a controlar a complexidade do modelo. Shrinking reduz o impacto individual


---

# Page 28

28

de cada √°rvore, enquanto Column Subsampling seleciona aleatoriamente um subconjunto de atributos para cada √°rvore, aumentando a robustez e a velocidade do modelo (CHEN; GUESTRIN, 2016).

2.5.3 Como o XGBoost prev√™ dados futuros

O funcionamento do XGBoost para previs√µes ocorre de maneira iterativa, seguindo os passos:

a) Inicializa√ß√£o: O processo se inicia com a defini√ß√£o de uma previs√£o inicial, que geralmente corresponde √† m√©dia dos valores reais presentes nos dados de treinamento, no caso de problemas de regress√£o. Essa previs√£o inicial serve como ponto de partida para o modelo e representa a estimativa mais simples poss√≠vel sem considerar ainda as rela√ß√µes complexas entre as vari√°veis (CHEN; GUESTRIN, 2016; NIELSEN, 2016);

b) C√°lculo dos res√≠duos: Ap√≥s a obten√ß√£o da previs√£o inicial, calcula-se a diferen√ßa entre os valores previstos e os valores reais, gerando assim os res√≠duos. Esses res√≠duos indicam o quanto o modelo atual est√° errando na previs√£o. O objetivo do XGBoost √© reduzir esses res√≠duos a cada nova itera√ß√£o, corrigindo gradualmente as falhas do modelo anterior (NIELSEN,

2016; ZHANG et al., 2021);

c) Treinamento iterativo das √°rvores: Em cada itera√ß√£o, uma nova √°rvore de decis√£o √© treinada, n√£o para prever diretamente os valores finais, mas sim para modelar os res√≠duos obtidos na etapa anterior. Ou seja, cada √°rvore seguinte busca aprender e corrigir os erros cometidos pelo conjunto das

√°rvores anteriores, ajustando-se a padr√µes ainda n√£o capturados (XIE;

## ZHANG, 2021; NIELSEN, 2016);

d) Atualiza√ß√£o das previs√µes: As previs√µes do modelo s√£o atualizadas somando as previs√µes das novas √°rvores treinadas √†s previs√µes acumuladas das √°rvores anteriores. Com isso, o modelo torna-se progressivamente mais preciso a cada ciclo, pois incorpora sucessivamente corre√ß√µes dos erros passados. Ao final do processo, a previs√£o final √©

composta pela soma ponderada de todas as √°rvores criadas durante as


---

# Page 29

29

itera√ß√µes, representando assim uma combina√ß√£o de m√∫ltiplos aprendizados parciais (CHEN; GUESTRIN, 2016; XIE; ZHANG, 2021).

A fun√ß√£o objetivo otimizada no processo √©:

ùêø(ùúë) = ‚àëùëô(ùë¶ÃÇùë¶, ùë¶ùëñ)

ùëñ

+ ‚àëŒ©(ùëìùëò)

ùëò

Onde:

‚Ä¢ ùëô(ùë¶ÃÇùë¶, ùë¶ùëñ) representa a fun√ß√£o de perda (e.g., erro quadr√°tico m√©dio);

‚Ä¢ Œ©(ùëìùëò) representa o termo de regulariza√ß√£o que controla a complexidade do modelo (CHEN; GUESTRIN, 2016).

2.5.4 Exemplos pr√°ticos de uso do XGBoost a) Utilidades: Segundo Noorunnahar et al. (apud Kontopoulou et al., 2023), no campo de utilidades, foi conduzido um estudo com o objetivo de prever a produ√ß√£o anual de arroz em Bangladesh. Os autores compararam a precis√£o das previs√µes feitas por um m√©todo ARIMA otimizado, fundamentado no crit√©rio AIC, e pelo algoritmo XGBoost. Para a avalia√ß√£o dos modelos, foram consideradas m√©tricas de erro como MAE, MPE, RMSE

e MAPE. Os resultados indicaram que o modelo XGBoost obteve um desempenho superior em rela√ß√£o ao ARIMA no conjunto de teste, demonstrando maior efic√°cia na previs√£o da produ√ß√£o de arroz para o contexto analisado;

b) Previs√£o de volume de vendas no varejo: No setor de utilidades e com√©rcio, o XGBoost tem se mostrado eficaz na previs√£o de volumes de vendas. A

pesquisa de Dairu e Shilong (2021) √© um exemplo, onde o modelo XGBoost foi utilizado para prever o volume de vendas no varejo, comparando seus resultados com o ARIMA cl√°ssico, o algoritmo GBDT, um modelo de LSTM


---

# Page 30

30

e a ferramenta de previs√£o Prophet. Os resultados desse estudo indicaram que as abordagens baseadas em √°rvores, treinadas com caracter√≠sticas de clima e temperatura, ofereceram o melhor desempenho de previs√£o entre os cinco modelos, enquanto o ARIMA apresentou o pior desempenho.

Notavelmente, o XGBoost exigiu significativamente menos itera√ß√µes de treinamento do que o GBDT e, juntamente com o GBDT, necessitou de menos dados e recursos em contraste com os modelos de LSTM. Al√©m disso, os autores propuseram um modelo de previs√£o de vendas baseado em XGBoost para um conjunto de dados de bens de varejo do Walmart, demonstrando bom desempenho com menor tempo de computa√ß√£o e recursos de mem√≥ria.


---

# Page 31

31

## 3 METODOLOGIA

Este cap√≠tulo apresenta os procedimentos metodol√≥gicos adotados para a realiza√ß√£o da presente pesquisa, detalhando de forma sistem√°tica as etapas que orientaram o desenvolvimento do estudo. S√£o descritos o tipo de pesquisa, a abordagem utilizada, os m√©todos de coleta e an√°lise dos dados, bem como os crit√©rios que fundamentaram as escolhas metodol√≥gicas. O objetivo √© conferir transpar√™ncia e fundamenta√ß√£o cient√≠fica ao percurso investigativo, garantindo a validade e a confiabilidade dos resultados obtidos.

## 3.1 METODOLOGIA DE TRABALHO

Com o intuito de proporcionar uma vis√£o geral do percurso metodol√≥gico adotado, a figura a seguir apresenta, de forma esquem√°tica, as principais etapas e procedimentos desenvolvidos ao longo deste trabalho. O diagrama tem como objetivo ilustrar, de maneira clara e objetiva, a estrutura metodol√≥gica geral que orientou a condu√ß√£o da pesquisa.

Fonte: elaborado pelo autor

Figura 1 - Metodologia geral do trabalho


---

# Page 32

32

3.1.1 Defini√ß√£o do problema e objetivos da previs√£o

Este trabalho tem como ponto de partida uma necessidade pr√°tica observada em um dos produtos desenvolvidos pela empresa onde atuo, voltado √† an√°lise e visualiza√ß√£o de dados corporativos. Especificamente, trata-se de um dashboard constru√≠do na ferramenta Power BI, que apresenta diversas an√°lises de desempenho, incluindo uma medida respons√°vel por estimar o faturamento do m√™s corrente com base nos dados registrados desde o primeiro dia do m√™s at√© o momento da consulta.

O problema que este trabalho prop√µe a investigar consiste em avaliar se √©

poss√≠vel aprimorar essa estimativa por meio da aplica√ß√£o de modelos de aprendizado de m√°quina e m√©todos estat√≠sticos avan√ßados. Para isso, foram desenvolvidos diferentes modelos preditivos (ARIMA, Theta, Suaviza√ß√£o Exponencial e XGBoost)

utilizando os mesmos dados dispon√≠veis no dashboard, buscando simular o contexto real de previs√£o. O desempenho de cada modelo foi avaliado com base em m√©tricas estat√≠sticas padronizadas.

O objetivo principal deste estudo √© verificar qual dos modelos testados apresenta melhor desempenho preditivo. A ado√ß√£o do melhor modelo poder√° resultar em previs√µes mais precisas e na gera√ß√£o de insights mais robustos e estrat√©gicos.

3.1.2 Coleta e pr√©-processamento dos dados

A coleta e o pr√©-processamento dos dados utilizados neste trabalho foram realizados atrav√©s da ferramenta Visual Studio Code. Os dados empregados correspondem √†s s√©ries hist√≥ricas de faturamento dispon√≠veis em um produto interno da empresa, sendo originalmente utilizados em um dashboard desenvolvido em

Power BI.

Os dados utilizados neste estudo consistiram em registros transacionais de vendas contendo 37.425 transa√ß√µes no per√≠odo de 2014 a 2025. Os campos principais inclu√≠ram a data de emiss√£o do pedido, valor l√≠quido da venda, identifica√ß√£o do cliente e tipo de opera√ß√£o comercial.


---

# Page 33

33

O pipeline implementado seguiu uma abordagem sistem√°tica dividida em etapas distintas, conforme mostra figura abaixo, cada uma com objetivos espec√≠ficos para preparar os dados para diferentes tipos de modelos de machine learning.

Fonte: elaborado pelo autor

3.1.2.1 Filtragem e agrega√ß√£o inicial

O processo de pr√©-processamento iniciou com a filtragem exclusiva de transa√ß√µes classificadas como "VENDA", excluindo devolu√ß√µes e outros tipos de opera√ß√µes comerciais. O valor l√≠quido das vendas foi estabelecido como vari√°vel target, representando a quantidade que os modelos tentariam prever.

3.1.2.2 Anonimiza√ß√£o dos dados

Para garantir a privacidade e conformidade com requisitos de prote√ß√£o de dados, foi implementado um processo de anonimiza√ß√£o utilizando fun√ß√£o de hash

Figura 2 - Metodologia do pr√©-processamento


---

# Page 34

34

criptogr√°fico MD5 para transformar identifica√ß√µes de clientes em c√≥digos an√¥nimos.

O sistema gerou identificadores no formato "CLIENTE_####" onde os quatro d√≠gitos foram derivados deterministicamente do hash do nome original. Esta abordagem protegeu a privacidade dos clientes enquanto preservou a capacidade de rastreamento consistente ao longo do tempo.

3.1.2.3 Agrega√ß√£o temporal mensal

Ap√≥s a filtragem inicial, os dados transacionais foram agregados temporalmente em per√≠odos mensais, calculando a soma total de vendas para cada m√™s. Este processo foi fundamental pois os modelos de s√©ries temporais operam com observa√ß√µes sequenciais regularmente espa√ßadas no tempo.

O procedimento consistiu em agrupar todas as transa√ß√µes por m√™s e ano, gerando uma s√©rie temporal com frequ√™ncia mensal cobrindo o per√≠odo completo dos dados. Cada observa√ß√£o representou o faturamento total do m√™s correspondente, resultando em aproximadamente 132 pontos temporais mensais.

3.1.2.4 Convers√£o para formato Darts

Os dados agregados foram ent√£o convertidos para o formato TimeSeries da biblioteca Darts, utilizada para implementa√ß√£o de todos os modelos neste estudo. A

biblioteca Darts oferece uma interface unificada para modelagem de s√©ries temporais, suportando tanto m√©todos estat√≠sticos tradicionais (ARIMA, Theta, Suaviza√ß√£o

Exponencial) quanto algoritmos de machine learning (XGBoost) especializados em s√©ries temporais.

Esta convers√£o incluiu a defini√ß√£o adequada do √≠ndice temporal (datas mensais no formato ISO), especifica√ß√£o da coluna de valores (faturamento mensal agregado), e configura√ß√£o da frequ√™ncia da s√©rie temporal (mensal). A estrutura TimeSeries permitiu que todos os modelos acessassem funcionalidades avan√ßadas como divis√£o temporal apropriada, gera√ß√£o autom√°tica de features, e aplica√ß√£o de transforma√ß√µes espec√≠ficas para cada algoritmo.


---

# Page 35

35

3.1.2.5 Considera√ß√µes sobre engenharia de features

Diferentemente de abordagens tradicionais que requerem engenharia manual extensiva de features (cria√ß√£o de lags, m√©dias m√≥veis, codifica√ß√µes trigonom√©tricas etc.), a biblioteca Darts realiza automaticamente a cria√ß√£o das features necess√°rias para cada tipo de modelo durante o processo de treinamento.

Para os modelos estat√≠sticos (ARIMA, Theta, Suaviza√ß√£o Exponencial), a Darts opera diretamente sobre a s√©rie temporal univariada, aplicando internamente as transforma√ß√µes e diferencia√ß√µes necess√°rias.

Para o modelo XGBoost, a Darts utiliza o m√≥dulo XGBModel, que cria automaticamente features temporais atrav√©s de:

a) Lags configur√°veis da vari√°vel target;

b) Lags de covariadas passadas (quando aplic√°vel);

c) Encoders temporais (m√™s, ano, trimestre, dia do ano, semana do ano, dia da semana);

d) Normaliza√ß√£o apropriada via MaxAbsScaler.

Esta abordagem simplificou significativamente o pipeline de pr√©-

processamento, eliminando a necessidade de engenharia manual de features e garantindo consist√™ncia na prepara√ß√£o dos dados para todos os modelos.

3.1.3 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal

A an√°lise explorat√≥ria de dados (EDA) constitui uma etapa fundamental no processo de modelagem de s√©ries temporais, precedendo a aplica√ß√£o de modelos preditivos e fornecendo informa√ß√µes essenciais sobre a estrutura, padr√µes e caracter√≠sticas dos dados hist√≥ricos. Conforme destacado por Bezerra (2006), a compreens√£o adequada do comportamento temporal dos dados √© crucial para a sele√ß√£o e parametriza√ß√£o apropriada de modelos de previs√£o, influenciando diretamente a qualidade e confiabilidade dos resultados obtidos.

No contexto de s√©ries temporais de vendas, a EDA assume particular import√¢ncia devido √† complexidade inerente desses dados, que frequentemente apresentam componentes de tend√™ncia, sazonalidade, ciclos econ√¥micos e varia√ß√µes


---

# Page 36

36

irregulares. Segundo Makridakis, Wheelwright e Hyndman (1999), a identifica√ß√£o precisa desses componentes atrav√©s de t√©cnicas explorat√≥rias adequadas √©

fundamental para orientar as decis√µes metodol√≥gicas subsequentes, incluindo a escolha de modelos estat√≠sticos apropriados e a defini√ß√£o de estrat√©gias de pr√©-

processamento.

3.1.3.1 Vis√£o geral da s√©rie temporal

A an√°lise explorat√≥ria foi implementada atrav√©s de um sistema automatizado de visualiza√ß√µes desenvolvido em Python, utilizando bibliotecas especializadas em an√°lise de s√©ries temporais. Os dados utilizados correspondem √† s√©rie temporal de vendas mensais no per√≠odo de outubro de 2014 a setembro de 2025, totalizando 132

observa√ß√µes ap√≥s o pr√©-processamento e agrega√ß√£o temporal mensal.

A estrutura√ß√£o dos dados seguiu as diretrizes estabelecidas por Parzen (1961), que define uma s√©rie temporal como um conjunto de observa√ß√µes dispostas cronologicamente, representada matematicamente como um processo estoc√°stico.

Para garantir a adequa√ß√£o dos dados √† an√°lise temporal, foi implementada uma verifica√ß√£o rigorosa da ordena√ß√£o cronol√≥gica, tratamento de valores ausentes e valida√ß√£o da consist√™ncia temporal.

A primeira an√°lise apresenta uma vis√£o geral abrangente da s√©rie temporal, incluindo a evolu√ß√£o das vendas ao longo do tempo com linha de tend√™ncia, distribui√ß√£o dos valores por ano, an√°lise das vendas acumuladas e volatilidade temporal. Esta vis√£o panor√¢mica revelou uma tend√™ncia de crescimento consistente de 2014 a 2022, seguida por um decl√≠nio significativo entre os anos 2023 e 2025, com valores variando de aproximadamente R$ 1 milh√£o em 2014 para um pico acima de R$ 80 milh√µes em 2022.


---

# Page 37

37

Fonte: elaborado pelo autor

3.1.3.2 Decomposi√ß√£o STL

A decomposi√ß√£o STL (Seasonal-Trend using Loess) foi aplicada para separar os componentes estruturais da s√©rie temporal. A decomposi√ß√£o confirmou a presen√ßa de uma tend√™ncia de longo prazo bem definida e padr√µes sazonais consistentes, com a s√©rie original mostrando crescimento exponencial at√© 2022, seguido por decl√≠nio acentuado. O componente sazonal revelou padr√µes regulares de varia√ß√£o mensal, enquanto o res√≠duo indicou per√≠odos de maior volatilidade, especialmente durante os anos de transi√ß√£o econ√¥mica.

Figura 3 - Vis√£o geral da s√©rie temporal


---

# Page 38

38

Fonte: elaborado pelo autor

3.1.3.3 An√°lise de sazonalidade

A an√°lise sazonal detalhada examinou os padr√µes mensais e de autocorrela√ß√£o da s√©rie temporal. Foram calculadas as m√©dias mensais hist√≥ricas, revelando que determinados meses apresentam consistentemente maiores volumes de vendas. A

an√°lise de autocorrela√ß√£o identificou depend√™ncias temporais significativas at√© o lag

12, confirmando a presen√ßa de sazonalidade anual na s√©rie.

Figura 4 ‚Äì Decomposi√ß√£o da s√©rie temporal


---

# Page 39

39

Fonte: elaborado pelo autor

3.1.3.4 Propriedades estat√≠sticas

A an√°lise das propriedades estat√≠sticas incluiu o c√°lculo das fun√ß√µes de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial (PACF), fundamentais para a parametriza√ß√£o de modelos ARIMA. A ACF mostrou correla√ß√µes significativas nos primeiros lags, decaindo gradualmente at√© o lag 12, enquanto a PACF apresentou cortes abruptos ap√≥s o primeiro lag, sugerindo caracter√≠sticas autorregressivas na s√©rie. A an√°lise da s√©rie diferenciada (primeira diferen√ßa) confirmou a remo√ß√£o da tend√™ncia, tornando a s√©rie mais adequada para modelagem estat√≠stica.

Figura 5 - An√°lise da sazonalidade


---

# Page 40

40

Fonte: elaborado pelo autor

3.1.3.5 An√°lise de distribui√ß√£o

A an√°lise de distribui√ß√£o dos valores de vendas incluiu histograma com sobreposi√ß√£o de distribui√ß√£o normal, gr√°fico Q-Q para teste de normalidade, box plot para identifica√ß√£o de outliers, e compara√ß√£o de densidade. Os resultados indicaram que a distribui√ß√£o das vendas n√£o segue uma distribui√ß√£o normal, apresentando assimetria positiva e presen√ßa de valores extremos.

Figura 6 - Propriedades estat√≠sticas da s√©rie temporal


---

# Page 41

41

Fonte: elaborado pelo autor

3.1.3.6 Evolu√ß√£o temporal detalhada

A an√°lise de evolu√ß√£o temporal examinou as taxas de crescimento anual, padr√µes sazonais por ano, e tend√™ncia linear geral. O c√°lculo das taxas de crescimento revelou crescimento superior a 200% em 2015, estabiliza√ß√£o em torno de 20 a 40% nos anos intermedi√°rios, e decl√≠nios acentuados nos anos finais.

Figura 7 - An√°lise de distribui√ß√£o


---

# Page 42

42

Fonte: elaborado pelo autor

3.1.3.7 An√°lise de correla√ß√£o temporal

A an√°lise de correla√ß√£o incluiu correla√ß√µes com lags de 1 a 12 meses, autocorrela√ß√£o parcial detalhada, matriz de correla√ß√£o para lags selecionados e correla√ß√£o com componentes temporais (ano, trimestre, m√™s). Os resultados mostraram correla√ß√µes elevadas (maior que 0,8) para os primeiros lags, decaindo gradualmente at√© o lag 12. A matriz de correla√ß√£o dos lags selecionados revelou padr√µes de depend√™ncia temporal que orientaram a configura√ß√£o dos modelos preditivos.

Figura 8 - Evolu√ß√£o temporal das vendas


---

# Page 43

43

Fonte: elaborado pelo autor

3.1.3.8 Insights para modelagem

Com base nesta an√°lise explorat√≥ria abrangente, foram identificados os seguintes resultados fundamentais para a modelagem preditiva:

a) Estacionariedade: A s√©rie original n√£o √© estacion√°ria devido √† forte tend√™ncia, requerendo diferencia√ß√£o para modelos ARIMA (ùëë =  1);

b) Sazonalidade: Presen√ßa confirmada de sazonalidade anual (per√≠odo 12)

com padr√µes consistentes;

c) Autocorrela√ß√£o: Depend√™ncias temporais significativas at√© 12 lags, orientando a parametriza√ß√£o dos modelos;

d) Distribui√ß√£o: Dados n√£o seguem distribui√ß√£o normal, apresentando assimetria positiva;

Figura 9 - An√°lise de correla√ß√£o temporal


---

# Page 44

44

e) Tend√™ncia: Tend√™ncia de longo prazo bem definida com crescimento at√©

2022 seguido de decl√≠nio;

f) Volatilidade: Varia√ß√£o da volatilidade ao longo do tempo, com per√≠odos de maior instabilidade.

Estes resultados orientaram diretamente a configura√ß√£o dos par√¢metros para cada modelo preditivo, a escolha das t√©cnicas de pr√©-processamento espec√≠ficas, e as estrat√©gias de valida√ß√£o temporal adotadas nas etapas subsequentes.

## 3.2 MODELOS DE PREVIS√ÉO UTILIZADOS

A modelagem preditiva √© a etapa central deste trabalho, sendo respons√°vel por transformar os dados estruturados em previs√µes quantitativas para o faturamento.

Considerando as diferentes abordagens e caracter√≠sticas dos dados, foram selecionados m√∫ltiplos modelos de previs√£o, cada um com suas pr√≥prias vantagens, desvantagens e caracter√≠sticas espec√≠ficas de implementa√ß√£o.

Os modelos escolhidos para este estudo incluem t√©cnicas tradicionais de s√©ries temporais, como ARIMA, Theta e Suaviza√ß√£o Exponencial, bem como o algoritmo

XGBoost, amplamente utilizado em aplica√ß√µes empresariais para problemas de previs√£o com s√©ries temporais. Cada um desses modelos foi avaliado quanto √† sua capacidade de capturar padr√µes hist√≥ricos, prever tend√™ncias futuras e lidar com os desafios t√≠picos desse tipo de dado, como sazonalidade, tend√™ncia e varia√ß√µes irregulares.

Para garantir uma an√°lise comparativa robusta, foram considerados fatores como a facilidade de implementa√ß√£o, complexidade computacional e a precis√£o das previs√µes geradas. Todos os modelos foram implementados utilizando a biblioteca

Darts, que oferece uma interface unificada e padronizada para modelagem de s√©ries temporais, garantindo consist√™ncia na prepara√ß√£o dos dados, divis√£o temporal e avalia√ß√£o de desempenho.

Nos subt√≥picos a seguir, cada modelo √© apresentado individualmente, incluindo os requisitos espec√≠ficos de implementa√ß√£o e o diagrama do fluxo metodol√≥gico correspondente.


---

# Page 45

45

## 3.2.1 ARIMA

A figura a seguir mostra a metodologia utilizada para o modelo.

Fonte: elaborado pelo autor

3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente

A implementa√ß√£o do modelo ARIMA foi realizada utilizando o Visual Studio

Code como ambiente de desenvolvimento integrado, garantindo controle de vers√£o e reprodutibilidade do c√≥digo. O ambiente Python foi configurado com as seguintes bibliotecas essenciais:

Figura 10 - Metodologia do modelo ARIMA


---

# Page 46

46

a) Darts: Biblioteca especializada em s√©ries temporais que forneceu o m√≥dulo

ARIMA (com sele√ß√£o autom√°tica de par√¢metros via AutoARIMA), m√©todos de divis√£o temporal apropriados para s√©ries temporais, e fun√ß√µes integradas de avalia√ß√£o e diagn√≥stico;

b) Pandas: Utilizado para manipula√ß√£o e estrutura√ß√£o inicial dos dados, convers√£o de tipos de dados temporais, e opera√ß√µes de agrega√ß√£o e filtragem durante o pr√©-processamento;

c) Matplotlib e Seaborn: Empregados para gera√ß√£o de visualiza√ß√µes diagn√≥sticas, incluindo gr√°ficos de s√©rie temporal, correlogramas, an√°lise de res√≠duos e compara√ß√µes entre valores observados e previstos.

Esta prepara√ß√£o foi fundamental para garantir que todas as opera√ß√µes subsequentes fossem executadas de forma padronizada e rastre√°vel.

3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal

O processo de ingest√£o iniciou com o carregamento dos dados de faturamento mensal previamente processados na etapa 3.1.2, obtidos do arquivo CSV estruturado com 132 observa√ß√µes mensais. Os dados foram validados quanto √†:

a) Integridade temporal: Verifica√ß√£o de continuidade mensal sem lacunas, confirma√ß√£o da ordena√ß√£o cronol√≥gica correta, e valida√ß√£o do formato de datas no padr√£o ISO;

b) Qualidade dos valores: Identifica√ß√£o de valores nulos, negativos ou extremos que poderiam comprometer a modelagem, e confirma√ß√£o da escala monet√°ria consistente (valores em reais);

c) Estrutura adequada: Configura√ß√£o do √≠ndice temporal como DatetimeIndex do Pandas, garantindo opera√ß√µes temporais apropriadas.

A convers√£o para o objeto TimeSeries da Darts foi realizada especificando a coluna de valores (faturamento mensal), o √≠ndice temporal (datas mensais), e a frequ√™ncia da s√©rie ('MS' para mensal). Esta estrutura otimizada permitiu que o modelo

ARIMA acessasse funcionalidades avan√ßadas como detec√ß√£o autom√°tica de


---

# Page 47

47

periodicidade sazonal, aplica√ß√£o de transforma√ß√µes temporais (diferencia√ß√£o), e gera√ß√£o de previs√µes de forma eficiente.

3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o

A avalia√ß√£o de estacionariedade foi conduzida considerando os achados da an√°lise explorat√≥ria que evidenciaram forte tend√™ncia n√£o linear (crescimento exponencial at√© 2022, seguido de decl√≠nio acentuado) e padr√µes sazonais anuais consistentes usando o seguinte:

a) Testes de estacionariedade: O AutoARIMA da Darts realiza testes internos

(ADF) para detectar a presen√ßa de raiz unit√°ria e determinar automaticamente a necessidade de diferencia√ß√£o. b) Estrat√©gia de diferencia√ß√£o: O AutoARIMA foi configurado para explorar automaticamente:

a. Diferencia√ß√£o n√£o sazonal (d): Testadas ordens de 0 a 2, sendo ùëë =  1

(primeira diferen√ßa) a mais comum para remover tend√™ncia linear. b. Diferencia√ß√£o sazonal (D): Avaliada com per√≠odo 12 (sazonalidade anual), testando ùê∑ =  0 (sem diferencia√ß√£o sazonal) e ùê∑ =  1 (uma diferencia√ß√£o sazonal para remover padr√µes sazonais n√£o estacion√°rios).

O processo de diferencia√ß√£o foi crucial para transformar a s√©rie n√£o estacion√°ria original em uma s√©rie com propriedades estat√≠sticas est√°veis, evitando regress√µes esp√∫rias e garantindo a validade dos pressupostos do modelo ARIMA. A

biblioteca Darts aplicou estas transforma√ß√µes de forma autom√°tica e revers√≠vel para as previs√µes finais.

3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste

A divis√£o temporal foi implementada seguindo rigorosamente o princ√≠pio de n√£o-sobreposi√ß√£o temporal, essencial para valida√ß√£o real√≠stica de modelos de s√©ries temporais. A estrat√©gia adotada foi:


---

# Page 48

48

a) Conjunto de treino: Primeiros 80% da s√©rie (aproximadamente 105 meses), representando o per√≠odo de outubro de 2014 at√© meados de 2023. Este per√≠odo incluiu a fase de crescimento consistente e o pico hist√≥rico das vendas, fornecendo ao modelo informa√ß√£o suficiente sobre tend√™ncias de longo prazo e padr√µes sazonais estabelecidos;

b) Conjunto de teste: √öltimos 20% da s√©rie (aproximadamente 27 meses), correspondendo ao per√≠odo final at√© setembro de 2025. Este per√≠odo capturou a fase de decl√≠nio das vendas, representando um desafio real de generaliza√ß√£o para o modelo;

c) Justificativa da divis√£o: A propor√ß√£o 80/20 foi escolhida para garantir quantidade suficiente de dados para o treinamento (especialmente importante para capturar m√∫ltiplos ciclos sazonais anuais), ao mesmo tempo que preservou um horizonte de teste representativo para avaliar performance preditiva.

A implementa√ß√£o utilizou m√©todos nativos da Darts, que garantiram preserva√ß√£o da estrutura temporal e evitaram vazamento de informa√ß√µes futuras para o conjunto de treino.

3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q

A parametriza√ß√£o do modelo foi conduzida atrav√©s do AutoARIMA da Darts, que implementou uma busca sistem√°tica e otimizada pelos melhores par√¢metros

SARIMA(p,d,q)(P,D,Q)s. Os par√¢metros foram definidos como:

b) Par√¢metros n√£o sazonais:

a. p (ordem autorregressiva): N√∫mero de lags da s√©rie defasada utilizados como preditores. Testadas ordens de 0 a 5, onde ùëù =  1 indica depend√™ncia do valor anterior, ùëù =  2 inclui os dois valores anteriores etc.;

b. d (ordem de diferencia√ß√£o): N√∫mero de diferencia√ß√µes aplicadas para tornar a s√©rie estacion√°ria. Avaliadas ordens de 0 a 2, baseadas nos testes de estacionariedade;


---

# Page 49

49

c. q (ordem de m√©dia m√≥vel): N√∫mero de erros de previs√£o defasados inclu√≠dos no modelo. Testadas ordens de 0 a 5, capturando depend√™ncias nos termos de erro. c) Par√¢metros sazonais (per√≠odo ùë† =  12):

a. P (autorregressivo sazonal): Depend√™ncia de valores sazonais defasados (ex.: mesmo m√™s do ano anterior). Testadas ordens de 0 a 2;

b. D (diferencia√ß√£o sazonal): Diferencia√ß√£o aplicada com per√≠odo sazonal para remover n√£o estacionariedade sazonal. Avaliadas ordens de 0 a 1;

c. Q (m√©dia m√≥vel sazonal): Erros sazonais defasados inclu√≠dos no modelo. Testadas ordens de 0 a 2.

Para crit√©rio de sele√ß√£o, o AutoARIMA utilizou o AIC para balancear qualidade do ajuste com parcim√¥nia do modelo, selecionando automaticamente a configura√ß√£o que minimizou o AIC. O algoritmo implementou busca stepwise para efici√™ncia computacional, explorando configura√ß√µes vizinhas de forma inteligente.

3.2.1.6 Treinamento do modelo

O processo de treinamento foi executado ap√≥s a sele√ß√£o autom√°tica dos melhores par√¢metros, utilizando os algoritmos de estima√ß√£o implementados na Darts.

O treinamento envolveu:

a) Estima√ß√£o por m√°xima verossimilhan√ßa: Os coeficientes do modelo foram estimados atrav√©s da maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa, que encontrou os par√¢metros que melhor explicaram os dados observados no conjunto de treino;

b) Otimiza√ß√£o num√©rica: O processo utilizou algoritmos de otimiza√ß√£o n√£o linear para encontrar os valores √≥timos dos coeficientes, iniciando de valores iniciais estimados e iterando at√© converg√™ncia;

c) Ajuste da componente sazonal: O modelo SARIMA ajustou simultaneamente os padr√µes n√£o sazonais (tend√™ncia de curto prazo, depend√™ncias de lags


---

# Page 50

50

pr√≥ximos) e sazonais (padr√µes anuais, depend√™ncias de per√≠odos equivalentes em anos anteriores);

d) Valida√ß√£o do ajuste: Durante o treinamento, foram monitoradas m√©tricas de converg√™ncia e estabilidade dos coeficientes estimados para garantir adequa√ß√£o do processo de otimiza√ß√£o.

O resultado foi um modelo completamente parametrizado, capaz de capturar tanto as depend√™ncias temporais de curto prazo quanto os padr√µes sazonais anuais identificados na an√°lise explorat√≥ria.

3.2.1.7 Valida√ß√£o do modelo e ajustes finos

A etapa de valida√ß√£o consistiu na gera√ß√£o de previs√µes para todo o horizonte do conjunto de teste e avalia√ß√£o sistem√°tica da performance preditiva:

a) Gera√ß√£o de previs√µes: O modelo treinado foi utilizado para produzir previs√µes recursivas, onde cada previs√£o utilizou apenas informa√ß√µes dispon√≠veis at√© aquele ponto temporal. Este processo simulou fielmente o cen√°rio real de previs√£o operacional;

b) Intervalos de confian√ßa: Foram gerados intervalos de previs√£o (tipicamente

95% de confian√ßa) baseados na vari√¢ncia estimada dos erros do modelo, fornecendo medida de incerteza associada a cada previs√£o;

c) M√©tricas de avalia√ß√£o: A performance foi avaliada atrav√©s do conjunto padronizado de m√©tricas:

a. MAE (Mean Absolute Error): Erro absoluto m√©dio em reais, interpret√°vel diretamente na escala do problema;

b. RMSE (Root Mean Squared Error): Raiz do erro quadr√°tico m√©dio, penalizando mais fortemente grandes desvios;

c. MAPE (Mean Absolute Percentage Error): Erro percentual absoluto m√©dio, permitindo interpreta√ß√£o relativa independente da escala.


---

# Page 51

51

d) An√°lise temporal das previs√µes: Foi conduzida an√°lise per√≠odo a per√≠odo para identificar padr√µes nos erros, sazonalidade residual, e performance diferencial ao longo do horizonte de previs√£o.

3.2.1.8 An√°lise residual

Uma an√°lise detalhada dos res√≠duos do modelo foi conduzida para verificar se os erros de previs√£o se distribu√≠ram de forma aleat√≥ria, sem padr√µes sistem√°ticos n√£o modelados. Foram gerados gr√°ficos de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial

(PACF) dos res√≠duos, buscando confirmar comportamento pr√≥ximo ao ru√≠do branco.

Res√≠duos com padr√µes significativos indicaram que o modelo n√£o conseguiu capturar completamente as rela√ß√µes temporais nos dados. Adicionalmente, a an√°lise incluiu inspe√ß√£o visual da distribui√ß√£o dos res√≠duos e identifica√ß√£o de outliers ou eventos at√≠picos que poderiam comprometer a precis√£o das previs√µes futuras. Esta valida√ß√£o foi essencial para confirmar a adequa√ß√£o do modelo selecionado.

3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura

Foram geradas visualiza√ß√µes espec√≠ficas para documentar o desempenho do modelo ARIMA, incluindo gr√°ficos de s√©rie temporal comparando valores observados e previstos, an√°lise de res√≠duos ao longo do tempo e representa√ß√£o gr√°fica da estrutura de correla√ß√£o do conjunto de dados para diagn√≥stico.

Os resultados do modelo ARIMA, incluindo previs√µes, m√©tricas de desempenho, par√¢metros selecionados e diagn√≥sticos, foram salvos de forma estruturada para posterior compara√ß√£o com os demais modelos (Theta, Suaviza√ß√£o

Exponencial e XGBoost). Esta documenta√ß√£o foi essencial para a an√°lise comparativa final e escolha da abordagem preditiva mais adequada.


---

# Page 52

52

3.2.2 Suaviza√ß√£o Exponencial

A figura a seguir mostra a metodologia utilizada para o modelo.

Fonte: elaborado pelo autor

O modelo de Suaviza√ß√£o Exponencial compartilhou grande parte da metodologia com o ARIMA, diferindo principalmente na abordagem de modelagem e nos crit√©rios de sele√ß√£o do modelo. As etapas de importa√ß√£o de bibliotecas, ingest√£o e convers√£o de dados e a divis√£o treino/teste foram executadas de forma id√™ntica ao

ARIMA, utilizando a mesma biblioteca Darts, mesma estrutura TimeSeries, e mesma propor√ß√£o 80/20 com divis√£o temporal rigorosa.

Figura 11 ‚Äì Metodologia do modelo Suaviza√ß√£o Exponencial


---

# Page 53

53

3.2.2.1 An√°lise de componentes para sele√ß√£o do modelo

Diferentemente do ARIMA, que se baseou em testes de estacionariedade e an√°lise de correlogramas, o modelo de Suaviza√ß√£o Exponencial utilizou os resultados da decomposi√ß√£o STL j√° realizada na an√°lise explorat√≥ria para orientar a sele√ß√£o do tipo apropriado de modelo.

Com base nos componentes j√° extra√≠dos na EDA, a biblioteca Darts implementou crit√©rios autom√°ticos para escolha entre:

a) Suaviza√ß√£o Exponencial Simples (SES): Para s√©ries sem tend√™ncia ou sazonalidade significativas;

b) M√©todo de Holt: Para s√©ries com tend√™ncia forte, mas sazonalidade fraca;

c) M√©todo de Holt-Winters: Para s√©ries com ambos os componentes significativos.

3.2.2.2 Decis√£o entre modelo aditivo e multiplicativo

Uma etapa espec√≠fica da Suaviza√ß√£o Exponencial foi a escolha entre formula√ß√µes aditiva e multiplicativa, baseada na an√°lise dos componentes sazonais da EDA:

a) Modelo Aditivo: Selecionado quando a amplitude da sazonalidade permaneceu relativamente constante ao longo do tempo;

b) Modelo Multiplicativo: Selecionado quando a amplitude da sazonalidade variou proporcionalmente ao n√≠vel da s√©rie.

A decis√£o foi automatizada pela Darts baseada na an√°lise da vari√¢ncia relativa dos componentes sazonais j√° extra√≠dos na EDA.


---

# Page 54

54

3.2.2.3 Configura√ß√£o e otimiza√ß√£o de par√¢metros

Ao contr√°rio do ARIMA, que utilizou par√¢metros discretos (p, d, q), a Suaviza√ß√£o Exponencial otimizou par√¢metros cont√≠nuos de suaviza√ß√£o:

a) Par√¢metros do modelo Holt-Winters:

a. Œ± (alfa): Par√¢metro de suaviza√ß√£o do n√≠vel (0 ‚â§ ùõº‚â§1);

b. Œ≤ (beta): Par√¢metro de suaviza√ß√£o da tend√™ncia (0 ‚â§ ùõΩ‚â§1);

c. Œ≥ (gama): Par√¢metro de suaviza√ß√£o sazonal (0 ‚â§ ùõæ‚â§1). b) Per√≠odo sazonal: Fixado em 12 meses conforme evidenciado na EDA;

c) Processo de otimiza√ß√£o: A Darts utilizou algoritmos de minimiza√ß√£o num√©rica para encontrar os valores √≥timos que minimizaram o erro quadr√°tico m√©dio no conjunto de treino.

3.2.2.4 Treinamento por suaviza√ß√£o recursiva

O processo de treinamento diferiu fundamentalmente do ARIMA por utilizar suaviza√ß√£o exponencial recursiva ao inv√©s de estima√ß√£o de m√°xima verossimilhan√ßa:

a) Inicializa√ß√£o dos componentes:

a. N√≠vel inicial estimado como m√©dia dos primeiros per√≠odos;

b. Tend√™ncia inicial calculada como diferen√ßa m√©dia inicial;

c. √çndices sazonais estimados atrav√©s dos primeiros ciclos da s√©rie. b) Atualiza√ß√£o recursiva: Para cada per√≠odo t do treino, os componentes foram atualizados atrav√©s de combina√ß√µes ponderadas dos valores observados e componentes anteriores projetados.

Este processo iterativo permitiu ao modelo adaptar-se gradualmente aos padr√µes, diferindo da estima√ß√£o simult√¢nea de todos os par√¢metros no ARIMA.


---

# Page 55

55

3.2.2.5 Gera√ß√£o de previs√µes diretas

A gera√ß√£o de previs√µes na Suaviza√ß√£o Exponencial utilizou abordagem direta

(n√£o recursiva) baseada nos componentes finais, projetando o n√≠vel futuro adicionando tend√™ncia multiplicada pelo horizonte ao √∫ltimo n√≠vel, e obtendo o componente sazonal do √≠ndice correspondente ao per√≠odo do ano.

3.2.2.6 An√°lise residual espec√≠fica para suaviza√ß√£o

A an√°lise residual seguiu protocolo similar ao ARIMA, mas com focos espec√≠ficos na valida√ß√£o de componentes (tend√™ncia e sazonalidade), estabilidade dos par√¢metros otimizados, e adequa√ß√£o do modelo selecionado (aditivo vs. multiplicativo) atrav√©s de an√°lise visual dos res√≠duos padronizados e m√©tricas de ajuste.

3.2.3 Theta

O modelo Theta compartilhou as etapas fundamentais de prepara√ß√£o com os modelos anteriores, diferindo principalmente na abordagem de decomposi√ß√£o e extrapola√ß√£o. As etapas de importa√ß√£o de bibliotecas, ingest√£o e convers√£o de dados e divis√£o treino/teste foram executadas de forma id√™ntica aos modelos anteriores, utilizando a mesma biblioteca Darts, mesma estrutura TimeSeries, e mesma divis√£o temporal 80/20.

A figura a seguir mostra a metodologia utilizada para o modelo.


---

# Page 56

56

Fonte: elaborado pelo autor

3.2.3.1 Verifica√ß√£o de pr√©-condi√ß√µes do m√©todo Theta

O m√©todo Theta na biblioteca Darts exigiu verifica√ß√µes espec√≠ficas antes da aplica√ß√£o:

a) Valida√ß√£o da s√©rie temporal: Confirma√ß√£o da aus√™ncia de valores nulos na s√©rie, pois o Theta da Darts n√£o possui tratamento autom√°tico para dados ausentes;

Figura 12 ‚Äì Metodologia do modelo Theta


---

# Page 57

57

b) Verifica√ß√£o de univari√¢ncia: O m√©todo foi aplicado exclusivamente √† s√©rie temporal univariada de faturamento mensal, sem vari√°veis explicativas adicionais, seguindo a natureza original do m√©todo proposto por

Assimakopoulos e Nikolopoulos (2000);

c) Confirma√ß√£o de regularidade temporal: Verifica√ß√£o da frequ√™ncia mensal constante da s√©rie, requisito para a decomposi√ß√£o Theta funcionar adequadamente.

3.2.3.2 Configura√ß√£o autom√°tica vs. manual do modelo

No quesito de configura√ß√£o, o m√©todo Theta da Darts ofereceu configura√ß√£o totalmente autom√°tica:

a) Par√¢metro Theta (Œ∏): A Darts implementou sele√ß√£o autom√°tica do par√¢metro

Œ∏, que controla a curvatura das linhas Theta. Valores menores que 1

enfatizam tend√™ncias de longo prazo, enquanto maiores destacam varia√ß√µes de curto prazo;

b) Detec√ß√£o autom√°tica de sazonalidade: O Theta detectou automaticamente a presen√ßa e o per√≠odo da sazonalidade (12 meses) com base nos padr√µes da s√©rie;

c) Configura√ß√£o de decomposi√ß√£o: O modelo foi configurado para aplicar decomposi√ß√£o autom√°tica da s√©rie em componentes Theta, sem necessidade de especifica√ß√£o manual.

3.2.3.3 Decomposi√ß√£o e cria√ß√£o das linhas Theta

Esta etapa foi espec√≠fica do m√©todo Theta, onde os seguintes pontos foram realizados:

a) Aplica√ß√£o das segundas diferen√ßas: O m√©todo aplicou o operador de segundas diferen√ßas √† s√©rie original conforme a formula√ß√£o matem√°tica de Assimakopoulos e Nikolopoulos (2000);

b) Gera√ß√£o das linhas Theta: Foram criadas m√∫ltiplas linhas Theta atrav√©s de transforma√ß√µes matem√°ticas, incluindo:


---

# Page 58

58

a. Linha Theta 0 (ùúÉ= 0): Representa tend√™ncia linear de longo prazo b. Linha Theta 2 (ùúÉ= 2): Captura varia√ß√µes de curto prazo e sazonalidade.

3.2.3.4 Treinamento e ajuste das componentes

O processo de treinamento do Theta diferiu dos outros modelos no seguinte:

a) Ajuste das linhas individuais: Cada linha Theta foi ajustada separadamente:

a. Linha Theta 0: Ajustada por regress√£o linear para capturar tend√™ncia de longo prazo;

b. Linha Theta 2: Ajustada por Suaviza√ß√£o Exponencial Simples (SES)

para varia√ß√µes de curto prazo. b) Otimiza√ß√£o autom√°tica: A Darts implementou otimiza√ß√£o autom√°tica dos par√¢metros de cada componente.

3.2.3.5 Combina√ß√£o de previs√µes e extrapola√ß√£o

A gera√ß√£o de previs√µes seguiu abordagem √∫nica de combina√ß√£o de extrapola√ß√µes, onde cada linha Theta foi extrapolada separadamente para o horizonte de teste, e as previs√µes finais foram obtidas atrav√©s de combina√ß√£o ponderada das extrapola√ß√µes individuais, tipicamente com pesos iguais ou otimizados baseados na performance hist√≥rica.

3.2.3.6 Avalia√ß√£o e diagn√≥sticos espec√≠ficos

A avalia√ß√£o seguiu protocolo similar aos modelos anteriores, com an√°lises espec√≠ficas de valida√ß√£o das linhas Theta, verifica√ß√£o da capacidade de reconstru√ß√£o da s√©rie original, e an√°lise de estabilidade dos par√¢metros otimizados.


---

# Page 59

59

3.2.4 XGBoost

A figura 3 mostra a metodologia utilizada para o modelo.

Fonte: elaborado pelo autor

3.2.4.1 Prepara√ß√£o e integra√ß√£o com Darts

O modelo XGBoost foi implementado utilizando o m√≥dulo XGBModel da biblioteca Darts, que integra o algoritmo XGBoost com a infraestrutura de s√©ries temporais da Darts. Diferentemente da implementa√ß√£o tradicional que requer engenharia manual extensiva de features, o m√≥dulo da Darts automatiza a cria√ß√£o de features temporais necess√°rias para o treinamento.

A entrada do modelo foi a mesma s√©rie temporal univariada utilizada pelos outros modelos (faturamento mensal agregado), mantendo consist√™ncia na prepara√ß√£o dos dados. A Darts se encarregou automaticamente de transformar esta

Figura 13 ‚Äì Metodologia do modelo XGBoost


---

# Page 60

60

s√©rie temporal em formato tabular apropriado para o XGBoost durante o processo de treinamento.

3.2.4.2 Divis√£o dos dados em treino e teste Engenharia autom√°tica de features

Assim como nos demais modelos, os dados foram divididos respeitando rigorosamente a ordem cronol√≥gica na propor√ß√£o 80/20, evitando vazamento de informa√ß√µes futuras. A Darts garantiu que a divis√£o temporal fosse consistente com os outros modelos implementados.

3.2.4.3 Engenharia autom√°tica de features

O m√≥dulo da Darts criou automaticamente as features necess√°rias atrav√©s de par√¢metros configur√°veis:

a) Lags da vari√°vel target: Foram configurados 17 lags principais [-1, -2, -3, -4,

-5, -6, -7, -8, -9, -10, -11, -12, -15, -18, -24, -30, -36] para capturar depend√™ncias temporais em diferentes horizontes. b) Lags de covariadas passadas: Configurados 8 lags [-1, -2, -3, -4, -5, -6, -12,

-24] para capturar padr√µes adicionais de depend√™ncia temporal. c) Encoders temporais: Foram adicionados automaticamente 6 encoders temporais (m√™s, ano, trimestre, dia do ano, semana do ano, dia da semana)

para capturar padr√µes c√≠clicos e sazonais. d) Normaliza√ß√£o: Aplicada automaticamente via MaxAbsScaler para garantir escala apropriada das features, particularmente importante para lidar com outliers em dados de vendas.

Esta abordagem eliminou a necessidade de criar manualmente features como m√©dias m√≥veis, codifica√ß√µes trigonom√©tricas, e estat√≠sticas agregadas, simplificando significativamente o pipeline e garantindo que apenas as features mais relevantes fossem utilizadas.


---

# Page 61

61

3.2.4.4 Configura√ß√£o dos hiper par√¢metros iniciais

O modelo XGBoost implementado via Darts separou os par√¢metros em duas categorias distintas: par√¢metros espec√≠ficos do framework Darts para processamento de series temporais e hiper par√¢metros do algoritmo XGBoost propriamente dito. a) Par√¢metros do framework Darts (configura√ß√£o de series temporais):

a. lags: 17 valores de defasagem [-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -

12, -15, -18, -24, -30, -36] para capturar depend√™ncias temporais em m√∫ltiplos horizontes. b. lags_past_covariates: 8 lags adicionais [-1, -2, -3, -4, -5, -6, -12, -24] para padr√µes de depend√™ncia temporal complementares. c. add_encoders: Encoders temporais autom√°ticos incluindo m√™s, ano, trimestre, dia do ano, semana do ano e dia da semana para captura de padr√µes c√≠clicos e sazonais. d. data_scaling:

MaxAbsScaler aplicado automaticamente para normaliza√ß√£o robusta das features. b) Hiper par√¢metros do algoritmo XGBoost (passados via kwargs):

a. n_estimators: 2000 arvores de decis√£o para garantir capacidade adequada de aprendizado e converg√™ncia do algoritmo de gradient boosting. b. max_depth: 8 n√≠veis de profundidade m√°xima, controlando a complexidade das arvores individuais e evitando overfitting. c. learning_rate: 0,05 para controlar o peso de cada nova arvore no ensemble, garantindo aprendizado est√°vel e converg√™ncia gradual. d. subsample: 0,9 (90% de amostragem) para aumentar a generaliza√ß√£o do modelo atrav√©s de varia√ß√£o estoc√°stica nas amostras de treinamento. e. colsample_bytree: 0,9 para selecionar aleatoriamente 90% das features em cada arvore, promovendo diversidade no ensemble. f. reg_alpha: 0,2 (regulariza√ß√£o

## ùêø1

ùêøùëéùë†ùë†ùëú) para penalizar complexidade e promover esparsidade nos pesos do modelo.


---

# Page 62

62

g. reg_lambda: 1,5 (regulariza√ß√£o

## ùêø2

ùëÖùëñùëëùëîùëí) para controle adicional de complexidade e suaviza√ß√£o dos pesos. h. random_state: 42 para garantir reprodutibilidade total dos resultados entre execu√ß√µes.

Esta configura√ß√£o hibrida aproveitou a especializa√ß√£o da Darts em processamento de series temporais (gera√ß√£o autom√°tica de lags e encoders temporais) combinada com o poder preditivo do algoritmo XGBoost (ensemble de arvores com gradient boosting). Os hiper par√¢metros do XGBoost foram definidos manualmente com base em pr√°ticas estabelecidas para modelos de previs√£o, priorizando capacidade de aprendizado (n_estimators alto e max_depth moderado)

equilibrada com regulariza√ß√£o (reg_alpha e reg_lambda) para evitar overfitting.

3.2.4.5 Treinamento do modelo

O processo de treinamento do XGBoost seguiu o paradigma de gradient boosting:

a) Inicializa√ß√£o: O processo iniciou com uma previs√£o inicial simples

(geralmente a m√©dia dos valores de treino);

b) Treinamento iterativo: Em cada itera√ß√£o, uma nova √°rvore de decis√£o foi treinada para modelar os res√≠duos (erros) das √°rvores anteriores, corrigindo gradualmente as falhas do modelo;

c) Atualiza√ß√£o das previs√µes: As previs√µes foram atualizadas somando as previs√µes das novas √°rvores √†s previs√µes acumuladas das √°rvores anteriores, multiplicadas pela taxa de aprendizado (learning_rate);

d) Regulariza√ß√£o: Durante o treinamento, os termos de regulariza√ß√£o L1 e L2

foram aplicados para penalizar complexidade excessiva e promover modelos mais simples e generaliz√°veis.

A integra√ß√£o com Darts garantiu que todo este processo respeitasse a natureza temporal dos dados, utilizando apenas informa√ß√µes dispon√≠veis at√© cada ponto temporal durante o treinamento.


---

# Page 63

63

3.2.4.6 Avalia√ß√£o inicial de desempenho

A avalia√ß√£o do desempenho foi realizada de maneira an√°loga aos outros modelos, atrav√©s das m√©tricas MAE, RMSE e MAPE aplicadas ao conjunto de teste.

A an√°lise dos erros permitiu verificar a capacidade do modelo em capturar padr√µes complexos presentes nos dados de vendas.

3.2.4.7 Valida√ß√£o e an√°lise de resultados

Foi empregada valida√ß√£o temporal adequada a s√©ries temporais, assegurando a robustez dos resultados e a aus√™ncia de overfitting. Os resultados da valida√ß√£o foram analisados quanto √† consist√™ncia e poss√≠veis padr√µes residuais, confirmando a adequa√ß√£o do modelo.

3.2.4.8 Gera√ß√£o das previs√µes finais e armazenamento dos resultados

As previs√µes finais geradas pelo modelo XGBoost foram armazenadas em formato estruturado para compara√ß√£o direta com os resultados dos demais modelos

(ARIMA, Theta e Suaviza√ß√£o Exponencial), permitindo an√°lise comparativa abrangente baseada nas mesmas m√©tricas padronizadas.

3.2.5 Power BI

O m√©todo de previs√£o atualmente implementado no Power BI utiliza uma abordagem h√≠brida que combina dois m√©todos estat√≠sticos simples, mas robustos, para gerar previs√µes de faturamento mensal. Este m√©todo foi considerado como baseline (solu√ß√£o de refer√™ncia) para compara√ß√£o com os modelos de machine learning desenvolvidos neste trabalho.

3.2.5.1 Estrutura da solu√ß√£o no Power BI

A solu√ß√£o foi implementada atrav√©s de medidas DAX no Power BI, que realizam c√°lculos autom√°ticos a partir dos geram cobran√ßa (GERA_COBRANCA = 1). Este comportamento sugere que o Theta pode ser mais adequado para s√©ries temporais com padr√µes mais regulares e previs√≠veis.armazenados no banco de dados corporativo. O processo segue a seguinte estrutura:


---

# Page 64

64

a) Medida de Faturamento Realizado: Calcula a soma do faturamento l√≠quido mensal, considerando apenas opera√ß√µes de vendas processadas que geraram cobran√ßa. Esta medida filtra automaticamente os dados pela dimens√£o de data selecionada. b) Medida de Faturamento Mensal: Agrega o faturamento realizado para cada m√™s/ano, garantindo que cada ponto temporal seja associado ao valor correspondente de faturamento. c) Per√≠odo de Teste: Define o intervalo temporal para as previs√µes (julho de

2023 a setembro de 2025), correspondendo aos 27 meses utilizados para valida√ß√£o dos modelos.

3.2.5.2 C√°lculo da previs√£o h√≠brida

O m√©todo h√≠brido combina duas t√©cnicas estat√≠sticas com igual peso (50%

cada):

a) M√©dia M√≥vel de 6 Meses (MM6): Calcula a m√©dia aritm√©tica dos 6 meses anteriores ao per√≠odo de previs√£o. Esta t√©cnica captura tend√™ncias recentes e variabilidades de curto prazo nos dados de vendas, reduzindo o impacto de flutua√ß√µes aleat√≥rias. b) Year-over-Year (YoY): Utiliza o valor de faturamento do mesmo m√™s no ano anterior. Esta t√©cnica captura padr√µes sazonais anuais, presumindo que os padr√µes de vendas se repetem em ciclos anuais.

O c√°lculo final da previs√£o h√≠brida para cada m√™s √© dado por:

ùëÉùëüùëíùë£ùëñùë†√£ùëú ùêª√≠ùëèùëüùëñùëëùëé= (ùëÄùëÄ6 ùë• 0,5) + (ùëåùëúùëå ùë• 0,5)

Esta combina√ß√£o permite que o modelo capture tanto tend√™ncias recentes (via

MM6) quanto padr√µes sazonais (via YoY), equilibrando a adaptabilidade a mudan√ßas curtas com a estabilidade de padr√µes hist√≥ricos anuais.


---

# Page 65

65

3.2.5.3 Extra√ß√£o de dados e compara√ß√£o com modelos de ML

Ap√≥s a implementa√ß√£o das medidas DAX no Power BI, foi criada uma tabela contendo as seguintes colunas para cada m√™s no per√≠odo de teste:

a) M√™s/Ano: Identificador temporal do per√≠odo;

b) Faturamento Real Teste: Valor observado de faturamento para o m√™s, obtido atrav√©s da medida de Faturamento Realizado;

c) Faturamento Previsto (H√≠brido): Valor previsto usando o m√©todo h√≠brido descrito anteriormente.

Esta tabela foi extra√≠da do Power BI em formato CSV e importada em um script

Python para realizar a compara√ß√£o com o melhor modelo de machine learning. As m√©tricas padr√µes (MAE, RMSE e MAPE) foram calculadas diretamente sobre os dados desta tabela, permitindo uma avalia√ß√£o quantitativa equivalente √† realizada para os demais modelos de previs√£o desenvolvidos neste trabalho.

O armazenamento dos dados em formato CSV garante rastreabilidade dos resultados e facilita a reprodutibilidade da an√°lise, permitindo futuras revis√µes e melhorias na metodologia de compara√ß√£o.

## 3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS

Ap√≥s o ajuste e valida√ß√£o de todos os modelos preditivos desenvolvidos neste trabalho, foi realizada uma compara√ß√£o quantitativa do desempenho de cada modelo utilizando as seguintes m√©tricas estat√≠sticas, recomendadas pela literatura para problemas de previs√£o de s√©ries temporais: a) Erro M√©dio Absoluto (MAE); b) Raiz do Erro Quadr√°tico M√©dio (RMSE); c) Erro Percentual Absoluto M√©dio (MAPE).


---

# Page 66

66

3.3.1 Compara√ß√£o entre os modelos de aprendizado de m√°quina e estat√≠sticos

As m√©tricas foram calculadas para o conjunto de teste de cada modelo (27

meses, de julho de 2023 a setembro de 2025), permitindo uma avalia√ß√£o consistente e compar√°vel. Este processo seguiu a metodologia recomendada pela literatura para compara√ß√£o de modelos de previs√£o de s√©ries temporais, conforme Hyndman et al.

(1999) e Gardner (1985).

Os quatro modelos implementados (ARIMA, Exponential Smoothing, Theta e XGBoost) foram submetidos ao mesmo conjunto de teste com as mesmas m√©tricas de erro calculadas de forma padronizada. Esse procedimento permitiu uma compara√ß√£o quantitativa objetiva do desempenho de cada abordagem, considerando tanto modelos estat√≠sticos tradicionais quanto algoritmos de aprendizado de m√°quina.

3.3.2 Compara√ß√£o do melhor modelo de ML versus m√©todo Power BI

Na sequ√™ncia, o modelo de melhor desempenho entre os algoritmos de machine learning foi comparado diretamente ao m√©todo de previs√£o h√≠brido atualmente implementado no Power BI. Esta compara√ß√£o adicional √© essencial para responder √† quest√£o central de pesquisa deste trabalho: se modelos avan√ßados de aprendizado de m√°quina conseguem superar uma abordagem estat√≠stica simples, mas consolidada.

O procedimento de compara√ß√£o seguiu a mesma metodologia utilizada para a compara√ß√£o entre os modelos de ML. As m√©tricas MAE, RMSE e MAPE foram calculadas para ambos os modelos utilizando o mesmo per√≠odo de teste (27 meses, de julho de 2023 a setembro de 2025), permitindo uma avalia√ß√£o consistente e direta da efetividade de cada abordagem.


---

# Page 67

67

## 4 AN√ÅLISE DOS RESULTADOS

Nesta se√ß√£o s√£o apresentados os resultados da implementa√ß√£o e avalia√ß√£o de todos os modelos de previs√£o desenvolvidos neste trabalho. Os resultados s√£o organizados por modelo, apresentando as m√©tricas de desempenho obtidas no conjunto de teste (27 meses, de julho de 2023 a setembro de 2025) para cada abordagem.

4.1 RESULTADOS DOS MODELOS DE APRENDIZADO DE M√ÅQUINA E

## ESTAT√çSTICOS

Esta subse√ß√£o detalha o desempenho de cada t√©cnica (ARIMA, Exponential

Smoothing, Theta e XGBoost), organizados em ordem de sofistica√ß√£o crescente. A

apresenta√ß√£o segue uma progress√£o que permite visualizar claramente como a capacidade preditiva evoluiu entre os modelos tradicionais estat√≠sticos at√© as abordagens mais avan√ßadas de machine learning.

## 4.1.1 ARIMA

O modelo ARIMA implementado utilizando AutoARIMA da biblioteca Darts apresentou os seguintes resultados no conjunto de teste:

Quadro 1 - Resultados das M√©tricas do Modelo ARIMA

M√©trica

Valor

## MAE

## R$ 121.014,75

## RMSE

## R$ 143.364,02

## MAPE

33,61%

Fonte: elaborado pelo autor

O ARIMA apresentou o desempenho mais inferior entre todos os modelos testados.

O modelo dificuldade em capturar adequadamente os padr√µes complexos presentes nos dados de vendas, resultando em erros absolutamente elevados. O


---

# Page 68

68

MAPE de 33,61% indica que, em m√©dia, as previs√µes do ARIMA desviaram 33,61%

dos valores reais observados, demonstrando capacidade preditiva muito limitada para este conjunto de dados espec√≠fico.

4.1.2 Suaviza√ß√£o Exponencial

O modelo de Suaviza√ß√£o Exponencial foi implementado utilizando a classe

ExponentialSmoothing da Darts, aplicando o m√©todo de Holt-Winters para capturar componentes de n√≠vel, tend√™ncia e sazonalidade.

Os resultados obtidos foram:

Quadro 2 - Resultados das M√©tricas do Modelo Suaviza√ß√£o Exponencial

M√©trica

Valor

## MAE

## R$ 107.171,15

## RMSE

## R$ 137.369,02

## MAPE

23,99%

Fonte: elaborado pelo autor

O modelo apresentou desempenho superior ao ARIMA em todas as m√©tricas, reduzindo o erro em 11,5% em rela√ß√£o ao MAE do ARIMA. O

MAPE de 23,99% indica erros significativos nas previs√µes. O modelo demonstrou melhor capacidade que o ARIMA em capturar a sazonalidade dos dados, por√©m ainda se mostrou insuficiente para gerar previs√µes com acur√°cia adequada para fins organizacionais.

4.1.3 Theta

O m√©todo Theta foi implementado utilizando a classe AutoTheta da Darts, que aplica automaticamente t√©cnicas de decomposi√ß√£o temporal para capturar padr√µes de longo e curto prazo na s√©rie. Os resultados foram:


---

# Page 69

69

Quadro 3 - Resultados das M√©tricas do Modelo Theta

M√©trica

Valor

## MAE

## R$ 186.346,45

## RMSE

## R$ 233.478,88

## MAPE

40,30%

Fonte: elaborado pelo autor

O m√©todo Theta apresentou um desempenho moderado entre os modelos de s√©ries temporais. Embora tenha obtido resultados superiores ao ARIMA, o modelo mostrou-se inferior √† Suaviza√ß√£o Exponencial neste contexto espec√≠fico. O MAPE de 40,30% representa uma redu√ß√£o significativa na magnitude dos erros percentuais, indicando que o m√©todo sazonais e de tend√™ncia presentes nos dados com o novo filtro de transa√ß√µes que geram cobran√ßa (GERA_COBRANCA = 1). Este comportamento sugere que o Theta pode ser mais adequado para s√©ries temporais com padr√µes mais regulares e previs√≠veis.

4.1.4 XGBoost

O modelo XGBoost foi implementado utilizando a classe XGBModel da Darts com configura√ß√£o de 17 lags principais, 8 lags de covariadas passadas e 6 encoders temporais, combinados com hiper par√¢metros otimizados para o problema espec√≠fico.

Os resultados obtidos foram:

Quadro 4 - Resultados das M√©tricas do Modelo XGBoost Ultimate

M√©trica

Valor

## MAE

## R$ 120.808,89

## RMSE

## R$ 157.902,94

## MAPE

31,66%

Fonte: elaborado pelo autor

O XGBoost Ultimate apresentou desempenho inferior √† Suaviza√ß√£o Exponencial neste contexto espec√≠fico. Com MAPE de 31,66%, o modelo demonstrou melhor capacidade que ARIMA (33,61%) e Theta (40,30%), mas ficou atr√°s da Suaviza√ß√£o Exponencial (23,99%). O modelo conseguiu capturar os padr√µes sazonais e de tend√™ncia dos dados, por√©m com menor precis√£o que a abordagem de suaviza√ß√£o exponencial. Este resultado evidencia que, embora XGBoost seja um algoritmo sofisticado, sua complexidade n√£o necessariamente resulta em melhor desempenho em s√©ries temporais com padr√µes bem definidos e volume limitado de observa√ß√µes.

## 4.2 RESUMO COMPARATIVO DOS MODELOS DE ML

A tabela abaixo apresenta um resumo consolidado dos resultados de todos os modelos de machine learning e estat√≠sticos:

Quadro 5 - Tabela Comparativa dos Modelos

Modelo

## MAE

## RMSE

## MAPE

Suaviza√ß√£o Exponencial

## R$ 107.171,15

## R$ 137.369,02

23,99%

XGBoost

## R$ 120.808,89

## R$ 157.902,94

31,66%

## ARIMA

## R$ 121.014,75

## R$ 143.364,02

33,61%

Theta

## R$ 186.346,45

## R$ 233.478,88

40,30%

Fonte: elaborado pelo autor

Com base nesta an√°lise, a Suaviza√ß√£o Exponencial foi identificada como o melhor modelo entre os algoritmos de machine learning testados, com MAPE de 23,99%, seguida pelo XGBoost Ultimate com 31,66%. Para a pr√≥xima etapa de compara√ß√£o com a abordagem implementada no Power BI, optou-se por utilizar o XGBoost Ultimate como representante dos modelos de ML, considerando sua maior complexidade e potencial para cen√°rios com maior volume de dados.

## 4.3 COMPARA√á√ÉO: MODELOS DE MACHINE LEARNING VERSUS M√âTODO POWER BI

Ap√≥s identificar a Suaviza√ß√£o Exponencial como o melhor modelo entre os algoritmos de machine learning testados (MAPE 23,99%), foi realizada uma compara√ß√£o direta com o m√©todo de previs√£o h√≠brido implementado no Power BI. Esta compara√ß√£o √© fundamental para responder √† quest√£o de pesquisa central deste trabalho.

Os resultados obtidos foram os seguintes:


---

# Page 71

71

Quadro 6 - Tabela Comparativa entre Power BI e Suaviza√ß√£o Exponencial

M√©todo

## MAE

## RMSE

## MAPE

Power BI

## R$ 89.651,22

## R$ 113.475,15

21,82%

Suaviza√ß√£o Exponencial

## R$ 107.171,15

## R$ 137.369,02

23,99%

Fonte: elaborado pelo autor

Como visto no quadro 6, o m√©todo h√≠brido implementado no Power BI, que combina 50% de M√©dia M√≥vel 6 Meses com 50% de YoY, apresentou desempenho superior at√© mesmo ao melhor modelo de ML (Suaviza√ß√£o Exponencial):

a) MAPE: Power BI obteve 21,82% enquanto Suaviza√ß√£o Exponencial alcan√ßou 23,99%, representando uma diferen√ßa de 2,17 pontos percentuais a favor do Power BI. Este resultado √© ainda mais impressionante ao considerar que a Suaviza√ß√£o Exponencial √© o melhor modelo de machine learning testado;

b) MAE: Power BI obteve R$ 89.651,22 enquanto Suaviza√ß√£o Exponencial alcan√ßou R$

107.171,15, evidenciando erro absoluto m√©dio 19,5% maior no melhor modelo de ML;

uma melhoria relativa de 99,1% em favor do Power BI;

c) RMSE: Power BI obteve R$ 113.475,15 enquanto Suaviza√ß√£o Exponencial alcan√ßou R$

137.369,02, indicando maior variabilidade dos erros no modelo de ML mesmo considerando o melhor desempenho entre os algoritmos testados.



## 4.4 LIMITA√á√ïES E DESAFIOS T√âCNICOS

Embora os resultados apresentados sejam relevantes, √© importante reconhecer as limita√ß√µes inerentes ao estudo. O conjunto de dados compreende 132 observa√ß√µes mensais, volume modesto em contextos de machine learning, particularmente para otimizar o potencial de modelos complexos como XGBoost que tendem a se beneficiar de amostras maiores. A s√©rie temporal apresenta tend√™ncia n√£o-linear pronunciada com crescimento exponencial seguido de decl√≠nio acentuado, al√©m de n√£o-

estacionariedade que exigiu transforma√ß√µes extensivas. Estas transforma√ß√µes, embora necess√°rias, podem limitar a capacidade dos modelos em prever comportamentos fora do padr√£o hist√≥rico observado ou em cen√°rios de mudan√ßa estrutural nos padr√µes de vendas.


---

# Page 72

72

A divis√£o temporal fixa na propor√ß√£o 80/20 n√£o permite valida√ß√£o cruzada em m√∫ltiplas janelas temporais, limitando a robustez da avalia√ß√£o a um √∫nico per√≠odo de teste. Esta abordagem n√£o quantifica variabilidade de desempenho quando modelos s√£o aplicados a diferentes per√≠odos hist√≥ricos. Adicionalmente, embora a Darts forne√ßa uma interface unificada para modelagem, os hiper par√¢metros do XGBoost n√£o foram submetidos a otimiza√ß√£o sistem√°tica atrav√©s de Grid Search ou Random

Search, o que poderia potencialmente identificar configura√ß√µes ainda mais otimizadas.

O c√°lculo do Power BI, apesar de seu excelente desempenho, utiliza apenas dois componentes (MM6 e YoY) com pesos fixos e iguais (50% cada), sem explora√ß√£o de combina√ß√µes alternativas, pesos adaptativos ou ajuste din√¢mico baseado em caracter√≠sticas do per√≠odo. Extens√µes do m√©todo, como pondera√ß√£o sazonal ou ajustes de tend√™ncia, n√£o foram investigadas e poderiam potencialmente melhorar ainda mais o desempenho.

No contexto de implementa√ß√£o pr√°tica, a depend√™ncia de dados extra√≠dos de sistemas corporativos legados introduz riscos de inconsist√™ncia, atrasos de atualiza√ß√£o ou erros de integra√ß√£o que poderiam degradar a acur√°cia das previs√µes.

A natureza de "caixa preta" do XGBoost, embora ofere√ßa capacidade preditiva superior, limita significativamente a explicabilidade das previs√µes a pessoas n√£o t√©cnicas, dificultando a aceita√ß√£o organizacional e auditoria das recomenda√ß√µes.

Por fim, os resultados e conclus√µes deste trabalho refletem o contexto espec√≠fico desta organiza√ß√£o, incluindo seus padr√µes de sazonalidade √∫nicos, estrutura de produtos, base de clientes e ciclos econ√¥micos. Generaliza√ß√£o destas conclus√µes para outras organiza√ß√µes, setores ou contextos deve ser realizada com prud√™ncia, reconhecendo que diferentes neg√≥cios apresentam caracter√≠sticas fundamentalmente distintas que podem requerer abordagens de previs√£o adaptadas.


---

# Page 73

73

## 5 CONCLUS√ÉO

O problema que orientou este trabalho foi: "Modelos avan√ßados de aprendizado de m√°quina podem proporcionar previs√µes mais precisas de faturamento, quando comparados √† abordagem utilizada em dashboards de Power BI?". A resposta, baseada em an√°lise emp√≠rica rigorosa realizada em 132 observa√ß√µes mensais de faturamento (outubro de 2014 a setembro de 2025), √© contundente: N√£o. Modelos avan√ßados de aprendizado de m√°quina n√£o superaram o m√©todo h√≠brido implementado no Power BI para este contexto espec√≠fico.
A an√°lise comparativa envolveu quatro modelos de s√©ries temporais (ARIMA com MAPE 33,61%, Suaviza√ß√£o Exponencial com 23,99%, Theta com 40,30% e XGBoost Ultimate com 31,66%) contra o c√°lculo feito no Power BI baseado em M√©dia M√≥vel 6 Meses combinada com YoY (MAPE 21,82%). O resultado mais significativo √© que o c√°lculo feito no Power BI, uma combina√ß√£o simples de dois componentes estat√≠sticos b√°sicos, superou o melhor modelo de ML (Suaviza√ß√£o Exponencial), evidenciando que sofistica√ß√£o algor√≠tmica n√£o necessariamente resulta em melhor desempenho preditivo para este contexto espec√≠fico.
Esta descoberta √© particularmente relevante considerando que o XGBoost Ultimate, utilizava 17 lags principais, 8 lags de covariadas e 6 encoders temporais, representando uma infraestrutura computacional significativamente mais complexa que a abordagem simples do Power BI. O resultado evidencia que, para s√©ries temporais com sazonalidade clara e padr√µes bem definidos, m√©todos estat√≠sticos simples e bem estabelecidos podem ser superiores a algoritmos sofisticados.
Al√©m da superioridade em acur√°cia, o c√°lculo feito no Power BI apresenta vantagens operacionais substantivas que refor√ßam sua adequa√ß√£o. A interpretabilidade imediata dos componentes (MM6 e YoY) facilita a aceita√ß√£o organizacional e auditoria das previs√µes junto a stakeholders n√£o t√©cnicos, ao contr√°rio do XGBoost que funciona como "caixa preta". A aus√™ncia de hiper par√¢metros complexos garante estabilidade previs√≠vel com novos dados e reduz riscos de degrada√ß√£o de desempenho. A manuten√ß√£o √© praticamente nula, enquanto modelos de ML requerem monitoramento cont√≠nuo e poss√≠vel revis√£o peri√≥dica. Estes fatores cumulativos indicam que a superioridade observada do Power BI n√£o √© meramente estat√≠stica, mas fundamentalmente operacional e organizacional.


---

# Page 74

74

Os desafios t√©cnicos enfrentados incluem volume modesto de dados (132 observa√ß√µes) em rela√ß√£o ao potencial de modelos complexos,  n√£o-estacionariedade pronunciada que exigiu transforma√ß√µes extensivas, divis√£o temporal fixa (80/20) que limitou valida√ß√£o a per√≠odo √∫nico, e sele√ß√£o de hiper par√¢metros do XGBoost Ultimate sem otimiza√ß√£o sistem√°tica exaustiva. Reconhece-se que o m√©todo Power BI, apesar de superior, utiliza apenas dois componentes com pesos fixos, deixando potencial para extens√µes como pesos adaptativos ou componentes adicionais. Estas limita√ß√µes, contudo, n√£o alteram a conclus√£o central: para este contexto espec√≠fico, simplicidade prevaleceu sobre complexidade.

As contribui√ß√µes deste trabalho incluem:

a) valida√ß√£o emp√≠rica de cen√°rio onde m√©todos simples superam algoritmos sofisticados, refor√ßando relev√¢ncia de m√©todos estat√≠sticos tradicionais;

b) demonstra√ß√£o de que viabilidade operacional, interpretabilidade e estabilidade s√£o igualmente cr√≠ticas que acur√°cia estat√≠stica na sele√ß√£o de m√©todos;

c) detalhamento metodol√≥gico completo de implementa√ß√£o e compara√ß√£o padronizada de quatro abordagens distintas;

d) reafirma√ß√£o de li√ß√£o fundamental para profissionais de dados, onde a

"melhor" solu√ß√£o frequentemente n√£o √© a mais sofisticada tecnicamente, mas a mais adequada ao contexto.

Do ponto de vista pr√°tico, conclui-se que m√©todo Power BI deve ser mantido como principal ferramenta de previs√£o, com aloca√ß√£o de recursos em outras oportunidades onde machine learning possa oferecer vantagens mais substantivas.

Contudo, an√°lises futuras segmentadas por categoria de produto, per√≠odo sazonal ou unidade de neg√≥cio podem revelar contextos em que abordagens diferenciadas sejam necess√°rias.

Trabalhos futuros dever√£o explorar:

a) Incorpora√ß√£o de vari√°veis ex√≥genas nos modelos de ML;

b) An√°lise segmentada por categoria ou unidade de neg√≥cio;

c) Abordagens de ensemble combinando Power BI com ML de forma adaptativa;


---

# Page 75

75

d) M√©todos ML mais avan√ßados (LSTM, redes neurais recorrentes) para compara√ß√£o;

e) Diferentes horizontes de previs√£o para avaliar desempenho em longo prazo;

f) Monitoramento cont√≠nuo do Power BI com reavalia√ß√£o peri√≥dica caso novos dados ou mudan√ßas estruturais nos padr√µes de vendas sejam observados.

Conclui-se definitivamente que, para este trabalho, a resposta ao problema de pesquisa √©: modelos avan√ßados de aprendizado de m√°quina n√£o conseguiram superar o m√©todo Power BI. Esta conclus√£o reafirma uma li√ß√£o fundamental para profissionais de dados, cientistas de dados e tomadores de decis√£o: a escolha do melhor m√©todo nem sempre favorece a solu√ß√£o mais sofisticada. Efetividade pr√°tica, interpretabilidade, estabilidade e adequa√ß√£o ao contexto organizacional s√£o crit√©rios igualmente importantes que devem ser considerados na sele√ß√£o de abordagens para problemas reais de previs√£o. A simplicidade bem aplicada frequentemente supera a complexidade quando ambas s√£o avaliadas em seus contextos operacional e organizacional completo.


---

# Page 76

76

## REFER√äNCIAS

ASSIMAKOPOULOS, V.; NIKOLOPOULOS, K. The Theta model: a decomposition approach to forecasting. International Journal of Forecasting, v. 16, n. 4, p. 521‚Äì

530, out. 2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00066-2.

BEZERRA, Manoel Ivanildo Silvestre. Apostila de An√°lise de S√©ries Temporais.

S√£o Paulo: UNESP, 2006. Dispon√≠vel em:

https://www.ibilce.unesp.br/Home/Departamentos/MatematicaEstatistica/apostila_ser ies_temporais_unesp.pdf.

BOX, G. E. P. et al. Time series analysis: forecasting and control. Hoboken, New

Jersey: John Wiley & Sons, 2015.

CHEN, T.; GUESTRIN, C. XGBoost: a Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ‚Äô16, v. 1, n. 1, p. 785‚Äì794, 13 ago. 2016. Dispon√≠vel em:

https://doi.org/10.1145/2939672.2939785.

DAIRU, X.; SHILONG, Z. Machine Learning Model for Sales Forecasting by

Using XGBoost. Dispon√≠vel em:

https://doi.org/10.1109/ICCECE51280.2021.9342304.

ENSAFI, Y. et al. Time-series forecasting of seasonal items sales using machine learning ‚Äì A comparative analysis. International Journal of Information

Management Data Insights, v. 2, n. 1, p. 100058, abr. 2022. Dispon√≠vel em:

https://doi.org/10.1016/j.jjimei.2022.100058.

FATTAH, J. et al. Forecasting of demand using ARIMA model. International Journal of Engineering Business Management, v. 10, n. 1, p. 184797901880867, Jan.

2018. Dispon√≠vel em: https://journals.sagepub.com/doi/10.1177/1847979018808673.


---

# Page 77

77

FIORUCCI, J. A. et al. Models for optimising the theta method and their relationship to state space models. International Journal of Forecasting, v. 32, n. 4, p. 1151‚Äì

1161, out. 2016. Dispon√≠vel em: https://doi.org/10.1016/j.ijforecast.2016.02.005.

FOURKIOTIS, K. P.; TSADIRAS, A. Applying Machine Learning and Statistical

Forecasting Methods for Enhancing Pharmaceutical Sales Predictions. Forecasting, v. 6, n. 1, p. 170‚Äì186, 1 mar. 2024. Dispon√≠vel em:

https://doi.org/10.3390/forecast6010010.

GARDNER, E. S. Exponential smoothing: The state of the art. Journal of

Forecasting, v. 4, n. 1, p. 1‚Äì28, 1985. Dispon√≠vel em:

https://doi.org/10.1002/for.3980040103.

KONTOPOULOU, V. I. et al. A Review of ARIMA vs. Machine Learning Approaches for Time Series Forecasting in Data Driven Networks. Future Internet, v. 15, n. 8, p.

255, 1 ago. 2023. Dispon√≠vel em: https://doi.org/10.3390/fi15080255.

LOZIA, Z. Application of modelling and simulation to evaluate the theta method used in diagnostics of automotive shock absorbers. The Archives of Automotive

Engineering ‚Äì Archiwum Motoryzacji, v. 96, n. 2, p. 5‚Äì30, 30 jun. 2022. Dispon√≠vel em: https://doi.org/10.14669/AM/150823.

MAKRIDAKIS, S.; HIBON, M. The M3-Competition: results, conclusions and implications. International Journal of Forecasting, v. 16, n. 4, p. 451‚Äì476, out.

2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00057-1.

MAKRIDAKIS, S.; WHEELWRIGHT, S. C.; HYNDMAN, R. J. Forecasting: Methods and Applications. In: Elements of Forecasting. Oxfordshire: Taylor & Francis, 1999. p. 345‚Äì346. Dispon√≠vel em:

https://www.researchgate.net/publication/52008212_Forecasting_Methods_and_Appl ications.


---

# Page 78

78

MALIK, Shubham; HARODE, Rohan; KUNWAR, Akash Singh. XGBoost: a deep dive into boosting. Medium Blog, 2020. Dispon√≠vel em:

http://dx.doi.org/10.13140/RG.2.2.15243.64803.

MCKENZIE, ED. General exponential smoothing and the equivalent arma process. Journal of Forecasting, v. 3, n. 3, p. 333‚Äì344, Jul. 1984. Dispon√≠vel em:

https://doi.org/10.1002/for.3980030312.

MONDAL, P.; SHIT, L.; GOSWAMI, S. Study of Effectiveness of Time Series

Modeling (Arima) in Forecasting Stock Prices. International Journal of Computer

Science, Engineering and Applications, v. 4, n. 2, p. 13‚Äì29, 30 abr. 2014.

Dispon√≠vel em: https://doi.org/10.5121/ijcsea.2014.4202.

MURAT, M. et al. Forecasting daily meteorological time series using ARIMA and regression models. International Agrophysics, v. 32, n. 2, p. 253‚Äì264, 1 abr. 2018.

Dispon√≠vel em: https://doi.org/10.1515/intag-2017-0007.

NEWBOLD, P. ARIMA model building and the time series analysis approach to forecasting. Journal of Forecasting, v. 2, n. 1, p. 23‚Äì35, Jan. 1983. Dispon√≠vel em:

https://doi.org/10.1002/for.3980020104.

PAO, James J.; SULLIVAN, Danielle S. Time series sales forecasting. Final year project, Computer Science, Stanford Univ., Stanford, CA, USA, 2017. Dispon√≠vel em:

https://cs229.stanford.edu/proj2017/final-reports/5244336.pdf.

PARZEN, E. An Approach to Time Series Analysis. The Annals of Mathematical

Statistics, v. 32, n. 4, p. 951‚Äì989, 1961. Dispon√≠vel em:

https://www.jstor.org/stable/2237900.

SHIRI, F. M. et al. A Comprehensive Overview and Comparative Analysis on Deep

Learning Models. Journal on Artificial Intelligence, v. 6, n. 1, p. 301‚Äì360, 2024.

Dispon√≠vel em: https://doi.org/10.32604/jai.2024.054314.


---

# Page 79

79

SPILIOTIS, E.; ASSIMAKOPOULOS, V.; MAKRIDAKIS, S. Generalizing the Theta method for automatic forecasting. European Journal of Operational Research,

Jan. 2020. Dispon√≠vel em: http://dx.doi.org/10.1016/j.ejor.2020.01.007.

VAVLIAKIS, K.; SIAILIS, A.; SYMEONIDIS, A. Optimizing Sales Forecasting in e-

Commerce with ARIMA and LSTM Models. Proceedings of the 17th International

Conference on Web Information Systems and Technologies, 2021. Dispon√≠vel em: https://doi.org/10.5220/0010659500003058.
