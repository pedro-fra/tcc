## UNIVERSIDADE DO VALE DO RIO DOS SINOS (UNISINOS)

## UNIDADE ACAD√äMICA DE GRADUA√á√ÉO CURSO DE ENGENHARIA DA

## COMPUTA√á√ÉO

## PEDRO DELAVALD FR√Å

## PREVIS√ÉO DE VENDAS:

An√°lise comparativa entre abordagens de aprendizado de m√°quina e Power BI
S√£o Leopoldo
2025

---

# Page 2

2

## PEDRO DELAVALD FR√Å

## PREVIS√ÉO DE VENDAS:

An√°lise comparativa entre abordagens de aprendizado de m√°quina e Power BI
Trabalho de
Conclus√£o de
Curso apresentado como requisito parcial para
obten√ß√£o do t√≠tulo de Bacharel em
Engenharia da Computa√ß√£o, pelo Curso de
Engenharia da
Computa√ß√£o da
Universidade do Vale do Rio dos Sinos

## (UNISINOS)

Orientador: Prof. MSc. Jean Schmith
S√£o Leopoldo
2025

---

# Page 3

## RESUMO

Este trabalho tem como objetivo avaliar e comparar o desempenho de diferentes m√©todos de previs√£o de vendas, utilizando tanto t√©cnicas estat√≠sticas
tradicionais quanto algoritmos modernos de aprendizado de m√°quina, aplicados a dados reais de faturamento extra√≠dos de um dashboard corporativo em Power BI.
Diante do aumento da competitividade e da demanda por decis√µes empresariais baseadas em dados, destaca-se a necessidade de modelos preditivos cada vez mais
precisos e robustos. O estudo envolve a implementa√ß√£o dos modelos ARIMA, Theta, Suaviza√ß√£o Exponencial e XGBoost, analisando suas performances preditivas e as
possibilidades de ado√ß√£o dessas abordagens no contexto empresarial. Os resultados s√£o avaliados a partir de m√©tricas estat√≠sticas padronizadas, permitindo identificar se
algum modelo apresenta desempenho superior ao m√©todo atualmente empregado. A pesquisa contribui para a aproxima√ß√£o entre teoria e pr√°tica, oferecendo subs√≠dios
para a escolha de m√©todos de previs√£o mais adequados √†s necessidades das organiza√ß√µes e potencializando o valor estrat√©gico das an√°lises de vendas.
Palavras-chave: Previs√£o de Vendas; S√©ries Temporais; Aprendizado de M√°quina;
Power BI; ARIMA; XGBoost; Suaviza√ß√£o Exponencial; M√©todo Theta; Business
Intelligence.

---

# Page 4

## ABSTRACT

This work aims to evaluate and compare the performance of different sales forecasting methods, employing both traditional statistical techniques and modern
machine learning algorithms, applied to real revenue data extracted from a corporate dashboard in Power BI. Given the increasing competitiveness and demand for data-
driven business decisions, there is a growing need for more accurate and robust predictive models. The study involves the implementation of ARIMA, Theta,
Exponential Smoothing, and XGBoost models, analyzing their predictive performance and the feasibility of adopting these approaches in corporate environments. The results
are assessed using standardized statistical metrics, allowing for the identification of models that outperform the currently employed method. This research contributes to
bridging the gap between theory and practice, offering guidance for the selection of forecasting methods that best fit organizational needs and enhancing the strategic
value of sales analytics.
Key-words: Sales Forecasting; Time S√©ries; Machine Learning; Power BI; ARIMA;
XGBoost; Exponential Smoothing; Theta Method; Business Intelligence.

---

# Page 5

## LISTA DE FIGURAS

Figura 1 - Metodologia geral do trabalho ................................................................... 30
Figura 2 - Metodologia do pr√©-processamento .......................................................... 32
Figura 3 - Vis√£o geral da s√©rie temporal ................................................................... 36
Figura 4 ‚Äì Decomposi√ß√£o da s√©rie temporal ............................................................. 37
Figura 5 - An√°lise da sazonalidade ........................................................................... 38
Figura 6 - Propriedades estat√≠sticas da s√©rie temporal ............................................. 39
Figura 7 - An√°lise de distribui√ß√£o .............................................................................. 40
Figura 8 - Evolu√ß√£o temporal das vendas ................................................................. 41
Figura 9 - An√°lise de correla√ß√£o temporal ................................................................. 42
Figura 10 - Metodologia do modelo ARIMA .............................................................. 44
Figura 11 ‚Äì Metodologia do modelo Suaviza√ß√£o Exponencial .................................. 51
Figura 12 ‚Äì Metodologia do modelo Theta ................................................................ 55
Figura 13 ‚Äì Metodologia do modelo XGBoost ........................................................... 58

---

# Page 6

6

## LISTA DE QUADROS

Nenhuma entrada de √≠ndice de ilustra√ß√µes foi encontrada.

---

# Page 7

## LISTA DE SIGLAS

## CNN

Convolutional Neural Network

## RNN

Recurrent Neural Network

## ARIMA

Auto Regressive Integrated Moving Average
XGBoost
X Gradient Boost

## ML

Machine Learning

## PIB

Produto Interno Bruto

## SARIMA

Seasonal Auto Regressive Integrated Moving Average

## LSTM

Long Short-Term Memory

## STL

Seasonal and Trend decomposition using LOESS

## AIC

Akaike Information Criterion

## AR

Auto Regressive

## MA

Moving Average

## SES

Simple Exponential Smoothing

## ACF

Autocorrelation Function

## PACF

Parcial Autocorrelation Function

## KPSS

Kwiatkowski-Phillips-Schmidt-Shin

## ADF

Augmented Dickey Fuller

## RMSSE

Root Mean Squared Scaled Error

## RMSE

Root Mean Squared Error

## MAE

Mean Absolute Error

## BI

Business Intelligence

## GBDT

Gradient Boosting Decision Tree

---

# Page 8

## SUM√ÅRIO

1 INTRODU√á√ÉO ....................................................................................................... 11
1.1 TEMA .................................................................................................................. 11
1.2 DELIMITA√á√ÉO DO TEMA ................................................................................... 12
1.3 PROBLEMA ........................................................................................................ 12
1.4 OBJETIVOS ........................................................................................................ 12
1.4.1 Objetivo geral ................................................................................................. 12
1.4.2 Objetivos espec√≠ficos ..................................................................................... 12
1.5 JUSTIFICATIVA .................................................................................................. 13
2 FUNDAMENTA√á√ÉO TE√ìRICA ............................................................................. 14
2.1 S√âRIES TEMPORAIS ......................................................................................... 14
2.1.1 Conceitos fundamentais e defini√ß√µes .......................................................... 14
2.1.2 Caracter√≠sticas principais .............................................................................. 14
2.1.3 Classifica√ß√µes de s√©ries temporais .............................................................. 15
2.1.4 Exemplos de aplica√ß√£o .................................................................................. 16
2.2 M√âTODO THETA ................................................................................................ 16
2.2.1 Descri√ß√£o geral e origem ............................................................................... 17
2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros .......................................................... 17
2.2.3 Equa√ß√£o da linha Theta ................................................................................. 18
2.2.4 Express√µes aditivas e multiplicativas .......................................................... 18
2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros ..................... 18
2.2.6 Exemplos pr√°ticos de uso ............................................................................. 19
2.3 MODELO ARIMA ................................................................................................ 20
2.3.1 Defini√ß√£o e estrutura do modelo ARIMA ...................................................... 20
2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA ........................................... 21
2.3.3 Como o modelo ARIMA funciona para prever dados futuros? .................. 21
2.3.4 Casos pr√°ticos e exemplos na literatura ...................................................... 22
2.4 SUAVIZA√á√ÉO EXPONENCIAL ........................................................................... 23
2.4.1 Defini√ß√£o e estrutura do m√©todo .................................................................. 23
2.4.2 Vantagens e limita√ß√µes na previs√£o de dados ............................................ 24
2.4.3 Aplica√ß√µes e estudos de caso ...................................................................... 25
2.5 XGBOOST ........................................................................................................... 26
2.5.1 Vis√£o geral do Extreme Gradient Boosting .................................................. 26

---

# Page 9

9
2.5.2 Caracter√≠sticas e conceitos do XGBoost ..................................................... 27
2.5.3 Como o XGBoost prev√™ dados futuros ........................................................ 27
2.5.4 Exemplos pr√°ticos de uso do XGBoost ........................................................ 29
3 METODOLOGIA .................................................................................................... 30
3.1 METODOLOGIA DE TRABALHO ....................................................................... 30
3.1.1 Defini√ß√£o do problema e objetivos da previs√£o .......................................... 31
3.1.2 Coleta e pr√©-processamento dos dados ...................................................... 31
3.1.2.1 Filtragem e agrega√ß√£o inicial ......................................................................... 32
3.1.2.3 Agrega√ß√£o temporal mensal .......................................................................... 33
3.1.2.4 Convers√£o para formato Darts ...................................................................... 33
3.1.2.5 Considera√ß√µes sobre engenharia de features ............................................... 33
3.1.3 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal ............................... 34
3.1.3.1 Vis√£o geral da s√©rie temporal ........................................................................ 35
3.1.3.2 Decomposi√ß√£o STL ....................................................................................... 36
Fonte: elaborado pelo autor ...................................................................................... 37
3.1.3.3 An√°lise de sazonalidade ................................................................................ 37
3.1.3.4 Propriedades estat√≠sticas .............................................................................. 38
Fonte: elaborado pelo autor ...................................................................................... 39
3.1.3.5 An√°lise de distribui√ß√£o ................................................................................... 39
3.1.3.6 Evolu√ß√£o temporal detalhada ........................................................................ 40
Fonte: elaborado pelo autor ...................................................................................... 41
3.1.3.7 An√°lise de correla√ß√£o temporal ..................................................................... 41
Fonte: elaborado pelo autor ...................................................................................... 42
3.1.3.8 Insights para modelagem .............................................................................. 42
3.2 MODELOS DE PREVIS√ÉO UTILIZADOS ........................................................... 43
3.2.1 ARIMA .............................................................................................................. 44
3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente ............................... 44
3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal ................................... 45
3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o ............................................ 46
3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste ........................................ 46
3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q ................................................................. 47
3.2.1.6 Treinamento do modelo ................................................................................. 48
3.2.1.7 Valida√ß√£o do modelo e ajustes finos ............................................................. 49
3.2.1.8 An√°lise residual ............................................................................................. 50

---

# Page 10

10
3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura ............................. 50
3.2.2 Suaviza√ß√£o Exponencial ................................................................................ 51
3.2.2.1 An√°lise de componentes para sele√ß√£o do modelo ........................................ 52
3.2.2.2 Decis√£o entre modelo aditivo e multiplicativo ................................................ 52
3.2.2.3 Configura√ß√£o e otimiza√ß√£o de par√¢metros .................................................... 53
3.2.2.4 Treinamento por suaviza√ß√£o recursiva .......................................................... 53
3.2.2.5 Gera√ß√£o de previs√µes diretas ........................................................................ 54
3.2.2.6 An√°lise residual espec√≠fica para suaviza√ß√£o ................................................. 54
3.2.3 Theta ................................................................................................................ 54
3.2.3.1 Verifica√ß√£o de pr√©-condi√ß√µes do m√©todo Theta ............................................ 55
3.2.3.2 Configura√ß√£o autom√°tica vs. manual do modelo ........................................... 56
3.2.3.3 Decomposi√ß√£o e cria√ß√£o das linhas Theta .................................................... 56
3.2.3.4 Treinamento e ajuste das componentes ........................................................ 57
3.2.3.5 Combina√ß√£o de previs√µes e extrapola√ß√£o ..................................................... 57
3.2.3.6 Avalia√ß√£o e diagn√≥sticos espec√≠ficos ............................................................ 57
3.2.4 XGBoost .......................................................................................................... 58
3.2.4.1 Prepara√ß√£o e integra√ß√£o com Darts .............................................................. 58
3.2.4.2 Divis√£o dos dados em treino e teste Engenharia autom√°tica de features ..... 59
3.2.4.3 Engenharia autom√°tica de features ............................................................... 59
3.2.4.4 Configura√ß√£o dos hiper par√¢metros iniciais ................................................... 60
3.2.4.5 Treinamento do modelo ................................................................................. 61
3.2.4.6 Avalia√ß√£o inicial de desempenho .................................................................. 62
3.2.4.7 Valida√ß√£o e an√°lise de resultados ................................................................. 62
3.2.4.8 Gera√ß√£o das previs√µes finais e armazenamento dos resultados .................. 62
3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS .............................................. 62
REFER√äNCIAS ......................................................................................................... 63

---

# Page 11

11

## 1 INTRODU√á√ÉO

A previs√£o de vendas, no contexto atual da transforma√ß√£o digital e da crescente demanda por decis√µes empresariais baseadas em dados, se estabelece como um dos
grandes desafios e diferenciais competitivos para organiza√ß√µes de todos os portes.
Com mercados cada vez mais din√¢micos e suscet√≠veis a varia√ß√µes econ√¥micas, tecnol√≥gicas e comportamentais, a precis√£o nas estimativas de faturamento assume
papel central no planejamento, controle de estoques, log√≠stica, defini√ß√£o de metas e estrat√©gias comerciais. Este cen√°rio impulsionou o avan√ßo de diferentes m√©todos de
previs√£o, desde t√©cnicas estat√≠sticas tradicionais at√© abordagens inovadoras de aprendizado de m√°quina, que v√™m transformando a forma como as empresas
analisam e projetam seus resultados futuros.
O uso disseminado de ferramentas de BI, como o Power BI, trouxe grandes avan√ßos para a visualiza√ß√£o e interpreta√ß√£o dos dados hist√≥ricos das empresas,
permitindo a elabora√ß√£o de dashboards customizados para acompanhamento do desempenho de vendas. Contudo, muitos desses sistemas ainda utilizam m√©todos de
previs√£o relativamente simples, que podem n√£o captar integralmente a complexidade dos padr√µes temporais, sazonalidades e vari√°veis ex√≥genas presentes nos dados
(ENSAFI et al., 2022). Paralelamente, algoritmos de ML, como o XGBoost, v√™m sendo destacados na literatura por sua elevada acur√°cia preditiva, robustez e flexibilidade
na incorpora√ß√£o de m√∫ltiplos fatores ao processo de modelagem, sendo escolhido frequentemente em cen√°rios reais e competi√ß√µes internacionais (CHEN; GUESTRIN,
2016).
Diante desse contexto, torna-se pertinente avaliar, sob uma perspectiva aplicada e comparativa, se modelos de ML podem efetivamente aprimorar as
previs√µes de faturamento realizadas por solu√ß√µes j√° consolidadas no ambiente empresarial, como o Power BI, contribuindo para a gera√ß√£o de insights mais robustos
e embasados para a tomada de decis√£o.

## 1.1 TEMA

O presente trabalho aborda o tema da previs√£o de vendas utilizando s√©ries temporais, com foco na compara√ß√£o entre m√©todos tradicionais e modernos de
modelagem preditiva aplicados a dados reais de faturamento empresarial.

---

# Page 12

12

## 1.2 DELIMITA√á√ÉO DO TEMA

A pesquisa concentra-se na an√°lise comparativa do desempenho de diferentes modelos de previs√£o utilizando dados hist√≥ricos extra√≠dos de um banco de dados. O
estudo limita-se √† previs√£o de faturamento mensal, simulando o contexto pr√°tico enfrentado por empresas que necessitam estimar o resultado do m√™s corrente com
base em informa√ß√µes parciais, do primeiro dia do m√™s at√© o momento da consulta.

## 1.3 PROBLEMA

O problema que orienta este trabalho √©: Modelos avan√ßados de aprendizado de m√°quina podem proporcionar previs√µes mais precisas de faturamento, quando
comparados √† abordagem utilizada em dashboards de Power BI? A investiga√ß√£o busca responder se a ado√ß√£o de modelos de aprendizado de m√°quina como XGBoost,
ARIMA, Suaviza√ß√£o Exponencial e Theta pode, de fato, melhorar a acur√°cia das proje√ß√µes realizadas atualmente pela empresa, promovendo maior confiabilidade e
valor estrat√©gico √†s informa√ß√µes disponibilizadas.

## 1.4 OBJETIVOS

1.4.1 Objetivo geral
Avaliar, de forma comparativa, o desempenho de diferentes abordagens de previs√£o de vendas, sejam elas tradicionais ou baseadas em ML, aplicadas a dados
reais de faturamento, verificando se algum dos modelos apresenta desempenho superior ao m√©todo atualmente utilizado em dashboards de Power BI.
1.4.2 Objetivos espec√≠ficos a) Revisar e contextualizar os principais conceitos de s√©ries temporais,
m√©todos estat√≠sticos cl√°ssicos e t√©cnicas de ML voltadas √† previs√£o de vendas, conforme descrito por autores como Bezerra (2006), Makridakis,
Wheelwright e Hyndman (1999) e Ensafi et al. (2022);

---

# Page 13

13 b) Estruturar e pr√©-processar os dados hist√≥ricos de faturamento de acordo
com as exig√™ncias de cada modelo preditivo, assegurando anonimiza√ß√£o, integridade e conformidade com boas pr√°ticas de ci√™ncia de dados;
c) Implementar, treinar e validar modelos de previs√£o ARIMA, Theta, Suaviza√ß√£o Exponencial e XGBoost, utilizando m√©tricas estat√≠sticas
padronizadas para avalia√ß√£o do desempenho;
d) Analisar comparativamente os resultados obtidos e discutir as vantagens, limita√ß√µes e possibilidades pr√°ticas para ado√ß√£o dos m√©todos preditivos no
contexto empresarial.
Acredita-se que essa abordagem possibilite uma an√°lise abrangente e rigorosa, identificando as oportunidades e desafios envolvidos na transi√ß√£o para modelos
preditivos mais avan√ßados no ambiente corporativo.

## 1.5 JUSTIFICATIVA

A relev√¢ncia deste estudo se justifica tanto pelo avan√ßo recente das t√©cnicas de an√°lise preditiva quanto pela necessidade real de organiza√ß√µes aprimorarem seus
processos de tomada de decis√£o frente a cen√°rios de incerteza e competitividade. Do ponto de vista acad√™mico, h√° uma lacuna na literatura nacional sobre aplica√ß√µes
pr√°ticas e comparativas de modelos de machine learning em ambientes de BI amplamente adotados por empresas brasileiras, como o Power BI (ENSAFI et al.,
2022; SHIRI et al., 2024). Internacionalmente, pesquisas v√™m demonstrando o potencial de algoritmos como XGBoost na supera√ß√£o de m√©todos tradicionais de
previs√£o, especialmente em s√©ries temporais com padr√µes complexos e influ√™ncias externas (CHEN; GUESTRIN, 2016).
No √¢mbito empresarial, a ado√ß√£o de modelos mais precisos pode representar ganhos substanciais em planejamento, controle financeiro e competitividade,
permitindo que decis√µes sejam tomadas com maior base quantitativa e menor risco.
Este trabalho, ao propor uma an√°lise comparativa fundamentada, contribui para aproximar a teoria e a pr√°tica, orientando gestores e profissionais de dados quanto √†
melhor escolha de m√©todos para suas demandas espec√≠ficas.

---

# Page 14

14

## 2 FUNDAMENTA√á√ÉO TE√ìRICA

Neste cap√≠tulo, apresenta-se o embasamento te√≥rico indispens√°vel ao desenvolvimento do presente estudo. Ser√£o discutidos os conceitos fundamentais
relacionados √† previs√£o de dados, contemplando tanto a aplica√ß√£o de algoritmos de aprendizado de m√°quina quanto a utiliza√ß√£o de c√°lculos no Power BI. A partir dessa
fundamenta√ß√£o, busca-se sustentar o estudo de caso realizado, evidenciando as principais vantagens e limita√ß√µes de cada abordagem na an√°lise e proje√ß√£o de
informa√ß√µes.

## 2.1 S√âRIES TEMPORAIS

A an√°lise de s√©ries temporais √© uma importante √°rea da estat√≠stica, dedicada √† compreens√£o, modelagem e previs√£o de fen√¥menos que s√£o observados de forma
sequencial no tempo. Conforme Bezerra (2006), a utiliza√ß√£o da an√°lise de s√©ries temporais √© amplamente difundida em diversas √°reas, como economia, meteorologia,
sa√∫de, controle de processos industriais, vendas e finan√ßas, devido √† capacidade de identificar padr√µes de comportamento e realizar previs√µes futuras com base em dados
hist√≥ricos.
2.1.1 Conceitos fundamentais e defini√ß√µes
De acordo com Parzen (1961), uma s√©rie temporal pode ser entendida como um conjunto de observa√ß√µes dispostas cronologicamente, sendo representada
matematicamente como um processo estoc√°stico, no qual cada valor observado corresponde a um instante espec√≠fico no tempo.
2.1.2 Caracter√≠sticas principais
Entre os principais conceitos e caracter√≠sticas envolvidos na an√°lise de s√©ries temporais, destacam-se:
a) Estacionariedade: Segundo Bezerra (2006), a estacionariedade ocorre quando as propriedades estat√≠sticas, tais como m√©dia, vari√¢ncia e
covari√¢ncia, permanecem constantes ao longo do tempo. A condi√ß√£o de

---

# Page 15

15 estacionariedade √© importante para aplica√ß√£o correta de diversos modelos,
como os modelos ARIMA;
b) Tend√™ncia: Refere-se √† dire√ß√£o predominante da s√©rie ao longo do tempo, podendo ser crescente, decrescente ou est√°vel. Segundo Makridakis,
Wheelwright e Hyndman (1999), a tend√™ncia √© fundamental para entender o comportamento das s√©ries e escolher modelos adequados;
c) Sazonalidade: Corresponde √†s varia√ß√µes peri√≥dicas e regulares que ocorrem em intervalos fixos, como mensal ou anual, devido a fatores
externos ou
eventos recorrentes

## (MAKRIDAKIS,

## WHEELWRIGHT;

## HYNDMAN, 1999);

d) Autocorrela√ß√£o: Representa a correla√ß√£o da s√©rie consigo mesma em diferentes momentos do tempo (lags). De acordo com Parzen (1961), esse
conceito √© fundamental para identificar e compreender o comportamento das s√©ries temporais;
e) Ru√≠do branco: Para Bezerra (2006), √© a parcela aleat√≥ria da s√©rie temporal, composta por erros aleat√≥rios independentes com m√©dia zero e
vari√¢ncia constante, que n√£o apresentam qualquer tipo de padr√£o previs√≠vel.
2.1.3 Classifica√ß√µes de s√©ries temporais
Makridakis, Wheelwright e Hyndman (1999) classificam as s√©ries temporais em tipos distintos:
a) S√©ries estacion√°rias: Caracterizam-se por apresentar m√©dia e vari√¢ncia constantes ao longo do tempo. S√£o frequentemente observadas em s√©ries
financeiras de retorno;
b) S√©ries n√£o estacion√°rias: S√£o s√©ries cujas propriedades estat√≠sticas, como m√©dia e/ou vari√¢ncia, alteram-se com o tempo. Exemplos comuns incluem
s√©ries econ√¥micas como PIB e infla√ß√£o;
c) S√©ries lineares e n√£o lineares: S√©ries lineares podem ser modeladas por t√©cnicas tradicionais, como ARIMA, enquanto s√©ries n√£o lineares exigem
modelos mais avan√ßados, como redes neurais artificiais (SHIRI et al., 2024).

---

# Page 16

16
2.1.4 Exemplos de aplica√ß√£o
V√°rios estudos demonstram a aplica√ß√£o pr√°tica das s√©ries temporais em diversos contextos:
a) Previs√£o de vendas no varejo: Ensafi et al. (2022) compararam t√©cnicas tradicionais como SARIMA e Suaviza√ß√£o Exponencial com m√©todos
avan√ßados como redes neurais LSTM e CNN para previs√£o das vendas sazonais de m√≥veis. Os resultados mostraram que as redes neurais LSTM
apresentaram maior precis√£o na captura de padr√µes complexos e sazonais;
b) Previs√£o de vendas semanais em lojas de departamento: Pao e Sullivan
(2014) utilizaram t√©cnicas como √°rvores de decis√£o, STL+ARIMA e redes neurais feed-forward com entradas temporais defasadas, concluindo que as
redes neurais tiveram um desempenho superior, capturando com efici√™ncia as sazonalidades das vendas semanais;
c) Aplica√ß√£o de Deep Learning em s√©ries temporais complexas: Shiri et al.
(2024) realizaram uma revis√£o abrangente sobre o uso de modelos de deep learning, como CNN, RNN, LSTM e Transformer, em s√©ries temporais. O
estudo apontou que t√©cnicas modernas baseadas em deep learning t√™m se mostrado superiores √†s t√©cnicas tradicionais, principalmente em s√©ries
complexas e com grandes volumes de dados.

## 2.2 M√âTODO THETA

O m√©todo Theta ganhou popularidade ao vencer a competi√ß√£o M3 de previs√µes de s√©ries temporais devido √† sua simplicidade e efici√™ncia em gerar previs√µes precisas
para diversos tipos de dados. Desde ent√£o, este m√©todo tem sido amplamente estudado e aprimorado, resultando em diferentes variantes que exploram seu
potencial para aplica√ß√µes autom√°ticas e mais robustas. (ASSIMAKOPOULOS;

## NIKILOPOULOS, 2000).

---

# Page 17

17
2.2.1 Descri√ß√£o geral e origem
O m√©todo Theta √© uma t√©cnica de previs√£o uni variada que decomp√µe a s√©rie temporal original em componentes denominados "linhas Theta". Cada linha Theta √©
obtida ajustando-se a curvatura dos dados originais atrav√©s de um par√¢metro Œ∏ aplicado √†s segundas diferen√ßas da s√©rie original. (ASSIMAKOPOULOS;

## NIKILOPOULOS, 2000; SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020). A

combina√ß√£o dessas linhas Theta gera previs√µes que equilibram tend√™ncias de curto e longo prazo. (ASSIMAKOPOULOS; NIKILOPOULOS, 2000).
2.2.2 Fundamenta√ß√£o te√≥rica e par√¢metros
As principais caracter√≠sticas do m√©todo Theta incluem:
a) Decomposi√ß√£o da s√©rie temporal: a s√©rie original √© dividida em m√∫ltiplas linhas Theta, destacando diferentes caracter√≠sticas como tend√™ncias de
curto e longo prazo (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000);
b) Par√¢metro Œ∏ (Theta): controla a curvatura das linhas, com ùúÉ< 1 enfatizando tend√™ncias de longo prazo e ùúÉ> 1 destacando varia√ß√µes de curto prazo.

## (ASSIMAKOPOULOS;

## NIKOLOPOULOS,

2000;

## SPILIOTIS;

## ASSIMAKOPOULOS; MAKRIDAKIS, 2020);

c) Combina√ß√£o de previs√µes: as previs√µes geradas a partir das linhas Theta s√£o combinadas usando pondera√ß√µes espec√≠ficas para gerar resultados
mais robustos e precisos (FIORUCCI et al., 2016);
d) Flexibilidade e robustez: permite ajuste e adapta√ß√£o autom√°tica dos par√¢metros para diferentes s√©ries temporais, tornando-o vers√°til para
diversos contextos (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020);
e) Efici√™ncia computacional: destaca-se pela simplicidade computacional, sendo f√°cil e r√°pido de implementar, especialmente quando comparado com
m√©todos mais complexos como ARIMA ou redes neurais (FIORUCCI et al., 2016);
f) Capacidade de generaliza√ß√£o: √© aplic√°vel em s√©ries temporais com diferentes padr√µes, como tend√™ncias lineares, n√£o lineares, s√©ries com

---

# Page 18

18 comportamento
sazonal e
s√©ries irregulares

## (SPILIOTIS;

## ASSIMAKOPOULOS; MAKRIDAKIS, 2020);

g) Simplicidade na interpreta√ß√£o: oferece resultados facilmente interpret√°veis, facilitando seu uso pr√°tico em ambientes corporativos e industriais
(FIORUCCI et al., 2016).
2.2.3 Equa√ß√£o da linha Theta
Segundo Spiliotis, Assimakopoulos e Makridakis (2020), o m√©todo Theta pode ser matematicamente descrito da seguinte forma:
Seja ùëåùë° uma s√©rie temporal observada no tempo ùë°. Uma linha Theta ùëçùë°(ùúÉ) √© obtida pela express√£o:
‚àá2ùëçùë°(ùúÉ) = ùúÉ‚àá2ùëåùë°= ùúÉ(ùëåùë°‚àí2ùëå(ùë°‚àí1) + ùëå(ùë°+2)), ùë°= 3, ‚Ä¶ , ùëõ
onde ‚àá2ùëåùë° √© o operador das segundas diferen√ßas da s√©rie original ùëå no ponto ùë°.
2.2.4 Express√µes aditivas e multiplicativas
No m√©todo Theta, as previs√µes podem ser realizadas utilizando express√µes aditivas ou multiplicativas:
a) Modelo aditivo: √© o modelo original do m√©todo Theta, no qual as previs√µes s√£o obtidas pela combina√ß√£o linear aditiva das linhas Theta ajustadas

## (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000);

b) Modelo multiplicativo: √© uma extens√£o recente do m√©todo, permitindo modelar situa√ß√µes em que componentes como sazonalidade e tend√™ncia
interagem de forma multiplicativa, sendo especialmente √∫til em s√©ries com tend√™ncia
exponencial ou
comportamento sazonal
multiplicativo

## (SPILIOTIS; ASSIMAKOPOULOS; MAKRIDAKIS, 2020).

2.2.5 Funcionamento do m√©todo para previs√£o de dados futuros
Para prever dados futuros, o m√©todo Theta realiza as seguintes etapas

## (ASSIMAKOPOULOS; NIKOLOPOULOS, 2000; FIORUCCI, 2016):

---

# Page 19

19 a) Decomposi√ß√£o: a s√©rie temporal √© decomposta em linhas Theta com
diferentes curvaturas;
b) Extrapola√ß√£o: cada linha √© extrapolada individualmente, frequentemente usando m√©todos simples, como suaviza√ß√£o exponencial simples (SES) para
tend√™ncias de curto prazo e regress√£o linear para tend√™ncias de longo prazo;
c) Combina√ß√£o das linhas: as previs√µes individuais s√£o combinadas, geralmente com pesos iguais ou otimizados, produzindo uma previs√£o final
robusta.
2.2.6 Exemplos pr√°ticos de uso
O m√©todo Theta tem sido amplamente aplicado em diversas √°reas, demonstrando sua robustez:
a) Competi√ß√£o M3: a vers√£o cl√°ssica do m√©todo Theta alcan√ßou resultados superiores √†s demais t√©cnicas na competi√ß√£o M3, uma famosa competi√ß√£o
internacional focada em m√©todos de previs√£o de s√©ries temporais, especialmente em s√©ries mensais e microecon√¥micas, destacando-se por
sua precis√£o e simplicidade (MAKRIDAKIS; HIBON, 2000);
b) Diagn√≥stico automotivo: Lozia (2022) utilizou o m√©todo Theta na avalia√ß√£o diagn√≥stica de amortecedores automotivos, demonstrando a efic√°cia do
m√©todo em modelar e prever o comportamento din√¢mico de sistemas mec√¢nicos complexos;
c) Previs√£o autom√°tica: Spiliotis, Assimakopoulos e Makridakis (2020) propuseram generaliza√ß√µes do m√©todo Theta capazes de selecionar
automaticamente a forma mais apropriada (aditiva ou multiplicativa) e ajustar a inclina√ß√£o das tend√™ncias, superando outros algoritmos autom√°ticos em
competi√ß√µes recentes (como M4), especialmente em s√©ries anuais.

---

# Page 20

20

## 2.3 MODELO ARIMA

O modelo ARIMA √© uma t√©cnica estat√≠stica amplamente utilizada para an√°lise e previs√£o de s√©ries temporais, desenvolvido por Box e Jenkins (1970). √â
especialmente indicado para s√©ries cujos valores passados e erros hist√≥ricos podem ser utilizados para prever valores futuros (NEWBOLD, 1983).
2.3.1 Defini√ß√£o e estrutura do modelo ARIMA
O modelo ARIMA √© uma combina√ß√£o dos modelos autorregressivos (AR), integrados (I) e de m√©dias m√≥veis (MA), definidos pela seguinte nota√ß√£o geral ARIMA
(p, d, q), onde (NEWBOLD, 1983):
a) p: ordem do termo autorregressivo (AR), representa a rela√ß√£o linear entre a observa√ß√£o atual e as anteriores;
b) d: n√∫mero de diferencia√ß√µes necess√°rias para tornar a s√©rie estacion√°ria;
c) q: ordem dos termos de m√©dia m√≥vel (MA), que refletem os erros anteriores do modelo.
Matematicamente, o modelo ARIMA (p, d, q) pode ser expresso da seguinte forma (NEWBOLD, 1983):
ùëåùë°=  ùõø + ùúô1ùëåùë°‚àí1 + ùúô2ùëåùë°‚àí2 + ‚Ä¶ + ùúôùëùùëåùë°‚àíùëù‚àí ùúÉ1ùúÄùë°‚àí1 ‚àí ùúÉ2ùúÄùë°‚àí2 ‚àí ‚Ä¶ ‚àí ùúÉùëûùúÄùë°‚àíùëû+ ùúÄùë°
Onde:
‚Ä¢
ùëåùë°: valor atual da s√©rie temporal.
‚Ä¢
ùëåùë°‚àí1, ùëåùë°‚àí2,..., ùëåùë°‚àíùëù : valores anteriores da s√©rie temporal (termos AR).
‚Ä¢ ùúÄùë°: erro aleat√≥rio (res√≠duos) com distribui√ß√£o normal, m√©dia zero e vari√¢ncia
constante (ru√≠do branco).
‚Ä¢ ùúÄùë°‚àí1, ùúÄùë°‚àí2, ..., ùúÄùë°‚àíùëû: erros anteriores da s√©rie (termos MA).
‚Ä¢ ùõø: constante.
‚Ä¢ ùúô1, ùúô2, ‚Ä¶ , ùúôùëù: coeficientes do termo autorregressivo.
‚Ä¢ ùúÉ1, ùúÉ2, ‚Ä¶ , ùúÉùëû: coeficientes do termo de m√©dia m√≥vel.

---

# Page 21

21
2.3.2 Conceitos e caracter√≠sticas do modelo ARIMA
As principais caracter√≠sticas do modelo ARIMA incluem (BOX; JENKINS, 1970;
FATTAH et al., 2018):
a) Flexibilidade: Pode ajustar-se a diversas s√©ries temporais, incorporando tend√™ncia, ciclos e sazonalidade;
b) Necessidade de estacionariedade: S√©ries temporais precisam ser estacion√°rias para utiliza√ß√£o correta do modelo. A estacionariedade √©
geralmente obtida por diferencia√ß√£o sucessiva das s√©ries temporais;
c) Simplicidade: F√°cil de compreender e implementar, apresentando resultados robustos em previs√µes de curto prazo.
Para verificar se uma s√©rie √© estacion√°ria, frequentemente s√£o utilizados testes estat√≠sticos como o teste Dickey-Fuller (ADF) e o teste KPSS (MURAT et al., 2018).
2.3.3 Como o modelo ARIMA funciona para prever dados futuros?
O processo de constru√ß√£o do modelo ARIMA segue a metodologia Box-
Jenkins, que possui as seguintes etapas (BOX; JENKINS, 1970; MONDAL et al., 2014):
a) Identifica√ß√£o do modelo: Determina√ß√£o das ordens p, d e q, com base na an√°lise gr√°fica das fun√ß√µes de autocorrela√ß√£o (ACF) e autocorrela√ß√£o
parcial (PACF);
b) Estima√ß√£o dos par√¢metros: Os coeficientes do modelo s√£o estimados, normalmente utilizando o m√©todo da m√°xima verossimilhan√ßa;
c) Diagn√≥stico do modelo: Verifica√ß√£o da adequa√ß√£o do modelo por meio da an√°lise dos res√≠duos (erros), usando testes como o teste de Ljung-Box e
crit√©rios estat√≠sticos como AIC (Crit√©rio de Informa√ß√£o de Akaike);
d) Previs√£o: Realiza√ß√£o da previs√£o de valores futuros utilizando o modelo ajustado.

---

# Page 22

22
2.3.4 Casos pr√°ticos e exemplos na literatura
O modelo ARIMA tem diversas aplica√ß√µes pr√°ticas, como evidenciado em diferentes estudos acad√™micos:
a) Previs√£o de demanda em ind√∫strias aliment√≠cias: Fattah et al. (2018) mostraram que o modelo ARIMA (1,0,1) foi eficaz em prever a demanda
futura, ajudando a empresa na gest√£o eficiente de estoques e redu√ß√£o de custos;
b) Previs√£o de vendas no e-commerce: Um modelo h√≠brido combinando
ARIMA com redes neurais LSTM foi utilizado para previs√£o precisa em ambientes com alta volatilidade, como o com√©rcio eletr√¥nico (VAVLIAKIS et
al., 2021);
c) Previs√£o no mercado farmac√™utico: Fourkiotis e Tsadiras (2024) utilizaram
ARIMA em combina√ß√£o com t√©cnicas de aprendizado de m√°quina para prever a demanda por produtos farmac√™uticos, mostrando sua efic√°cia em
capturar efeitos sazonais. Para enfrentar esse desafio, Fourkiotis e Tsadiras
(2024) utilizaram t√©cnicas de an√°lise uni variada de s√©ries temporais para desenvolver previs√µes mais precisas. Os autores analisaram uma base de
dados real contendo 600.000 registros hist√≥ricos de vendas provenientes de uma farm√°cia online, abrangendo um per√≠odo entre 2014 e 2019. A
metodologia proposta envolveu as etapas de pr√©-processamento e limpeza de dados, segmenta√ß√£o dos dados, an√°lise explorat√≥ria e identifica√ß√£o dos
padr√µes temporais, aplica√ß√£o e compara√ß√£o do modelo ARIMA com modelos avan√ßados de ML como LSTM e XGBoost e, por fim, avalia√ß√£o do
modelo com m√©tricas espec√≠ficas. Os resultados demonstraram que o modelo ARIMA apresentou uma boa capacidade preditiva ao capturar
adequadamente a sazonalidade e tend√™ncias lineares de vendas. Contudo, os autores destacaram que modelos de ML avan√ßados, especialmente o
XGBoost, tiveram um desempenho ainda superior. Em particular, o XGBoost obteve as menores taxas de erro absoluto percentual m√©dio (MAPE). Apesar
da boa performance dos modelos avan√ßados de Machine Learning, o modelo ARIMA ainda obteve desempenho competitivo e foi considerado

---

# Page 23

23 eficaz especialmente em s√©ries temporais com forte componente linear e
sazonalidade bem definida;
d) Previs√£o de pre√ßos no mercado financeiro: Mondal et al. (2014) utilizaram
ARIMA para prever pre√ßos de a√ß√µes, destacando sua simplicidade e robustez na previs√£o de tend√™ncias.

## 2.4 SUAVIZA√á√ÉO EXPONENCIAL

O m√©todo de suaviza√ß√£o exponencial tem recebido grande aten√ß√£o no contexto de previs√µes estat√≠sticas devido √† sua efic√°cia, simplicidade e adaptabilidade na
previs√£o de s√©ries temporais. Sua popularidade adv√©m da capacidade intr√≠nseca de atribuir pesos maiores √†s observa√ß√µes mais recentes em detrimento das observa√ß√µes
mais antigas, permitindo r√°pidas adapta√ß√µes √†s mudan√ßas na din√¢mica dos dados

## (GARDNER, 1985; CIPRA, 1992).

Essa t√©cnica tornou-se uma abordagem padr√£o em diversos campos pr√°ticos, incluindo gest√£o de estoques, controle de processos industriais, finan√ßas e gest√£o de
cadeias de suprimentos. Sua ampla ado√ß√£o se d√° pela facilidade computacional e pela interpreta√ß√£o de suas previs√µes em compara√ß√£o com m√©todos mais complexos
como modelos ARIMA e redes neurais (MCKENZIE, 1984).
2.4.1 Defini√ß√£o e estrutura do m√©todo
O m√©todo de exponential smoothing √© uma t√©cnica recursiva para previs√£o de s√©ries temporais que se baseia na pondera√ß√£o exponencial decrescente das
observa√ß√µes passadas. Formalmente, uma previs√£o futura √© constru√≠da como uma combina√ß√£o linear entre a observa√ß√£o mais recente e a previs√£o feita anteriormente.
Essa caracter√≠stica de atualiza√ß√£o recursiva confere simplicidade e efici√™ncia computacional ao m√©todo (BROWN, 1962; MCKENZIE, 1984).
Matematicamente, para o SES, a previs√£o do valor da s√©rie temporal ùëãùë°+1 pode ser expressa por:
ùëãÃÇùë°+1 = ùõºùëãùë°+ (1 ‚àíùõº)ùëãÃÇùë°
Onde:
‚Ä¢
ùëãÃÇùë°+1: valor previsto para o pr√≥ximo per√≠odo;

---

# Page 24

24
‚Ä¢
ùëãùë°: valor observado no per√≠odo atual;
‚Ä¢
ùëãÃÇùë°: previs√£o feita anteriormente para o per√≠odo atual;
‚Ä¢ ùõº: constante de suaviza√ß√£o 0 < ùõº< 1, que define o grau de pondera√ß√£o
aplicado ao dado mais recente (BROWN, 1962).
J√° m√©todos mais avan√ßados, como o m√©todo de Holt-Winters, consideram explicitamente os componentes de n√≠vel, tend√™ncia e sazonalidade da s√©rie temporal.
Segundo Gardner (1985), para s√©ries com comportamento sazonal e tend√™ncia linear, a previs√£o futura para ‚Ñé passos √† frente √© dada pela express√£o geral do m√©todo de
Holt-Winters multiplicativo:
ùëãÃÇùë°+‚Ñé= (ùêøùë°+ ‚Ñé √ó ùëèùë°) √ó  ùëÜùë°+‚Ñé‚àíùëö(ùëò+1)
Onde:
‚Ä¢
ùêøùë° √© o n√≠vel estimado da s√©rie no tempo ùë°;
‚Ä¢ ùëèùë° √© a tend√™ncia estimada no tempo ùë°;
‚Ä¢
ùëÜùë°+‚Ñé‚àíùëö(ùëò+1) √© o fator sazonal estimado no tempo correspondente;
‚Ä¢ ‚Ñé representa o horizonte futuro da previs√£o (quantidade de per√≠odos √† frente);
‚Ä¢ ùëö √© o per√≠odo sazonal da s√©rie (por exemplo, ùëö= 12 para s√©ries mensais
anuais);
‚Ä¢ ùëò √© o n√∫mero de ciclos completos transcorridos.
Esses m√©todos avan√ßados permitem previs√µes mais precisas em s√©ries complexas, com tend√™ncias claras ou padr√µes sazonais fortes, superando m√©todos
mais simples como m√©dias m√≥veis ou o pr√≥prio exponential smoothing simples

## (MCKENZIE, 1984; GARDNER, 1985).

2.4.2 Vantagens e limita√ß√µes na previs√£o de dados
Entre as caracter√≠sticas fundamentais do m√©todo de exponential smoothing destacam-se:
a) Adaptabilidade: capacidade de responder rapidamente √†s altera√ß√µes estruturais na s√©rie temporal, atribuindo pesos exponenciais aos dados
recentes (GARDNER, 1985);

---

# Page 25

25 b) Simplicidade computacional: a estrutura recursiva dos c√°lculos torna o
m√©todo atrativo em aplica√ß√µes pr√°ticas, especialmente onde √© necess√°ria atualiza√ß√£o constante das previs√µes (BROWN, 1962);
c) Flexibilidade estrutural: diferentes vers√µes, como simples, dupla e tripla
(Holt-Winters), permitem modelar comportamentos como tend√™ncia e sazonalidade com efici√™ncia (MCKENZIE, 1984);
d) Robustez: vers√µes robustas do m√©todo, que usam a minimiza√ß√£o dos desvios absolutos ou m√©todos M-estimadores ao inv√©s de m√≠nimos
quadrados, t√™m maior resist√™ncia a dados at√≠picos e s√©ries temporais com distribui√ß√µes assim√©tricas ou de caudas pesadas (CIPRA, 1992).
2.4.3 Aplica√ß√µes e estudos de caso a) Impacto da suaviza√ß√£o exponencial no Efeito Bullwhip: Chen, Ryan e
Simchi-Levi (2000) investigaram como a utiliza√ß√£o do exponential smoothing na previs√£o de demanda pode intensificar o efeito bullwhip, fen√¥meno no
qual pequenas varia√ß√µes na demanda s√£o ampliadas ao longo da cadeia de suprimentos. Eles demonstraram que, ao utilizar previs√µes com exponential
smoothing, as varia√ß√µes nas demandas observadas pelos fabricantes se tornam significativamente maiores do que as percebidas pelos varejistas,
aumentando os desafios de gest√£o e planejamento log√≠stico nas organiza√ß√µes;
b) Robustez a outliers em s√©ries temporais: Cipra (1992) avaliou o desempenho de vers√µes robustas do m√©todo de exponential smoothing em
s√©ries temporais contaminadas por outliers e distribui√ß√µes de caudas longas.
Utilizando minimiza√ß√£o dos desvios absolutos (norma ùêø1) em vez dos m√≠nimos quadrados, Cipra verificou experimentalmente que essas vers√µes
robustas forneceram previs√µes significativamente mais est√°veis e precisas na presen√ßa de valores extremos, superando m√©todos tradicionais
especialmente em s√©ries financeiras e industriais onde valores at√≠picos s√£o comuns;
c) Aplica√ß√µes em controle de estoques: Gardner (1985) destacou o uso bem- sucedido de exponential smoothing no controle e previs√£o para gest√£o de
estoques. Nesse contexto, foram aplicadas varia√ß√µes do m√©todo para prever

---

# Page 26

26 demandas futuras e determinar n√≠veis √≥timos de estoque, reduzindo custos
relacionados √† manuten√ß√£o excessiva ou insuficiente de produtos em invent√°rio. Esse exemplo demonstra claramente como o exponential
smoothing pode auxiliar gestores a otimizarem recursos financeiros e log√≠sticos nas organiza√ß√µes;
d) Previs√µes de demanda em s√©ries sazonais e com tend√™ncia: McKenzie
(1984) apresentou exemplos pr√°ticos demonstrando a efic√°cia do exponential smoothing para s√©ries temporais com forte comportamento
sazonal e tend√™ncia definida. Em seu estudo, foi utilizado o m√©todo Holt-
Winters para capturar esses componentes, proporcionando previs√µes mais precisas que outros m√©todos tradicionais como m√©dias m√≥veis simples e
modelos ARIMA em s√©ries complexas, especialmente no contexto de demanda sazonal de varejo e setores produtivos.

## 2.5 XGBOOST

O XGBoost tornou-se um dos m√©todos mais populares e eficazes no √¢mbito da previs√£o e classifica√ß√£o em machine learning, devido √† sua capacidade de lidar
eficientemente com grandes quantidades de dados e produzir modelos altamente precisos. Originalmente proposto por Chen e Guestrin em 2016, o XGBoost combina
otimiza√ß√µes algor√≠tmicas e t√©cnicas avan√ßadas de engenharia de sistemas para aprimorar significativamente o desempenho de previs√µes e classifica√ß√µes em diversas
√°reas (CHEN; GUESTRIN, 2016).
2.5.1 Vis√£o geral do Extreme Gradient Boosting
O XGBoost √© uma implementa√ß√£o otimizada do algoritmo Gradient Boosting, baseado em √°rvores de decis√£o sequenciais. Diferentemente das abordagens
tradicionais, que utilizam √°rvores independentes (como o Random Forest), o XGBoost constr√≥i √°rvores de maneira iterativa, com cada √°rvore subsequente aprendendo dos
res√≠duos e erros das anteriores. A combina√ß√£o final das √°rvores resulta em um modelo robusto e altamente eficiente para prever valores futuros e classificar dados
complexos (MALIK; HARODE; KUNWAR, 2020).

---

# Page 27

27
2.5.2 Caracter√≠sticas e conceitos do XGBoost
Entre as caracter√≠sticas fundamentais do XGBoost destacam-se:
a) Boosting: M√©todo de aprendizado de m√°quina que cria um modelo forte por meio da combina√ß√£o sequencial de modelos fracos. Cada novo modelo tenta
corrigir os erros dos modelos anteriores (MALIK; HARODE; KUNWAR, 2020);
b) Regulariza√ß√£o: O XGBoost incorpora penalidades ao modelo para evitar o ajuste excessivo (overfitting), limitando a complexidade atrav√©s de
par√¢metros como profundidade m√°xima das √°rvores, penaliza√ß√£o por complexidade (gamma) e regulariza√ß√£o dos pesos das folhas (lambda).
Essa abordagem resulta em modelos mais generaliz√°veis (CHEN;

## GUESTRIN, 2016);

c) Sparsity-aware Split Finding: Um algoritmo que otimiza o processo de divis√£o das √°rvores levando em conta a esparsidade dos dados,
economizando recursos computacionais ao ignorar valores ausentes ou zerados durante a constru√ß√£o das √°rvores (CHEN; GUESTRIN, 2016).
d) Paraleliza√ß√£o e computa√ß√£o distribu√≠da: O XGBoost √© projetado para ser executado em m√∫ltiplas CPUs, permitindo o processamento paralelo dos
dados e acelerando significativamente o treinamento de grandes modelos

## (CHEN; GUESTRIN, 2016);

e) Shrinking e Column Subsampling: T√©cnicas adicionais que ajudam a controlar a complexidade do modelo. Shrinking reduz o impacto individual
de cada √°rvore, enquanto Column Subsampling seleciona aleatoriamente um subconjunto de atributos para cada √°rvore, aumentando a robustez e a
velocidade do modelo (CHEN; GUESTRIN, 2016).
2.5.3 Como o XGBoost prev√™ dados futuros
O funcionamento do XGBoost para previs√µes ocorre de maneira iterativa, seguindo os passos:

---

# Page 28

28 a) Inicializa√ß√£o: O processo se inicia com a defini√ß√£o de uma previs√£o inicial,
que geralmente corresponde √† m√©dia dos valores reais presentes nos dados de treinamento, no caso de problemas de regress√£o. Essa previs√£o inicial
serve como ponto de partida para o modelo e representa a estimativa mais simples poss√≠vel sem considerar ainda as rela√ß√µes complexas entre as
vari√°veis (CHEN; GUESTRIN, 2016; NIELSEN, 2016);
b) C√°lculo dos res√≠duos: Ap√≥s a obten√ß√£o da previs√£o inicial, calcula-se a diferen√ßa entre os valores previstos e os valores reais, gerando assim os
res√≠duos. Esses res√≠duos indicam o quanto o modelo atual est√° errando na previs√£o. O objetivo do XGBoost √© reduzir esses res√≠duos a cada nova
itera√ß√£o, corrigindo gradualmente as falhas do modelo anterior (NIELSEN, 2016; ZHANG et al., 2021);
c) Treinamento iterativo das √°rvores: Em cada itera√ß√£o, uma nova √°rvore de decis√£o √© treinada, n√£o para prever diretamente os valores finais, mas sim
para modelar os res√≠duos obtidos na etapa anterior. Ou seja, cada √°rvore seguinte busca aprender e corrigir os erros cometidos pelo conjunto das
√°rvores anteriores, ajustando-se a padr√µes ainda n√£o capturados (XIE;

## ZHANG, 2021; NIELSEN, 2016);

d) Atualiza√ß√£o das previs√µes: As previs√µes do modelo s√£o atualizadas somando as previs√µes das novas √°rvores treinadas √†s previs√µes
acumuladas das √°rvores anteriores. Com isso, o modelo torna-se progressivamente mais preciso a cada ciclo, pois incorpora sucessivamente
corre√ß√µes dos erros passados. Ao final do processo, a previs√£o final √© composta pela soma ponderada de todas as √°rvores criadas durante as
itera√ß√µes, representando assim uma combina√ß√£o de m√∫ltiplos aprendizados parciais (CHEN; GUESTRIN, 2016; XIE; ZHANG, 2021).
A fun√ß√£o objetivo otimizada no processo √©:
ùêø(ùúë) = ‚àëùëô(ùë¶ÃÇùë¶, ùë¶ùëñ) ùëñ
+ ‚àëŒ©(ùëìùëò) ùëò
onde:
ùëô(ùë¶ÃÇùë¶, ùë¶ùëñ) representa a fun√ß√£o de perda (e.g., erro quadr√°tico m√©dio);

---

# Page 29

29
Œ©(ùëìùëò) representa o termo de regulariza√ß√£o que controla a complexidade do modelo (CHEN; GUESTRIN, 2016).
2.5.4 Exemplos pr√°ticos de uso do XGBoost a) Utilidades: Segundo Noorunnahar et al. (apud Kontopoulou et al., 2023), no
campo de utilidades, foi conduzido um estudo com o objetivo de prever a produ√ß√£o anual de arroz em Bangladesh. Os autores compararam a
precis√£o das previs√µes feitas por um m√©todo ARIMA otimizado, fundamentado no crit√©rio AIC, e pelo algoritmo XGBoost. Para a avalia√ß√£o
dos modelos, foram consideradas m√©tricas de erro como MAE, MPE, RMSE e MAPE. Os resultados indicaram que o modelo XGBoost obteve um
desempenho superior em rela√ß√£o ao ARIMA no conjunto de teste, demonstrando maior efic√°cia na previs√£o da produ√ß√£o de arroz para o
contexto analisado;
b) Previs√£o de volume de vendas no varejo: No setor de utilidades e com√©rcio, o XGBoost tem se mostrado eficaz na previs√£o de volumes de vendas. A
pesquisa de Dairu e Shilong (2021) √© um exemplo, onde o modelo XGBoost foi utilizado para prever o volume de vendas no varejo, comparando seus
resultados com o ARIMA cl√°ssico, o algoritmo GBDT, um modelo de LSTM e a ferramenta de previs√£o Prophet. Os resultados desse estudo indicaram
que as abordagens baseadas em √°rvores, treinadas com caracter√≠sticas de clima e temperatura, ofereceram o melhor desempenho de previs√£o entre os
cinco modelos, enquanto o ARIMA apresentou o pior desempenho.
Notavelmente, o XGBoost exigiu significativamente menos itera√ß√µes de treinamento do que o GBDT e, juntamente com o GBDT, necessitou de
menos dados e recursos em contraste com os modelos de LSTM. Al√©m disso, os autores propuseram um modelo de previs√£o de vendas baseado
em XGBoost para um conjunto de dados de bens de varejo do Walmart, demonstrando bom desempenho com menor tempo de computa√ß√£o e
recursos de mem√≥ria.

---

# Page 30

30

## 3 METODOLOGIA

Este cap√≠tulo apresenta os procedimentos metodol√≥gicos adotados para a realiza√ß√£o da presente pesquisa, detalhando de forma sistem√°tica as etapas que
orientaram o desenvolvimento do estudo. S√£o descritos o tipo de pesquisa, a abordagem utilizada, os m√©todos de coleta e an√°lise dos dados, bem como os crit√©rios
que fundamentaram as escolhas metodol√≥gicas. O objetivo √© conferir transpar√™ncia e fundamenta√ß√£o cient√≠fica ao percurso investigativo, garantindo a validade e a
confiabilidade dos resultados obtidos.

## 3.1 METODOLOGIA DE TRABALHO

Com o intuito de proporcionar uma vis√£o geral do percurso metodol√≥gico adotado, a figura a seguir apresenta, de forma esquem√°tica, as principais etapas e
procedimentos desenvolvidos ao longo deste trabalho. O diagrama tem como objetivo ilustrar, de maneira clara e objetiva, a estrutura metodol√≥gica geral que orientou a
condu√ß√£o da pesquisa.
Fonte: elaborado pelo autor
Figura 1 - Metodologia geral do trabalho

---

# Page 31

31
3.1.1 Defini√ß√£o do problema e objetivos da previs√£o
Este trabalho tem como ponto de partida uma necessidade pr√°tica observada em um dos produtos desenvolvidos pela empresa onde atuo, voltado √† an√°lise e
visualiza√ß√£o de dados corporativos. Especificamente, trata-se de um dashboard constru√≠do na ferramenta Power BI, que apresenta diversas an√°lises de desempenho,
incluindo uma medida respons√°vel por estimar o faturamento do m√™s corrente com base nos dados registrados desde o primeiro dia do m√™s at√© o momento da consulta.
O problema que este trabalho prop√µe a investigar consiste em avaliar se √© poss√≠vel aprimorar essa estimativa por meio da aplica√ß√£o de modelos de aprendizado
de m√°quina e m√©todos estat√≠sticos avan√ßados. Para isso, foram desenvolvidos diferentes modelos preditivos (ARIMA, Theta, Suaviza√ß√£o Exponencial e XGBoost)
utilizando os mesmos dados dispon√≠veis no dashboard, buscando simular o contexto real de previs√£o. O desempenho de cada modelo foi avaliado com base em m√©tricas
estat√≠sticas padronizadas.
O objetivo principal deste estudo √© verificar qual dos modelos testados apresenta melhor desempenho preditivo. A ado√ß√£o do melhor modelo poder√° resultar
em previs√µes mais precisas e na gera√ß√£o de insights mais robustos e estrat√©gicos.
3.1.2 Coleta e pr√©-processamento dos dados
A coleta e o pr√©-processamento dos dados utilizados neste trabalho foram realizados atrav√©s da ferramenta Visual Studio Code. Os dados empregados
correspondem √†s s√©ries hist√≥ricas de faturamento dispon√≠veis em um produto interno da empresa, sendo originalmente utilizados em um dashboard desenvolvido em
Power BI.
Os dados utilizados neste estudo consistiram em registros transacionais de vendas contendo 37.425 transa√ß√µes no per√≠odo de 2014 a 2025. Os campos principais
inclu√≠ram a data de emiss√£o do pedido, valor l√≠quido da venda, identifica√ß√£o do cliente e tipo de opera√ß√£o comercial.
O pipeline implementado seguiu uma abordagem sistem√°tica dividida em etapas distintas, conforme mostra figura abaixo, cada uma com objetivos espec√≠ficos
para preparar os dados para diferentes tipos de modelos de machine learning.

---

# Page 32

32
Fonte: elaborado pelo autor
3.1.2.1 Filtragem e agrega√ß√£o inicial
O processo de pr√©-processamento iniciou com a filtragem exclusiva de transa√ß√µes classificadas como "VENDA", excluindo devolu√ß√µes e outros tipos de
opera√ß√µes comerciais. O valor l√≠quido das vendas foi estabelecido como vari√°vel target, representando a quantidade que os modelos tentariam prever.
3.1.2.2 Anonimiza√ß√£o dos dados
Para garantir a privacidade e conformidade com requisitos de prote√ß√£o de dados, foi implementado um processo de anonimiza√ß√£o utilizando fun√ß√£o de hash
criptogr√°fico MD5 para transformar identifica√ß√µes de clientes em c√≥digos an√¥nimos.
O sistema gerou identificadores no formato "CLIENTE_####" onde os quatro d√≠gitos foram derivados deterministicamente do hash do nome original. Esta abordagem
Figura 2 - Metodologia do pr√©-processamento

---

# Page 33

33 protegeu a privacidade dos clientes enquanto preservou a capacidade de
rastreamento consistente ao longo do tempo.
3.1.2.3 Agrega√ß√£o temporal mensal
Ap√≥s a filtragem inicial, os dados transacionais foram agregados temporalmente em per√≠odos mensais, calculando a soma total de vendas para cada
m√™s. Este processo foi fundamental pois os modelos de s√©ries temporais operam com observa√ß√µes sequenciais regularmente espa√ßadas no tempo.
O procedimento consistiu em agrupar todas as transa√ß√µes por m√™s e ano, gerando uma s√©rie temporal com frequ√™ncia mensal cobrindo o per√≠odo completo dos
dados. Cada observa√ß√£o representou o faturamento total do m√™s correspondente, resultando em aproximadamente 132 pontos temporais mensais.
3.1.2.4 Convers√£o para formato Darts
Os dados agregados foram ent√£o convertidos para o formato TimeSeries da biblioteca Darts, utilizada para implementa√ß√£o de todos os modelos neste estudo. A
biblioteca Darts oferece uma interface unificada para modelagem de s√©ries temporais, suportando tanto m√©todos estat√≠sticos tradicionais (ARIMA, Theta, Suaviza√ß√£o
Exponencial) quanto algoritmos de machine learning (XGBoost) especializados em s√©ries temporais.
Esta convers√£o incluiu a defini√ß√£o adequada do √≠ndice temporal (datas mensais no formato ISO), especifica√ß√£o da coluna de valores (faturamento mensal agregado),
e configura√ß√£o da frequ√™ncia da s√©rie temporal (mensal). A estrutura TimeSeries permitiu que todos os modelos acessassem funcionalidades avan√ßadas como divis√£o
temporal apropriada, gera√ß√£o autom√°tica de features, e aplica√ß√£o de transforma√ß√µes espec√≠ficas para cada algoritmo.
3.1.2.5 Considera√ß√µes sobre engenharia de features
Diferentemente de abordagens tradicionais que requerem engenharia manual extensiva de features (cria√ß√£o de lags, m√©dias m√≥veis, codifica√ß√µes trigonom√©tricas

---

# Page 34

34 etc.), a biblioteca Darts realiza automaticamente a cria√ß√£o das features necess√°rias
para cada tipo de modelo durante o processo de treinamento.
Para os modelos estat√≠sticos (ARIMA, Theta, Suaviza√ß√£o Exponencial), a Darts opera diretamente sobre a s√©rie temporal univariada, aplicando internamente as
transforma√ß√µes e diferencia√ß√µes necess√°rias.
Para o modelo XGBoost, a Darts utiliza o m√≥dulo XGBModel, que cria automaticamente features temporais atrav√©s de:
a) Lags configur√°veis da vari√°vel target;
b) Lags de covariadas passadas (quando aplic√°vel);
c) Encoders temporais (m√™s, ano, trimestre, dia do ano, semana do ano, dia da semana);
d) Normaliza√ß√£o apropriada via MaxAbsScaler.
Esta abordagem
simplificou significativamente
o pipeline
de pr√©-
processamento, eliminando a necessidade de engenharia manual de features e garantindo consist√™ncia na prepara√ß√£o dos dados para todos os modelos.
3.1.3 An√°lise explorat√≥ria e estrutura√ß√£o da s√©rie temporal
A an√°lise explorat√≥ria de dados (EDA) constitui uma etapa fundamental no processo de modelagem de s√©ries temporais, precedendo a aplica√ß√£o de modelos
preditivos e fornecendo informa√ß√µes essenciais sobre a estrutura, padr√µes e caracter√≠sticas dos dados hist√≥ricos. Conforme destacado por Bezerra (2006), a
compreens√£o adequada do comportamento temporal dos dados √© crucial para a sele√ß√£o e parametriza√ß√£o apropriada de modelos de previs√£o, influenciando
diretamente a qualidade e confiabilidade dos resultados obtidos.
No contexto de s√©ries temporais de vendas, a EDA assume particular import√¢ncia devido √† complexidade inerente desses dados, que frequentemente
apresentam componentes de tend√™ncia, sazonalidade, ciclos econ√¥micos e varia√ß√µes irregulares. Segundo Makridakis, Wheelwright e Hyndman (1999), a identifica√ß√£o
precisa desses componentes atrav√©s de t√©cnicas explorat√≥rias adequadas √© fundamental para orientar as decis√µes metodol√≥gicas subsequentes, incluindo a
escolha de modelos estat√≠sticos apropriados e a defini√ß√£o de estrat√©gias de pr√©- processamento.

---

# Page 35

35
3.1.3.1 Vis√£o geral da s√©rie temporal
A an√°lise explorat√≥ria foi implementada atrav√©s de um sistema automatizado de visualiza√ß√µes desenvolvido em Python, utilizando bibliotecas especializadas em
an√°lise de s√©ries temporais. Os dados utilizados correspondem √† s√©rie temporal de vendas mensais no per√≠odo de outubro de 2014 a setembro de 2025, totalizando 132
observa√ß√µes ap√≥s o pr√©-processamento e agrega√ß√£o temporal mensal.
A estrutura√ß√£o dos dados seguiu as diretrizes estabelecidas por Parzen (1961), que define uma s√©rie temporal como um conjunto de observa√ß√µes dispostas
cronologicamente, representada matematicamente como um processo estoc√°stico.
Para garantir a adequa√ß√£o dos dados √† an√°lise temporal, foi implementada uma verifica√ß√£o rigorosa da ordena√ß√£o cronol√≥gica, tratamento de valores ausentes e
valida√ß√£o da consist√™ncia temporal.
A primeira an√°lise apresenta uma vis√£o geral abrangente da s√©rie temporal, incluindo a evolu√ß√£o das vendas ao longo do tempo com linha de tend√™ncia,
distribui√ß√£o dos valores por ano, an√°lise das vendas acumuladas e volatilidade temporal. Esta vis√£o panor√¢mica revelou uma tend√™ncia de crescimento consistente
de 2014 a 2022, seguida por um decl√≠nio significativo entre os anos 2023 e 2025, com valores variando de aproximadamente R$ 1 milh√£o em 2014 para um pico acima de
R$ 80 milh√µes em 2022.

---

# Page 36

36
Fonte: elaborado pelo autor
3.1.3.2 Decomposi√ß√£o STL
A decomposi√ß√£o STL (Seasonal-Trend using Loess) foi aplicada para separar os componentes estruturais da s√©rie temporal. A decomposi√ß√£o confirmou a presen√ßa
de uma tend√™ncia de longo prazo bem definida e padr√µes sazonais consistentes, com a s√©rie original mostrando crescimento exponencial at√© 2022, seguido por decl√≠nio
acentuado. O componente sazonal revelou padr√µes regulares de varia√ß√£o mensal, enquanto o res√≠duo indicou per√≠odos de maior volatilidade, especialmente durante os
anos de transi√ß√£o econ√¥mica.
Figura 3 - Vis√£o geral da s√©rie temporal

---

# Page 37

37
Fonte: elaborado pelo autor
3.1.3.3 An√°lise de sazonalidade
A an√°lise sazonal detalhada examinou os padr√µes mensais e de autocorrela√ß√£o da s√©rie temporal. Foram calculadas as m√©dias mensais hist√≥ricas, revelando que
determinados meses apresentam consistentemente maiores volumes de vendas. A an√°lise de autocorrela√ß√£o identificou depend√™ncias temporais significativas at√© o lag
12, confirmando a presen√ßa de sazonalidade anual na s√©rie.
Figura 4 ‚Äì Decomposi√ß√£o da s√©rie temporal

---

# Page 38

38
Fonte: elaborado pelo autor
3.1.3.4 Propriedades estat√≠sticas
A an√°lise das propriedades estat√≠sticas incluiu o c√°lculo das fun√ß√µes de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial (PACF), fundamentais para a
parametriza√ß√£o de modelos ARIMA. A ACF mostrou correla√ß√µes significativas nos primeiros lags, decaindo gradualmente at√© o lag 12, enquanto a PACF apresentou
cortes abruptos ap√≥s o primeiro lag, sugerindo caracter√≠sticas autorregressivas na s√©rie. A an√°lise da s√©rie diferenciada (primeira diferen√ßa) confirmou a remo√ß√£o da
tend√™ncia, tornando a s√©rie mais adequada para modelagem estat√≠stica.
Figura 5 - An√°lise da sazonalidade

---

# Page 39

39
Fonte: elaborado pelo autor
3.1.3.5 An√°lise de distribui√ß√£o
A an√°lise de distribui√ß√£o dos valores de vendas incluiu histograma com sobreposi√ß√£o de distribui√ß√£o normal, gr√°fico Q-Q para teste de normalidade, box plot
para identifica√ß√£o de outliers, e compara√ß√£o de densidade. Os resultados indicaram que a distribui√ß√£o das vendas n√£o segue uma distribui√ß√£o normal, apresentando
assimetria positiva e presen√ßa de valores extremos.
Figura 6 - Propriedades estat√≠sticas da s√©rie temporal

---

# Page 40

40
Fonte: elaborado pelo autor
3.1.3.6 Evolu√ß√£o temporal detalhada
A an√°lise de evolu√ß√£o temporal examinou as taxas de crescimento anual, padr√µes sazonais por ano, e tend√™ncia linear geral. O c√°lculo das taxas de
crescimento revelou crescimento superior a 200% em 2015, estabiliza√ß√£o em torno de 20 a 40% nos anos intermedi√°rios, e decl√≠nios acentuados nos anos finais.
Figura 7 - An√°lise de distribui√ß√£o

---

# Page 41

41
Fonte: elaborado pelo autor
3.1.3.7 An√°lise de correla√ß√£o temporal
A an√°lise de correla√ß√£o incluiu correla√ß√µes com lags de 1 a 12 meses, autocorrela√ß√£o parcial detalhada, matriz de correla√ß√£o para lags selecionados e
correla√ß√£o com componentes temporais (ano, trimestre, m√™s). Os resultados mostraram correla√ß√µes elevadas (>0,8) para os primeiros lags, decaindo
gradualmente at√© o lag 12. A matriz de correla√ß√£o dos lags selecionados revelou padr√µes de depend√™ncia temporal que orientaram a configura√ß√£o dos modelos
preditivos.
Figura 8 - Evolu√ß√£o temporal das vendas

---

# Page 42

42
Fonte: elaborado pelo autor
3.1.3.8 Insights para modelagem
Com base nesta an√°lise explorat√≥ria abrangente, foram identificados os seguintes resultados fundamentais para a modelagem preditiva:
a) Estacionariedade: A s√©rie original n√£o √© estacion√°ria devido √† forte tend√™ncia, requerendo diferencia√ß√£o para modelos ARIMA (d = 1);
b) Sazonalidade: Presen√ßa confirmada de sazonalidade anual (per√≠odo 12) com padr√µes consistentes;
c) Autocorrela√ß√£o: Depend√™ncias temporais significativas at√© 12 lags, orientando a parametriza√ß√£o dos modelos;
d) Distribui√ß√£o: Dados n√£o seguem distribui√ß√£o normal, apresentando assimetria positiva;
Figura 9 - An√°lise de correla√ß√£o temporal

---

# Page 43

43 e) Tend√™ncia: Tend√™ncia de longo prazo bem definida com crescimento at√©
2022 seguido de decl√≠nio;
f) Volatilidade: Varia√ß√£o da volatilidade ao longo do tempo, com per√≠odos de maior instabilidade.
Estes resultados orientaram diretamente a configura√ß√£o dos par√¢metros para cada modelo preditivo, a escolha das t√©cnicas de pr√©-processamento espec√≠ficas, e
as estrat√©gias de valida√ß√£o temporal adotadas nas etapas subsequentes.

## 3.2 MODELOS DE PREVIS√ÉO UTILIZADOS

A modelagem preditiva √© a etapa central deste trabalho, sendo respons√°vel por transformar os dados estruturados em previs√µes quantitativas para o faturamento.
Considerando as diferentes abordagens e caracter√≠sticas dos dados, foram selecionados m√∫ltiplos modelos de previs√£o, cada um com suas pr√≥prias vantagens,
desvantagens e caracter√≠sticas espec√≠ficas de implementa√ß√£o.
Os modelos escolhidos para este estudo incluem t√©cnicas tradicionais de s√©ries temporais, como ARIMA, Theta e Suaviza√ß√£o Exponencial, bem como o algoritmo
XGBoost, amplamente utilizado em aplica√ß√µes empresariais para problemas de previs√£o com s√©ries temporais. Cada um desses modelos foi avaliado quanto √† sua
capacidade de capturar padr√µes hist√≥ricos, prever tend√™ncias futuras e lidar com os desafios t√≠picos desse tipo de dado, como sazonalidade, tend√™ncia e varia√ß√µes
irregulares.
Para garantir uma an√°lise comparativa robusta, foram considerados fatores como a facilidade de implementa√ß√£o, complexidade computacional e a precis√£o das
previs√µes geradas. Todos os modelos foram implementados utilizando a biblioteca
Darts, que oferece uma interface unificada e padronizada para modelagem de s√©ries temporais, garantindo consist√™ncia na prepara√ß√£o dos dados, divis√£o temporal e
avalia√ß√£o de desempenho.
Nos subt√≥picos a seguir, cada modelo √© apresentado individualmente, incluindo os requisitos espec√≠ficos de implementa√ß√£o e o diagrama do fluxo metodol√≥gico
correspondente.

---

# Page 44

44

## 3.2.1 ARIMA

A figura a seguir mostra a metodologia utilizada para o modelo.
Fonte: elaborado pelo autor
3.2.1.1 Importa√ß√£o das bibliotecas e configura√ß√£o do ambiente
A implementa√ß√£o do modelo ARIMA foi realizada utilizando o Visual Studio
Code como ambiente de desenvolvimento integrado, garantindo controle de vers√£o e reprodutibilidade do c√≥digo. O ambiente Python foi configurado com as seguintes
bibliotecas essenciais:
Figura 10 - Metodologia do modelo ARIMA

---

# Page 45

45 a) Darts: Biblioteca especializada em s√©ries temporais que forneceu o m√≥dulo
ARIMA (com sele√ß√£o autom√°tica de par√¢metros via AutoARIMA), m√©todos de divis√£o temporal apropriados para s√©ries temporais, e fun√ß√µes integradas
de avalia√ß√£o e diagn√≥stico;
b) Pandas: Utilizado para manipula√ß√£o e estrutura√ß√£o inicial dos dados, convers√£o de tipos de dados temporais, e opera√ß√µes de agrega√ß√£o e
filtragem durante o pr√©-processamento;
c) Matplotlib e Seaborn: Empregados para gera√ß√£o de visualiza√ß√µes diagn√≥sticas, incluindo gr√°ficos de s√©rie temporal, correlogramas, an√°lise de
res√≠duos e compara√ß√µes entre valores observados e previstos.
Esta prepara√ß√£o foi fundamental para garantir que todas as opera√ß√µes subsequentes fossem executadas de forma padronizada e rastre√°vel.
3.2.1.2 Ingest√£o e convers√£o dos dados para s√©rie temporal
O processo de ingest√£o iniciou com o carregamento dos dados de faturamento mensal previamente processados na etapa 3.1.2, obtidos do arquivo CSV estruturado
com 132 observa√ß√µes mensais. Os dados foram validados quanto √†:
a) Integridade temporal: Verifica√ß√£o de continuidade mensal sem lacunas, confirma√ß√£o da ordena√ß√£o cronol√≥gica correta, e valida√ß√£o do formato de
datas no padr√£o ISO (YYYY-MM-DD);
b) Qualidade dos valores: Identifica√ß√£o de valores nulos, negativos ou extremos que poderiam comprometer a modelagem, e confirma√ß√£o da
escala monet√°ria consistente (valores em reais);
c) Estrutura adequada: Configura√ß√£o do √≠ndice temporal como DatetimeIndex do Pandas, garantindo opera√ß√µes temporais apropriadas.
A convers√£o para o objeto TimeSeries da Darts foi realizada especificando a coluna de valores (faturamento mensal), o √≠ndice temporal (datas mensais), e a
frequ√™ncia da s√©rie ('MS' para mensal). Esta estrutura otimizada permitiu que o modelo
ARIMA acessasse funcionalidades avan√ßadas como detec√ß√£o autom√°tica de

---

# Page 46

46 periodicidade sazonal, aplica√ß√£o de transforma√ß√µes temporais (diferencia√ß√£o), e
gera√ß√£o de previs√µes de forma eficiente.
3.2.1.3 Verifica√ß√£o de estacionaridade e diferencia√ß√£o
A avalia√ß√£o de estacionariedade foi conduzida considerando os achados da an√°lise explorat√≥ria que evidenciaram forte tend√™ncia n√£o linear (crescimento
exponencial at√© 2022, seguido de decl√≠nio acentuado) e padr√µes sazonais anuais consistentes usando o seguinte:
a) Testes de estacionariedade: O AutoARIMA da Darts realiza testes internos
(ADF - Augmented Dickey-Fuller) para detectar a presen√ßa de raiz unit√°ria e determinar automaticamente a necessidade de diferencia√ß√£o.
b) Estrat√©gia de diferencia√ß√£o: O AutoARIMA foi configurado para explorar automaticamente:
a. Diferencia√ß√£o n√£o sazonal (d): Testadas ordens de 0 a 2, sendo d = 1
(primeira diferen√ßa) a mais comum para remover tend√™ncia linear.
b. Diferencia√ß√£o sazonal (D): Avaliada com per√≠odo 12 (sazonalidade anual), testando D = 0 (sem diferencia√ß√£o sazonal) e D = 1 (uma
diferencia√ß√£o sazonal
para remover
padr√µes sazonais
n√£o estacion√°rios).
O processo de diferencia√ß√£o foi crucial para transformar a s√©rie n√£o estacion√°ria original em uma s√©rie com propriedades estat√≠sticas est√°veis, evitando
regress√µes esp√∫rias e garantindo a validade dos pressupostos do modelo ARIMA. A biblioteca Darts aplicou estas transforma√ß√µes de forma autom√°tica e revers√≠vel para
as previs√µes finais.
3.2.1.4 Divis√£o dos dados em conjuntos de treino e teste
A divis√£o temporal foi implementada seguindo rigorosamente o princ√≠pio de n√£o-sobreposi√ß√£o temporal, essencial para valida√ß√£o real√≠stica de modelos de s√©ries
temporais. A estrat√©gia adotada foi:

---

# Page 47

47 a) Conjunto de treino: Primeiros 80% da s√©rie (aproximadamente 105 meses),
representando o per√≠odo de outubro de 2014 at√© meados de 2023. Este per√≠odo incluiu a fase de crescimento consistente e o pico hist√≥rico das
vendas, fornecendo ao modelo informa√ß√£o suficiente sobre tend√™ncias de longo prazo e padr√µes sazonais estabelecidos;
b) Conjunto de teste: √öltimos 20% da s√©rie (aproximadamente 27 meses), correspondendo ao per√≠odo final at√© setembro de 2025. Este per√≠odo
capturou a fase de decl√≠nio das vendas, representando um desafio real de generaliza√ß√£o para o modelo;
c) Justificativa da divis√£o: A propor√ß√£o 80/20 foi escolhida para garantir quantidade suficiente de dados para o treinamento (especialmente
importante para capturar m√∫ltiplos ciclos sazonais anuais), ao mesmo tempo que preservou um horizonte de teste representativo para avaliar
performance preditiva.
A implementa√ß√£o utilizou m√©todos nativos da Darts, que garantiram preserva√ß√£o da estrutura temporal e evitaram vazamento de informa√ß√µes futuras para
o conjunto de treino.
3.2.1.5 Defini√ß√£o dos par√¢metros p, d e q
A parametriza√ß√£o do modelo foi conduzida atrav√©s do AutoARIMA da Darts, que implementou uma busca sistem√°tica e otimizada pelos melhores par√¢metros
SARIMA(p,d,q)(P,D,Q)s. Os par√¢metros foram definidos como:
b) Par√¢metros n√£o sazonais:
a. p (ordem autorregressiva): N√∫mero de lags da s√©rie defasada utilizados como preditores. Testadas ordens de 0 a 5, onde p = 1 indica
depend√™ncia do valor anterior, p = 2 inclui os dois valores anteriores etc;
b. d (ordem de diferencia√ß√£o): N√∫mero de diferencia√ß√µes aplicadas para tornar a s√©rie estacion√°ria. Avaliadas ordens de 0 a 2, baseadas nos
testes de estacionariedade;

---

# Page 48

48 c. q (ordem de m√©dia m√≥vel): N√∫mero de erros de previs√£o defasados
inclu√≠dos no modelo. Testadas ordens de 0 a 5, capturando depend√™ncias nos termos de erro.
c) Par√¢metros sazonais (per√≠odo s = 12):
a. P (autorregressivo sazonal): Depend√™ncia de valores sazonais defasados (ex.: mesmo m√™s do ano anterior). Testadas ordens de 0 a 2;
b. D (diferencia√ß√£o sazonal): Diferencia√ß√£o aplicada com per√≠odo sazonal para remover n√£o estacionariedade sazonal. Avaliadas ordens de 0 a 1;
c. Q (m√©dia m√≥vel sazonal): Erros sazonais defasados inclu√≠dos no modelo. Testadas ordens de 0 a 2.
Para crit√©rio de sele√ß√£o, o AutoARIMA utilizou o AIC (Akaike Information
Criterion) para balancear qualidade do ajuste com parcim√¥nia do modelo, selecionando automaticamente a configura√ß√£o que minimizou o AIC. O algoritmo
implementou busca
stepwise para
efici√™ncia computacional,
explorando configura√ß√µes vizinhas de forma inteligente.
3.2.1.6 Treinamento do modelo
O processo de treinamento foi executado ap√≥s a sele√ß√£o autom√°tica dos melhores par√¢metros, utilizando os algoritmos de estima√ß√£o implementados na Darts.
O treinamento envolveu:
a) Estima√ß√£o por m√°xima verossimilhan√ßa: Os coeficientes do modelo foram estimados atrav√©s da maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa, que
encontrou os par√¢metros que melhor explicaram os dados observados no conjunto de treino;
b) Otimiza√ß√£o num√©rica: O processo utilizou algoritmos de otimiza√ß√£o n√£o linear para encontrar os valores √≥timos dos coeficientes, iniciando de valores
iniciais estimados e iterando at√© converg√™ncia;
c) Ajuste da componente sazonal: O modelo SARIMA ajustou simultaneamente os padr√µes n√£o sazonais (tend√™ncia de curto prazo, depend√™ncias de lags
pr√≥ximos) e sazonais (padr√µes anuais, depend√™ncias de per√≠odos equivalentes em anos anteriores);

---

# Page 49

49 d) Valida√ß√£o do ajuste: Durante o treinamento, foram monitoradas m√©tricas de
converg√™ncia e estabilidade dos coeficientes estimados para garantir adequa√ß√£o do processo de otimiza√ß√£o.
O resultado foi um modelo completamente parametrizado, capaz de capturar tanto as depend√™ncias temporais de curto prazo quanto os padr√µes sazonais anuais
identificados na an√°lise explorat√≥ria.
3.2.1.7 Valida√ß√£o do modelo e ajustes finos
A etapa de valida√ß√£o consistiu na gera√ß√£o de previs√µes para todo o horizonte do conjunto de teste e avalia√ß√£o sistem√°tica da performance preditiva:
a) Gera√ß√£o de previs√µes: O modelo treinado foi utilizado para produzir previs√µes recursivas, onde cada previs√£o utilizou apenas informa√ß√µes
dispon√≠veis at√© aquele ponto temporal. Este processo simulou fielmente o cen√°rio real de previs√£o operacional;
b) Intervalos de confian√ßa: Foram gerados intervalos de previs√£o (tipicamente
95% de confian√ßa) baseados na vari√¢ncia estimada dos erros do modelo, fornecendo medida de incerteza associada a cada previs√£o;
c) M√©tricas de avalia√ß√£o: A performance foi avaliada atrav√©s do conjunto padronizado de m√©tricas:
a. MAE (Mean Absolute Error): Erro absoluto m√©dio em reais, interpret√°vel diretamente na escala do problema;
b. RMSE (Root Mean Squared Error): Raiz do erro quadr√°tico m√©dio, penalizando mais fortemente grandes desvios;
c. MAPE (Mean Absolute Percentage Error): Erro percentual absoluto m√©dio, permitindo interpreta√ß√£o relativa independente da escala.
d) An√°lise temporal das previs√µes: Foi conduzida an√°lise per√≠odo a per√≠odo para identificar padr√µes nos erros, sazonalidade residual, e performance
diferencial ao longo do horizonte de previs√£o.

---

# Page 50

50
3.2.1.8 An√°lise residual
Uma an√°lise detalhada dos res√≠duos do modelo foi conduzida para verificar se os erros de previs√£o se distribu√≠ram de forma aleat√≥ria, sem padr√µes sistem√°ticos n√£o
modelados. Foram gerados gr√°ficos de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial
(PACF) dos res√≠duos, buscando confirmar comportamento pr√≥ximo ao ru√≠do branco.
Res√≠duos com padr√µes significativos indicaram que o modelo n√£o conseguiu capturar completamente as rela√ß√µes temporais nos dados. Adicionalmente, a an√°lise
incluiu inspe√ß√£o visual da distribui√ß√£o dos res√≠duos e identifica√ß√£o de outliers ou eventos at√≠picos que poderiam comprometer a precis√£o das previs√µes futuras. Esta
valida√ß√£o foi essencial para confirmar a adequa√ß√£o do modelo selecionado.
3.2.1.9 Armazenamento dos resultados para compara√ß√£o futura
Foram geradas visualiza√ß√µes espec√≠ficas para documentar o desempenho do modelo ARIMA, incluindo gr√°ficos de s√©rie temporal comparando valores observados
e previstos, an√°lise de res√≠duos ao longo do tempo e representa√ß√£o gr√°fica da estrutura de correla√ß√£o do conjunto de dados para diagn√≥stico.
Os resultados do modelo ARIMA, incluindo previs√µes, m√©tricas de desempenho, par√¢metros selecionados e diagn√≥sticos, foram salvos de forma
estruturada para posterior compara√ß√£o com os demais modelos (Theta, Suaviza√ß√£o
Exponencial e XGBoost). Esta documenta√ß√£o foi essencial para a an√°lise comparativa final e escolha da abordagem preditiva mais adequada.

---

# Page 51

51
3.2.2 Suaviza√ß√£o Exponencial
A figura a seguir mostra a metodologia utilizada para o modelo.
Fonte: elaborado pelo autor
O modelo de Suaviza√ß√£o Exponencial compartilhou grande parte da metodologia com o ARIMA, diferindo principalmente na abordagem de modelagem e
nos crit√©rios de sele√ß√£o do modelo. As etapas de importa√ß√£o de bibliotecas, ingest√£o e convers√£o de dados e a divis√£o treino/teste foram executadas de forma id√™ntica ao
ARIMA, utilizando a mesma biblioteca Darts, mesma estrutura TimeSeries, e mesma propor√ß√£o 80/20 com divis√£o temporal rigorosa.
Figura 11 ‚Äì Metodologia do modelo Suaviza√ß√£o Exponencial

---

# Page 52

52
3.2.2.1 An√°lise de componentes para sele√ß√£o do modelo
Diferentemente do ARIMA, que se baseou em testes de estacionariedade e an√°lise de correlogramas, o modelo de Suaviza√ß√£o Exponencial utilizou os resultados
da decomposi√ß√£o STL j√° realizada na an√°lise explorat√≥ria para orientar a sele√ß√£o do tipo apropriado de modelo.
Com base nos componentes j√° extra√≠dos na EDA, a biblioteca Darts implementou crit√©rios autom√°ticos para escolha entre:
a) Suaviza√ß√£o Exponencial Simples (SES): Para s√©ries sem tend√™ncia ou sazonalidade significativas;
b) M√©todo de Holt: Para s√©ries com tend√™ncia forte, mas sazonalidade fraca;
c) M√©todo de Holt-Winters: Para s√©ries com ambos os componentes significativos (caso esperado desta s√©rie).
3.2.2.2 Decis√£o entre modelo aditivo e multiplicativo
Uma etapa espec√≠fica da Suaviza√ß√£o Exponencial foi a escolha entre formula√ß√µes aditiva e multiplicativa, baseada na an√°lise dos componentes sazonais
da EDA:
a) Modelo Aditivo: Selecionado quando a amplitude da sazonalidade permaneceu relativamente constante ao longo do tempo;
b) Modelo Multiplicativo: Selecionado quando a amplitude da sazonalidade variou proporcionalmente ao n√≠vel da s√©rie.
A decis√£o foi automatizada pela Darts baseada na an√°lise da vari√¢ncia relativa dos componentes sazonais j√° extra√≠dos na EDA.

---

# Page 53

53
3.2.2.3 Configura√ß√£o e otimiza√ß√£o de par√¢metros
Ao contr√°rio do ARIMA, que utilizou par√¢metros discretos (p, d, q), a
Suaviza√ß√£o Exponencial otimizou par√¢metros cont√≠nuos de suaviza√ß√£o:
a) Par√¢metros do modelo Holt-Winters:
a. Œ± (alfa): Par√¢metro de suaviza√ß√£o do n√≠vel (0 < Œ± ‚â§ 1);
b. Œ≤ (beta): Par√¢metro de suaviza√ß√£o da tend√™ncia (0 ‚â§ Œ≤ ‚â§ 1);
c. Œ≥ (gama): Par√¢metro de suaviza√ß√£o sazonal (0 ‚â§ Œ≥ ‚â§ 1).
b) Per√≠odo sazonal: Fixado em 12 meses conforme evidenciado na EDA;
c) Processo de otimiza√ß√£o: A Darts utilizou algoritmos de minimiza√ß√£o num√©rica para encontrar os valores √≥timos que minimizaram o erro
quadr√°tico m√©dio no conjunto de treino.
3.2.2.4 Treinamento por suaviza√ß√£o recursiva
O processo de treinamento diferiu fundamentalmente do ARIMA por utilizar suaviza√ß√£o exponencial recursiva ao inv√©s de estima√ß√£o de m√°xima verossimilhan√ßa:
a) Inicializa√ß√£o dos componentes:
a. N√≠vel inicial estimado como m√©dia dos primeiros per√≠odos;
b. Tend√™ncia inicial calculada como diferen√ßa m√©dia inicial;
c. √çndices sazonais estimados atrav√©s dos primeiros ciclos da s√©rie.
b) Atualiza√ß√£o recursiva: Para cada per√≠odo t do treino, os componentes foram atualizados atrav√©s de combina√ß√µes ponderadas dos valores observados e
componentes anteriores projetados.
Este processo iterativo permitiu ao modelo adaptar-se gradualmente aos padr√µes, diferindo da estima√ß√£o simult√¢nea de todos os par√¢metros no ARIMA.

---

# Page 54

54
3.2.2.5 Gera√ß√£o de previs√µes diretas
A gera√ß√£o de previs√µes na Suaviza√ß√£o Exponencial utilizou abordagem direta
(n√£o recursiva) baseada nos componentes finais, projetando o n√≠vel futuro adicionando tend√™ncia multiplicada pelo horizonte ao √∫ltimo n√≠vel, e obtendo o
componente sazonal do √≠ndice correspondente ao per√≠odo do ano.
3.2.2.6 An√°lise residual espec√≠fica para suaviza√ß√£o
A an√°lise residual seguiu protocolo similar ao ARIMA, mas com focos espec√≠ficos na valida√ß√£o de componentes (tend√™ncia e sazonalidade), estabilidade
dos par√¢metros otimizados (Œ±, Œ≤ e Œ≥), e adequa√ß√£o do modelo selecionado (aditivo vs.
multiplicativo) atrav√©s de an√°lise visual dos res√≠duos padronizados e m√©tricas de ajuste.
3.2.3 Theta
O modelo Theta compartilhou as etapas fundamentais de prepara√ß√£o com os modelos anteriores, diferindo principalmente na abordagem de decomposi√ß√£o e
extrapola√ß√£o. As etapas de importa√ß√£o de bibliotecas, ingest√£o e convers√£o de dados e divis√£o treino/teste foram executadas de forma id√™ntica aos modelos anteriores,
utilizando a mesma biblioteca Darts, mesma estrutura TimeSeries, e mesma divis√£o temporal 80/20.
A figura a seguir mostra a metodologia utilizada para o modelo.

---

# Page 55

55
Fonte: elaborado pelo autor
3.2.3.1 Verifica√ß√£o de pr√©-condi√ß√µes do m√©todo Theta
O m√©todo Theta na biblioteca Darts exigiu verifica√ß√µes espec√≠ficas antes da aplica√ß√£o:
a) Valida√ß√£o da s√©rie temporal: Confirma√ß√£o da aus√™ncia de valores nulos na s√©rie, pois o Theta da Darts n√£o possui tratamento autom√°tico para dados
ausentes;
Figura 12 ‚Äì Metodologia do modelo Theta

---

# Page 56

56 b) Verifica√ß√£o de univari√¢ncia: O m√©todo foi aplicado exclusivamente √† s√©rie
temporal univariada de faturamento mensal, sem vari√°veis explicativas adicionais, seguindo a natureza original do m√©todo proposto por
Assimakopoulos e Nikolopoulos (2000);
c) Confirma√ß√£o de regularidade temporal: Verifica√ß√£o da frequ√™ncia mensal constante da s√©rie, requisito para a decomposi√ß√£o Theta funcionar
adequadamente.
3.2.3.2 Configura√ß√£o autom√°tica vs. manual do modelo
No quesito de configura√ß√£o, o m√©todo Theta da Darts ofereceu configura√ß√£o totalmente autom√°tica:
a) Par√¢metro Theta (Œ∏): A Darts implementou sele√ß√£o autom√°tica do par√¢metro Œ∏, que controla a curvatura das linhas Theta. Valores Œ∏ < 1 enfatizam
tend√™ncias de longo prazo, enquanto Œ∏ > 1 destacam varia√ß√µes de curto prazo;
b) Detec√ß√£o autom√°tica de sazonalidade: O Theta detectou automaticamente a presen√ßa e o per√≠odo da sazonalidade (12 meses) com base nos padr√µes
da s√©rie;
c) Configura√ß√£o de decomposi√ß√£o: O modelo foi configurado para aplicar decomposi√ß√£o autom√°tica da s√©rie em componentes Theta, sem
necessidade de especifica√ß√£o manual.
3.2.3.3 Decomposi√ß√£o e cria√ß√£o das linhas Theta
Esta etapa foi espec√≠fica do m√©todo Theta, onde os seguintes pontos foram realizados:
a) Aplica√ß√£o das segundas diferen√ßas: O m√©todo aplicou o operador de segundas diferen√ßas √† s√©rie original conforme a formula√ß√£o matem√°tica de
Assimakopoulos e Nikolopoulos (2000);
b) Gera√ß√£o das linhas Theta: Foram criadas m√∫ltiplas linhas Theta atrav√©s de transforma√ß√µes matem√°ticas, incluindo:

---

# Page 57

57 a. Linha Theta 0 (Œ∏ = 0): Representa tend√™ncia linear de longo prazo
b. Linha Theta 2 (Œ∏ = 2): Captura varia√ß√µes de curto prazo e sazonalidade.
3.2.3.4 Treinamento e ajuste das componentes
O processo de treinamento do Theta diferiu dos outros modelos no seguinte:
a) Ajuste das linhas individuais: Cada linha Theta foi ajustada separadamente:
a. Linha Theta 0: Ajustada por regress√£o linear para capturar tend√™ncia de longo prazo;
b. Linha Theta 2: Ajustada por Suaviza√ß√£o Exponencial Simples (SES) para varia√ß√µes de curto prazo.
b) Otimiza√ß√£o autom√°tica: A Darts implementou otimiza√ß√£o autom√°tica dos par√¢metros de cada componente.
3.2.3.5 Combina√ß√£o de previs√µes e extrapola√ß√£o
A gera√ß√£o de previs√µes seguiu abordagem √∫nica de combina√ß√£o de extrapola√ß√µes, onde cada linha Theta foi extrapolada separadamente para o horizonte
de teste, e as previs√µes finais foram obtidas atrav√©s de combina√ß√£o ponderada das extrapola√ß√µes individuais, tipicamente com pesos iguais ou otimizados baseados na
performance hist√≥rica.
3.2.3.6 Avalia√ß√£o e diagn√≥sticos espec√≠ficos
A avalia√ß√£o seguiu protocolo similar aos modelos anteriores, com an√°lises espec√≠ficas de valida√ß√£o das linhas Theta, verifica√ß√£o da capacidade de reconstru√ß√£o
da s√©rie original, e an√°lise de estabilidade dos par√¢metros otimizados.

---

# Page 58

58
3.2.4 XGBoost
A figura 3 mostra a metodologia utilizada para o modelo.
Fonte: elaborado pelo autor
3.2.4.1 Prepara√ß√£o e integra√ß√£o com Darts
O modelo XGBoost foi implementado utilizando o m√≥dulo `XGBModel` da biblioteca Darts, que integra o algoritmo XGBoost com a infraestrutura de s√©ries
temporais da Darts. Diferentemente da implementa√ß√£o tradicional que requer engenharia manual extensiva de features, o `XGBModel` da Darts automatiza a
cria√ß√£o de features temporais necess√°rias para o treinamento.
A entrada do modelo foi a mesma s√©rie temporal univariada utilizada pelos outros modelos (faturamento mensal agregado), mantendo consist√™ncia na
prepara√ß√£o dos dados. A Darts se encarregou automaticamente de transformar esta
Figura 13 ‚Äì Metodologia do modelo XGBoost

---

# Page 59

59 s√©rie temporal em formato tabular apropriado para o XGBoost durante o processo de
treinamento.
3.2.4.2 Divis√£o dos dados em treino e teste Engenharia autom√°tica de features
Assim como nos demais modelos, os dados foram divididos respeitando rigorosamente a ordem cronol√≥gica na propor√ß√£o 80/20, evitando vazamento de
informa√ß√µes futuras. A Darts garantiu que a divis√£o temporal fosse consistente com os outros modelos implementados.
3.2.4.3 Engenharia autom√°tica de features
O XGBModel da Darts criou automaticamente as features necess√°rias atrav√©s de par√¢metros configur√°veis:
a) Lags da vari√°vel target: Foram configurados 17 lags principais [-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -15, -18, -24, -30, -36] para capturar
depend√™ncias temporais em diferentes horizontes.
b) Lags de covariadas passadas: Configurados 8 lags [-1, -2, -3, -4, -5, -6, -12, -24] para capturar padr√µes adicionais de depend√™ncia temporal.
c) Encoders temporais: Foram adicionados automaticamente 6 encoders temporais (m√™s, ano, trimestre, dia do ano, semana do ano, dia da semana)
para capturar padr√µes c√≠clicos e sazonais.
d) Normaliza√ß√£o: Aplicada automaticamente via MaxAbsScaler para garantir escala apropriada das features, particularmente importante para lidar com
outliers em dados de vendas.
Esta abordagem eliminou a necessidade de criar manualmente features como m√©dias m√≥veis, codifica√ß√µes trigonom√©tricas, e estat√≠sticas agregadas, simplificando
significativamente o pipeline e garantindo que apenas as features mais relevantes fossem utilizadas.

---

# Page 60

60
3.2.4.4 Configura√ß√£o dos hiper par√¢metros iniciais
O modelo XGBoost implementado via Darts separou os par√¢metros em duas categorias distintas: par√¢metros espec√≠ficos do framework Darts para processamento
de s√©ries temporais e hiper par√¢metros do algoritmo XGBoost propriamente dito.
a) Par√¢metros do framework Darts (configura√ß√£o de s√©ries temporais):
a. lags: 17 valores de defasagem [-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -
12, -15, -18, -24, -30, -36] para capturar depend√™ncias temporais em m√∫ltiplos horizontes.
b. lags_past_covariates: 8 lags adicionais [-1, -2, -3, -4, -5, -6, -12, -24] para padr√µes de depend√™ncia temporal complementares.
c. add_encoders: Encoders temporais autom√°ticos incluindo m√™s, ano, trimestre, dia do ano, semana do ano e dia da semana para captura de
padr√µes c√≠clicos e sazonais.
d. data_scaling:
MaxAbsScaler aplicado
automaticamente para
normaliza√ß√£o robusta das features.
b) Hiper par√¢metros do algoritmo XGBoost (passados via kwargs):
a. n_estimators: 2000 arvores de decis√£o para garantir capacidade adequada de aprendizado e converg√™ncia do algoritmo de gradient
boosting.
b. max_depth: 8 n√≠veis de profundidade m√°xima, controlando a complexidade das arvores individuais e evitando overfitting.
c. learning_rate: 0.05 para controlar o peso de cada nova arvore no ensemble, garantindo aprendizado est√°vel e converg√™ncia gradual.
d. subsample: 0.9 (90% de amostragem) para aumentar a generaliza√ß√£o do modelo atrav√©s de varia√ß√£o estoc√°stica nas amostras de
treinamento.
e. colsample_bytree: 0.9 para selecionar aleatoriamente 90% das features em cada arvore, promovendo diversidade no ensemble.
f. reg_alpha: 0.2 (regulariza√ß√£o L1/Lasso) para penalizar complexidade e promover esparsidade nos pesos do modelo.

---

# Page 61

61 g. reg_lambda: 1.5 (regulariza√ß√£o L2/Ridge) para controle adicional de
complexidade e suaviza√ß√£o dos pesos.
h. random_state: 42 para garantir reprodutibilidade total dos resultados entre execu√ß√µes.
Esta configura√ß√£o h√≠brida aproveitou a especializa√ß√£o da Darts em processamento de s√©ries temporais (gera√ß√£o autom√°tica de lags e encoders
temporais) combinada com o poder preditivo do algoritmo XGBoost (ensemble de arvores com gradient boosting). Os hiper par√¢metros do XGBoost foram definidos
manualmente com base em pr√°ticas estabelecidas para modelos de previs√£o, priorizando capacidade de aprendizado (n_estimators alto e max_depth moderado)
equilibrada com regulariza√ß√£o (reg_alpha e reg_lambda) para evitar overfitting.
3.2.4.5 Treinamento do modelo
O processo de treinamento do XGBoost seguiu o paradigma de gradient boosting:
a) Inicializa√ß√£o: O processo iniciou com uma previs√£o inicial simples
(geralmente a m√©dia dos valores de treino);
b) Treinamento iterativo: Em cada itera√ß√£o, uma nova √°rvore de decis√£o foi treinada para modelar os res√≠duos (erros) das √°rvores anteriores, corrigindo
gradualmente as falhas do modelo;
c) Atualiza√ß√£o das previs√µes: As previs√µes foram atualizadas somando as previs√µes das novas √°rvores √†s previs√µes acumuladas das √°rvores
anteriores, multiplicadas pela taxa de aprendizado (learning_rate);
d) Regulariza√ß√£o: Durante o treinamento, os termos de regulariza√ß√£o L1 e L2 foram aplicados para penalizar complexidade excessiva e promover
modelos mais simples e generaliz√°veis.
A integra√ß√£o com Darts garantiu que todo este processo respeitasse a natureza temporal dos dados, utilizando apenas informa√ß√µes dispon√≠veis at√© cada ponto
temporal durante o treinamento.

---

# Page 62

62
3.2.4.6 Avalia√ß√£o inicial de desempenho
A avalia√ß√£o do desempenho foi realizada de maneira an√°loga aos outros modelos, atrav√©s das m√©tricas MAE, RMSE e MAPE aplicadas ao conjunto de teste.
A an√°lise dos erros permitiu verificar a capacidade do modelo em capturar padr√µes complexos presentes nos dados de vendas.
3.2.4.7 Valida√ß√£o e an√°lise de resultados
Foi empregada valida√ß√£o temporal adequada a s√©ries temporais, assegurando a robustez dos resultados e a aus√™ncia de overfitting. Os resultados da valida√ß√£o
foram analisados quanto √† consist√™ncia e poss√≠veis padr√µes residuais, confirmando a adequa√ß√£o do modelo.
3.2.4.8 Gera√ß√£o das previs√µes finais e armazenamento dos resultados
As previs√µes finais geradas pelo modelo XGBoost foram armazenadas em formato estruturado para compara√ß√£o direta com os resultados dos demais modelos
(ARIMA, Theta e Suaviza√ß√£o Exponencial), permitindo an√°lise comparativa abrangente baseada nas mesmas m√©tricas padronizadas.

## 3.2.5 Metodologia do m√©todo h√≠brido no Power BI

O m√©todo de previs√£o atualmente implementado no Power BI utiliza uma abordagem h√≠brida que combina dois m√©todos estat√≠sticos simples, mas robustos, para gerar
previs√µes de faturamento mensal. Este m√©todo foi considerado como baseline
(solu√ß√£o de refer√™ncia) para compara√ß√£o com os modelos de machine learning desenvolvidos neste trabalho.

### 3.2.5.1 Estrutura da solu√ß√£o no Power BI

A solu√ß√£o foi implementada atrav√©s de medidas DAX no Power BI, que realizam c√°lculos autom√°ticos a partir dos dados de faturamento armazenados no banco de
dados corporativo. O processo segue a seguinte estrutura:
a) **Medida de Faturamento Realizado**: Calcula a soma do faturamento l√≠quido mensal, considerando apenas opera√ß√µes de vendas processadas (OPERACAO = "VENDA")
que geraram cobran√ßa (GERA_COBRANCA = 1). Esta medida filtra automaticamente os dados pela dimens√£o de data selecionada.
b) **Medida de Faturamento Mensal**: Agrega o faturamento realizado para cada m√™s/ano, garantindo que cada ponto temporal seja associado ao valor correspondente
de faturamento.
c) **Per√≠odo de Teste**: Define o intervalo temporal para as previs√µes (julho de
2023 a setembro de 2025), correspondendo aos 27 meses utilizados para valida√ß√£o dos modelos.

### 3.2.5.2 C√°lculo da previs√£o h√≠brida

O m√©todo h√≠brido combina duas t√©cnicas estat√≠sticas com igual peso (50% cada):
a) **M√©dia Movel de 6 Meses (MM6)**: Calcula a m√©dia aritm√©tica dos 6 meses anteriores ao per√≠odo de previs√£o. Esta t√©cnica captura tend√™ncias recentes e
variabilidades de curto prazo nos dados de vendas, reduzindo o impacto de flutua√ß√µes aleat√≥rias.
b) **Year-over-Year (YoY)**: Utiliza o valor de faturamento do mesmo m√™s no ano anterior. Esta t√©cnica captura padr√µes sazonais anuais, presumindo que os padr√µes
de vendas se repetem em ciclos anuais.
O c√°lculo final da previs√£o h√≠brida para cada m√™s e dado por:
Previs√£o H√≠brida = (M√©dia Movel 6 Meses √ó 0.5) + (Year-over-Year √ó 0.5)
Esta combina√ß√£o permite que o modelo capture tanto tend√™ncias recentes (via MM6) quanto padr√µes sazonais (via YoY), equilibrando a adaptabilidade a mudan√ßas
curtas com a estabilidade de padr√µes hist√≥ricos anuais.

### 3.2.5.3 Extra√ß√£o de dados e compara√ß√£o com modelos de ML

Ap√≥s a implementa√ß√£o das medidas DAX no Power BI, foi criada uma tabela contendo as seguintes colunas para cada m√™s no per√≠odo de teste:
- **M√™s/Ano**: Identificador temporal do per√≠odo;
- **Faturamento Real Teste**: Valor observado de faturamento para o m√™s, obtido atrav√©s da medida de Faturamento Realizado;
- **Faturamento Previsto (H√≠brido)**: Valor previsto usando o m√©todo h√≠brido descrito acima.
Esta tabela foi extra√≠da do Power BI em formato CSV e importada em um script
Python para realizar a compara√ß√£o com o melhor modelo de machine learning
(XGBoost). As m√©tricas padr√£o (MAE, RMSE e MAPE) foram calculadas diretamente sobre essa tabela, permitindo uma avalia√ß√£o quantitativa equivalente √† realizada
para os demais modelos de previs√£o desenvolvidos neste trabalho.
O armazenamento dos dados em formato CSV garante rastreabilidade dos resultados e facilita a reprodutibilidade da an√°lise, permitindo futuras revis√µes e
melhorias na metodologia de compara√ß√£o.

## 3.3 AVALIA√á√ÉO E COMPARA√á√ÉO DOS MODELOS

Ap√≥s o ajuste e valida√ß√£o de todos os modelos preditivos desenvolvidos neste trabalho, foi realizada uma compara√ß√£o quantitativa do desempenho de cada
modelo utilizando as seguintes m√©tricas estat√≠sticas, recomendadas pela literatura para problemas de previs√£o de s√©ries temporais:
a) Erro M√©dio Absoluto (MAE);
b) Raiz do Erro Quadr√°tico M√©dio (RMSE);
c) Erro Percentual Absoluto M√©dio (MAPE).

### 3.3.1 Compara√ß√£o entre os modelos de aprendizado de m√°quina e estat√≠sticos

As m√©tricas foram calculadas para o conjunto de teste de cada modelo (27 meses, de julho de 2023 a setembro de 2025), permitindo uma avalia√ß√£o consistente e
compar√°vel. Este processo seguiu a metodologia recomendada pela literatura para compara√ß√£o de modelos de previs√£o de s√©ries temporais, conforme Hyndman et al.
(1999) e Gardner (1985).
Os quatro modelos implementados (ARIMA, Exponential Smoothing, Theta e XGBoost) foram submetidos ao mesmo conjunto de teste, com as mesmas m√©tricas de erro
calculadas de forma padronizada. Esse procedimento permitiu uma compara√ß√£o quantitativa objetiva do desempenho de cada abordagem, considerando tanto modelos
estat√≠sticos tradicionais quanto algoritmos de aprendizado de m√°quina.

### 3.3.2 Compara√ß√£o do melhor modelo de ML versus m√©todo Power BI

Na sequ√™ncia, o modelo de melhor desempenho entre os algoritmos de machine learning foi comparado diretamente ao m√©todo de previs√£o h√≠brido atualmente
implementado no Power BI. Esta compara√ß√£o adicional √© essencial para responder √† quest√£o central de pesquisa deste trabalho: se modelos avan√ßados de aprendizado de
m√°quina conseguem superar uma abordagem estat√≠stica simples mas consolidada.
O procedimento de compara√ß√£o seguiu a mesma metodologia utilizada para a compara√ß√£o entre os modelos de ML. As m√©tricas MAE, RMSE e MAPE foram
calculadas para ambos os modelos utilizando o mesmo per√≠odo de teste (27 meses, de julho de 2023 a setembro de 2025), permitindo uma avalia√ß√£o consistente e
direta da efetividade de cada abordagem.

## 4 RESULTADOS

Nesta se√ß√£o s√£o apresentados os resultados da implementa√ß√£o e avalia√ß√£o de todos os modelos de previs√£o desenvolvidos neste trabalho. Os resultados s√£o organizados
por modelo, apresentando as m√©tricas de desempenho obtidas no conjunto de teste
(27 meses, de julho de 2023 a setembro de 2025) para cada abordagem.

### 4.1 Resultados dos Modelos de Aprendizado de M√°quina e Estat√≠sticos

Esta subse√ß√£o detalha o desempenho de cada t√©cnica (ARIMA, Exponential Smoothing, Theta e XGBoost), organizados em ordem de sofistica√ß√£o crescente. A apresenta√ß√£o segue uma progress√£o que permite visualizar claramente como a capacidade preditiva evoluiu entre os modelos tradicionais estat√≠sticos at√© as abordagens mais avan√ßadas de machine learning.

#### 4.1.1 ARIMA

O modelo ARIMA implementado utilizando AutoARIMA da biblioteca Darts apresentou os seguintes resultados no conjunto de teste:

| M√©trica | Valor |
|---------|-------|
| MAE | R$ 28,710,800.45 |
| RMSE | R$ 32,311,238.76 |
| MAPE | 78.73% |

O ARIMA apresentou o desempenho mais inferior entre todos os modelos testados.
O modelo dificuldade em capturar adequadamente os padr√µes complexos presentes nos dados de vendas, resultando em erros absolutamente elevados. O MAPE de 78.73%
indica que, em m√©dia, as previs√µes do ARIMA desviaram 78.73% dos valores reais observados, demonstrando capacidade preditiva muito limitada para este conjunto
de dados espec√≠fico.

#### 4.1.2 Exponential Smoothing

O modelo de Suaviza√ß√£o Exponencial (Exponential Smoothing) foi implementado utilizando a classe ExponentialSmoothing da Darts, aplicando o m√©todo de
Holt-Winters para capturar componentes de n√≠vel, tend√™ncia e sazonalidade.
Os resultados obtidos foram:

| M√©trica | Valor |
|---------|-------|
| MAE | R$ 21,846,386.39 |
| RMSE | R$ 25,914,518.67 |
| MAPE | 63.00% |

O Exponential Smoothing apresentou desempenho superior ao ARIMA em todas as m√©tricas, reduzindo o erro em 23.8% em rela√ß√£o ao MAE do ARIMA. Apesar dessa
melhoria, o MAPE de 63.00% ainda indica erros significativos nas previs√µes. O modelo demonstrou melhor capacidade que o ARIMA em capturar a sazonalidade dos
dados, por√©m ainda se mostrou insuficiente para gerar previs√µes com acur√°cia adequada para fins organizacionais.

#### 4.1.3 Theta

O m√©todo Theta foi implementado utilizando a classe AutoTheta da Darts, que aplica automaticamente t√©cnicas de decomposi√ß√£o temporal para capturar padr√µes de longo
e curto prazo na s√©rie. Os resultados foram:

| M√©trica | Valor |
|---------|-------|
| MAE | R$ 17,327,600.78 |
| RMSE | R$ 21,287,394.49 |
| MAPE | 39.71% |

O Theta apresentou desempenho substancialmente melhor que os dois modelos anteriores, reduzindo o MAE em 39.6% em rela√ß√£o ao Exponential Smoothing e em
69.2% em rela√ß√£o ao ARIMA. O MAPE de 39.71% representa uma redu√ß√£o significativa na magnitude dos erros percentuais, indicando que o m√©todo Theta conseguiu
capturar melhor os padr√µes sazonais e de tend√™ncia presentes nos dados de faturamento.

#### 4.1.4 XGBoost

O modelo XGBoost foi implementado utilizando a classe XGBModel da Darts com configura√ß√£o de 17 lags principais, 8 lags de covariadas passadas e 6 encoders
temporais, combinados com hyperpar√¢metros otimizados para o problema espec√≠fico.
Os resultados obtidos foram:

| M√©trica | Valor |
|---------|-------|
| MAE | R$ 10,110,160.96 |
| RMSE | R$ 13,302,309.10 |
| MAPE | 26.91% |

O XGBoost apresentou o melhor desempenho entre todos os modelos de machine learning testados. O modelo reduziu o MAE em 41.7% em rela√ß√£o ao Theta, 53.7%
em rela√ß√£o ao Exponential Smoothing e 64.8% em rela√ß√£o ao ARIMA. O MAPE de
26.91% representa a menor taxa de erro percentual observada entre os modelos, indicando que o XGBoost conseguiu capturar de forma mais eficaz os padr√µes
complexos e n√£o-lineares presentes nos dados de vendas. A superioridade do
XGBoost reflete a capacidade do algoritmo de gradient boosting em modelar relacionamentos complexos atrav√©s de suas m√∫ltiplas features de engenharia
temporal.

### 4.2 Resumo Comparativo dos Modelos de ML

A tabela abaixo apresenta um resumo consolidado dos resultados de todos os modelos de machine learning e estat√≠sticos:

| Modelo | MAE (R$) | RMSE (R$) | MAPE (%) | Ranking |
|--------|----------|-----------|----------|---------|
| ARIMA | 28,710,800.45 | 32,311,238.76 | 78.73 | 4¬∫ |
| Exponential Smoothing | 21,846,386.39 | 25,914,518.67 | 63.00 | 3¬∫ |
| Theta | 17,327,600.78 | 21,287,394.49 | 39.71 | 2¬∫ |
| XGBoost | 10,110,160.96 | 13,302,309.10 | 26.91 | 1¬∫ |

Com base nesta an√°lise, o XGBoost foi selecionado como o melhor modelo entre os algoritmos de machine learning testados para a pr√≥xima etapa de compara√ß√£o com a
abordagem implementada no Power BI.

### 4.3 Compara√ß√£o: Melhor Modelo de ML (XGBoost) versus M√©todo Power BI

Ap√≥s identificar o XGBoost como o melhor modelo entre os algoritmos de machine learning testados, foi realizada uma compara√ß√£o direta com o m√©todo de previs√£o
h√≠brido implementado no Power BI. Esta compara√ß√£o √© fundamental para responder √† quest√£o de pesquisa central deste trabalho.
Os resultados obtidos foram os seguintes:

| M√©todo/Modelo | MAE (R$) | RMSE (R$) | MAPE (%) | Vi√©s (%) | Acur√°cia (%) |
|---------------|----------|-----------|----------|----------|--------------|
| Power BI (H√≠brido: MM6 + YoY) | 95,139.69 | 119,785.85 | 23.45 | 1.47 | 79.44 |
| XGBoost (Melhor ML) | 10,110,160.96 | 13,302,309.10 | 26.91 | - | - |

**Resultado Principal: O m√©todo Power BI apresentou desempenho superior ao modelo XGBoost em todas as m√©tricas de erro avaliadas.**
O m√©todo h√≠brido implementado no Power BI combina duas t√©cnicas estat√≠sticas simples com efetividade comprovada:
1. **M√©dia M√≥vel 6 Meses (MM6)**: Calcula a m√©dia aritm√©tica dos √∫ltimos 6 meses, capturando tend√™ncias recentes e flutua√ß√µes de curto prazo;
2. **Year-over-Year (YoY)**: Utiliza o valor de faturamento do mesmo m√™s no ano anterior, assumindo que os padr√µes de vendas se repetem anualmente (sazonalidade anual bem definida).
Cada componente contribui com peso igual (50% cada), resultando em previs√µes que balanceiam adaptabilidade a mudan√ßas recentes com a estabilidade de padr√µes hist√≥ricos estabelecidos.
O desempenho superior √© evidente em todas as m√©tricas:
- **MAPE**: Power BI obteve 23.45% enquanto XGBoost alcan√ßou 26.91%, representando uma diferen√ßa de 3.46 pontos percentuais, equivalente a uma melhoria relativa de
12.9% em favor do Power BI;
- **MAE**: Power BI obteve R$ 95,139.69 enquanto XGBoost alcan√ßou R$ 10,110,160.96, uma diferen√ßa absoluta de R$ 10,015,021.27, equivalente a uma melhoria relativa de
99.1% em favor do Power BI;
- **RMSE**: Power BI obteve R$ 119,785.85 enquanto XGBoost alcan√ßou
R$ 13,302,309.10, indicando que o Power BI produz erros muito mais concentrados e previs√≠veis.
Adicionalmente, o m√©todo Power BI apresentou vi√©s de apenas 1.47%, indicando que as previs√µes s√£o praticamente n√£o-enviesadas em m√©dia, e acur√°cia de 79.44%
quando considerado o MAE em rela√ß√£o √† m√©dia dos valores observados no per√≠odo.

## 5 DISCUSS√ÉO

Os resultados apresentados na se√ß√£o anterior revelam insights importantes sobre a efetividade relativa de diferentes abordagens de previs√£o quando aplicadas ao
contexto espec√≠fico de previs√£o de vendas nesta organiza√ß√£o.

### 5.1 Desempenho Relativo dos Modelos de Machine Learning

A hierarquia de desempenho observada entre os modelos de machine learning e estat√≠sticos (ARIMA < Exponential Smoothing < Theta < XGBoost) reflete
progressivamente maior sofistica√ß√£o na captura de padr√µes temporais. O ARIMA, apesar de sua import√¢ncia te√≥rica como modelo can√¥nico em an√°lise de s√©ries
temporais, apresentou desempenho inadequado para este conjunto de dados, possivelmente devido a sua limita√ß√£o em modelar rela√ß√µes n√£o-lineares complexas.
O Exponential Smoothing demonstrou melhor capacidade em capturar a sazonalidade atrav√©s do m√©todo de Holt-Winters, por√©m ainda apresentou limita√ß√µes. O Theta,
com sua abordagem de decomposi√ß√£o temporal, melhorou substancialmente o desempenho, sugerindo que a separa√ß√£o expl√≠cita de componentes de longo e curto
prazo √© mais eficaz para estes dados que modelos globais como ARIMA.
O XGBoost, finalmente, apresentou o melhor desempenho entre os modelos testados.
A superioridade do XGBoost pode ser atribu√≠da √† sua capacidade de:
- Modelar intera√ß√µes n√£o-lineares entre features atrav√©s de m√∫ltiplas √°rvores de decis√£o;
- Capturar padr√µes complexos atrav√©s de 17 lags principais, 8 lags de covariadas e 6 encoders temporais;
- Aplicar regulariza√ß√£o L1 e L2 para evitar overfitting mantendo capacidade preditiva.
Contudo, o fato de que um modelo com 17 lags e 6 encoders temporais foi superado por uma combina√ß√£o simples de dois m√©todos estat√≠sticos b√°sicos √© revelador.

### 5.2 Superioridade do M√©todo Power BI: Uma An√°lise Cr√≠tica

O resultado mais significativo deste estudo √© que o m√©todo h√≠brido do Power BI superou substancialmente o melhor modelo de machine learning testado. Esta
descoberta contraria a expectativa comum de que algoritmos mais complexos e sofisticados produzem necessariamente melhores previs√µes.
O m√©todo Power BI combina apenas dois componentes simples, mas poderosos:
- **M√©dia M√≥vel 6 Meses**: Captura tend√™ncias recentes e volatilidades de curto prazo, sendo responsiva a mudan√ßas de comportamento nos √∫ltimos meses. Por exemplo, se houve uma queda de vendas nos √∫ltimos 3 meses, a MM6 refletir√° essa redu√ß√£o;
- **Year-over-Year (YoY)**: Baseia-se na premissa de que padr√µes de vendas se repetem em ciclos anuais. Concretamente, para prever faturamento em junho de 2024, utiliza-se o valor de junho de 2023, capturando sazonalidade estabelecida. Esta abordagem √© particularmente eficaz quando o neg√≥cio tem comportamentos sazonais bem definidos (p. ex., picos de vendas em per√≠odos espec√≠ficos do ano que se repetem consistentemente).
A melhoria de 12.9% do Power BI sobre o XGBoost em MAPE, embora menor em termos percentuais, √© mais significativa quando considerado em contexto:
1. **Simplicidade Operacional**: O m√©todo Power BI √© imediatamente compreens√≠vel pelos stakeholders n√£o-t√©cnicos, facilitando aceita√ß√£o organizacional e auditoria
das previs√µes;
2. **Estabilidade**: A aus√™ncia de hiperpar√¢metros complexos reduz o risco de degrada√ß√£o de desempenho em futuras aplica√ß√µes ou quando novos dados s√£o
incorporados;
3. **Interpretabilidade**: Cada componente (MM6 e YoY) √© facilmente explic√°vel em reuni√µes de neg√≥cio, ao contr√°rio do XGBoost que funciona como "caixa preta";
4. **Manuten√ß√£o**: O m√©todo Power BI requer pouca ou nenhuma reentrenagem, enquanto modelos de ML requerem monitoramento cont√≠nuo de performance e
poss√≠vel reciclagem peri√≥dica.
Estes fatores sugerem que a superioridade observada do Power BI n√£o √© apenas uma quest√£o estat√≠stica, mas tamb√©m de adequa√ß√£o pr√°tica √†s necessidades
organizacionais.

### 5.3 Implica√ß√µes para a Pr√°tica Organizacional

Este estudo demonstra que para o contexto espec√≠fico de previs√£o de vendas desta organiza√ß√£o, m√©todos simples e bem estabelecidos podem superar algoritmos
sofisticados de machine learning. Este achado alinha-se com a literatura que sugere que m√©todos estat√≠sticos tradicionais frequentemente alcan√ßam desempenho
competitivo em cen√°rios com sazonalidade clara e padr√µes bem definidos, conforme observado em estudos como Makridakis et al. (2000) e mais recentemente em
Hyndman e Athanasopoulos (2021).
As implica√ß√µes pr√°ticas incluem:
1. A continua√ß√£o do m√©todo Power BI atual √© justificada tanto estat√≠stica quanto operacionalmente;
2. Investimentos em infraestrutura de ML complexo para este problema espec√≠fico n√£o se justificam baseado em ganhos de acur√°cia;
3. Recursos podem ser melhor alocados em outras √°reas onde ML pode oferecer vantagens mais substantivas.
Contudo, reconhece-se que diferentes segmentos de produtos ou per√≠odos temporais espec√≠ficos podem apresentar padr√µes distintos, sugerindo que an√°lises
segmentadas poderiam ser exploradas em trabalhos futuros.

## 6 CONCLUS√ÉO

Este trabalho apresentou uma an√°lise comparativa abrangente de diferentes abordagens para previs√£o de vendas, comparando modelos estat√≠sticos tradicionais
(ARIMA, Exponential Smoothing, Theta) com algoritmos modernos de machine learning (XGBoost) e o m√©todo h√≠brido atualmente implementado no Power BI.

### 6.1 S√≠ntese dos Achados Principais

Os principais achados deste estudo foram:
1. **Hierarquia de Desempenho ML**: Entre os modelos de machine learning e estat√≠sticos testados, o XGBoost apresentou o melhor desempenho com MAPE de
26.91%, seguido por Theta (39.71%), Exponential Smoothing (63.00%) e ARIMA
(78.73%);
2. **Superioridade do Power BI**: O m√©todo h√≠brido Power BI (MM6 + YoY) superou o melhor modelo de ML em todas as m√©tricas, alcan√ßando MAPE de 23.45% comparado
aos 26.91% do XGBoost, uma melhoria relativa de 12.9%;
3. **Simplicidade Vence Complexidade**: A combina√ß√£o simples de dois m√©todos estat√≠sticos b√°sicos provou ser mais eficaz que um algoritmo sofisticado com 17
lags, 8 covariadas e 6 encoders temporais, sugerindo adequa√ß√£o particularmente alta do Power BI aos padr√µes espec√≠ficos dos dados de faturamento;
4. **Viabilidade Operacional**: Al√©m do desempenho superior, o m√©todo Power BI oferece vantagens significativas em termos de interpretabilidade, estabilidade,
manuten√ß√£o e aceita√ß√£o organizacional.

### 6.2 Resposta √† Quest√£o de Pesquisa

A quest√£o central deste trabalho foi: "Modelos avan√ßados de aprendizado de m√°quina conseguem superar o m√©todo h√≠brido simples implementado no Power BI?"
**Resposta: N√£o.** Os modelos testados, inclusive o melhor algoritmo de ML (XGBoost), n√£o conseguiram superar a efetividade do m√©todo Power BI. Ao contr√°rio, o Power BI
apresentou desempenho superior, consolidando sua adequa√ß√£o como m√©todo de previs√£o para este contexto espec√≠fico.

### 6.3 Recomenda√ß√µes

Com base nos achados deste estudo, recomenda-se:
1. **Manuten√ß√£o do M√©todo Atual**: Continuar utilizando o m√©todo h√≠brido Power BI para previs√µes de faturamento mensal, dado seu desempenho superior e
caracter√≠sticas operacionais favor√°veis;
2. **N√£o Investir em ML Geral**: Desconsiderar investimentos em implementa√ß√£o de modelos de ML complexos para o problema geral de previs√£o de vendas, pois os
ganhos incrementais de acur√°cia n√£o justificam a complexidade adicional;
3. **An√°lise Segmentada**: Explorar em trabalhos futuros se diferentes categorias de produtos ou per√≠odos sazonais espec√≠ficos apresentam padr√µes que possam
beneficiar de abordagens diferenciadas;
4. **Monitoramento Cont√≠nuo**: Manter monitoramento das m√©tricas de desempenho do m√©todo Power BI, com reavalia√ß√£o peri√≥dica caso novos dados ou mudan√ßas
estruturais nos padr√µes de vendas sejam observados.

### 6.4 Contribui√ß√£o Cient√≠fica

Este trabalho contribui para a literatura de previs√£o de s√©ries temporais ao:
- Documentar empiricamente um cen√°rio onde m√©todos simples superam algoritmos sofisticados;
- Destacar a import√¢ncia de considerar n√£o apenas acur√°cia estat√≠stica, mas tamb√©m viabilidade operacional na sele√ß√£o de m√©todos de previs√£o;
- Refor√ßar a recomenda√ß√£o de Makridakis et al. de n√£o negligenciar m√©todos estat√≠sticos simples em favor de abordagens mais complexas sem evid√™ncias claras
de ganho significativo;
- Contribuir para a aproxima√ß√£o entre pesquisa acad√™mica e pr√°tica organizacional ao demonstrar que a "melhor" solu√ß√£o frequentemente n√£o √© a mais sofisticada
tecnicamente.

### 6.5 Limita√ß√µes e Trabalhos Futuros

Este estudo apresenta algumas limita√ß√µes:
1. **Per√≠odo de Dados Limitado**: Os dados cobrem apenas 132 observa√ß√µes mensais
(2014-2025), o que pode n√£o ser suficiente para capturar padr√µes em ciclos econ√¥micos muito longos;
2. **Aus√™ncia de Vari√°veis Ex√≥genas**: O estudo utilizou apenas a s√©rie temporal de faturamento sem incorporar vari√°veis ex√≥genas como sazonalidade de
campanhas, indicadores econ√¥micos ou fatores externos;
3. **Contexto Organizacional Espec√≠fico**: Os achados s√£o espec√≠ficos a este conjunto de dados e organiza√ß√£o, podendo n√£o ser generaliz√°veis para outros
contextos.
Trabalhos futuros poderiam explorar:
- Incorpora√ß√£o de vari√°veis ex√≥genas nos modelos de ML;
- An√°lise segmentada por categoria de produto ou unidade de neg√≥cio;
- Explora√ß√£o de abordagens de ensemble que combinem Power BI com modelos ML;
- Investiga√ß√£o de m√©todos ML mais avan√ßados (redes neurais, LSTM) para compara√ß√£o;
- An√°lise de horizonte de previs√£o: avaliar se XGBoost se desempenha melhor em previs√µes de longo prazo.

### 6.6 Observa√ß√µes Finais

Este trabalho reafirma uma li√ß√£o importante para profissionais de dados e cientistas de dados: a escolha do melhor m√©todo nem sempre favorece a solu√ß√£o mais sofisticada.
Efetividade pr√°tica, interpretabilidade, estabilidade e adequa√ß√£o ao contexto organizacional s√£o crit√©rios igualmente importantes que devem ser considerados
quando se seleciona abordagens para problemas reais de previs√£o.

## REFER√äNCIAS

ASSIMAKOPOULOS, V.; NIKOLOPOULOS, K. The Theta model: a decomposition approach to forecasting. International Journal of Forecasting, v. 16, n. 4, p. 521‚Äì
530, out. 2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00066-2.

---

# Page 64

64
BEZERRA, Manoel Ivanildo Silvestre. Apostila de An√°lise de S√©ries Temporais.
S√£o Paulo: UNESP, 2006. Dispon√≠vel em:
https://www.ibilce.unesp.br/Home/Departamentos/MatematicaEstatistica/apostila_ser ies_temporais_unesp.pdf.
BOX, G. E. P. et al. Time s√©ries analysis: forecasting and control. Hoboken, New
Jersey: John Wiley & Sons, 2015.
CHEN, T.; GUESTRIN, C. XGBoost: a Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining - KDD ‚Äô16, v. 1, n. 1, p. 785‚Äì794, 13 ago. 2016. Dispon√≠vel em:
https://doi.org/10.1145/2939672.2939785.
DAIRU, X.; SHILONG, Z. Machine Learning Model for Sales Forecasting by
Using XGBoost. Dispon√≠vel em:
https://doi.org/10.1109/ICCECE51280.2021.9342304.
ENSAFI, Y. et al. Time-s√©ries forecasting of seasonal items sales using machine learning ‚Äì A comparative analysis. International Journal of Information
Management Data Insights, v. 2, n. 1, p. 100058, abr. 2022. Dispon√≠vel em:
https://doi.org/10.1016/j.jjimei.2022.100058.
FATTAH, J. et al. Forecasting of demand using ARIMA model. International Journal of Engineering Business Management, v. 10, n. 1, p. 184797901880867, Jan.
2018. Dispon√≠vel em: https://journals.sagepub.com/doi/10.1177/1847979018808673.
FIORUCCI, J. A. et al. Models for optimising the theta method and their relationship to state space models. International Journal of Forecasting, v. 32, n. 4, p. 1151‚Äì
1161, out. 2016. Dispon√≠vel em: https://doi.org/10.1016/j.ijforecast.2016.02.005.
FOURKIOTIS, K. P.; TSADIRAS, A. Applying Machine Learning and Statistical
Forecasting Methods for Enhancing Pharmaceutical Sales Predictions. Forecasting, v. 6, n. 1, p. 170‚Äì186, 1 mar. 2024. Dispon√≠vel em:
https://doi.org/10.3390/forecast6010010.

---

# Page 65

65
GARDNER, E. S. Exponential smoothing: The state of the art. Journal of
Forecasting, v. 4, n. 1, p. 1‚Äì28, 1985. Dispon√≠vel em:
https://doi.org/10.1002/for.3980040103.
KONTOPOULOU, V. I. et al. A Review of ARIMA vs. Machine Learning Approaches for Time S√©ries Forecasting in Data Driven Networks. Future Internet, v. 15, n. 8, p.
255, 1 ago. 2023. Dispon√≠vel em: https://doi.org/10.3390/fi15080255.
LOZIA, Z. Application of modelling and simulation to evaluate the theta method used in diagnostics of automotive shock absorbers. The Archives of Automotive
Engineering ‚Äì Archiwum Motoryzacji, v. 96, n. 2, p. 5‚Äì30, 30 jun. 2022. Dispon√≠vel em: https://doi.org/10.14669/AM/150823.
MAKRIDAKIS, S.; HIBON, M. The M3-Competition: results, conclusions and implications. International Journal of Forecasting, v. 16, n. 4, p. 451‚Äì476, out.
2000. Dispon√≠vel em: https://doi.org/10.1016/S0169-2070(00)00057-1.
MAKRIDAKIS, S.; WHEELWRIGHT, S. C.; HYNDMAN, R. J. Forecasting: Methods and Applications. In: Elements of Forecasting. Oxfordshire: Taylor & Francis, 1999.
p. 345‚Äì346. Dispon√≠vel em:
https://www.researchgate.net/publication/52008212_Forecasting_Methods_and_Appl ications.
MALIK, Shubham; HARODE, Rohan; KUNWAR, Akash Singh. XGBoost: a deep dive into boosting. Medium Blog, 2020. Dispon√≠vel em:
http://dx.doi.org/10.13140/RG.2.2.15243.64803.
MCKENZIE, ED. General exponential smoothing and the equivalent arma process. Journal of Forecasting, v. 3, n. 3, p. 333‚Äì344, Jul. 1984. Dispon√≠vel em:
https://doi.org/10.1002/for.3980030312.
MONDAL, P.; SHIT, L.; GOSWAMI, S. Study of Effectiveness of Time S√©ries
Modeling (Arima) in Forecasting Stock Prices. International Journal of Computer

---

# Page 66

66
Science, Engineering and Applications, v. 4, n. 2, p. 13‚Äì29, 30 abr. 2014.
Dispon√≠vel em: https://doi.org/10.5121/ijcsea.2014.4202.
MURAT, M. et al. Forecasting daily meteorological time s√©ries using ARIMA and regression models. International Agrophysics, v. 32, n. 2, p. 253‚Äì264, 1 abr. 2018.
Dispon√≠vel em: https://doi.org/10.1515/intag-2017-0007.
NEWBOLD, P. ARIMA model building and the time s√©ries analysis approach to forecasting. Journal of Forecasting, v. 2, n. 1, p. 23‚Äì35, Jan. 1983. Dispon√≠vel em:
https://doi.org/10.1002/for.3980020104.
PAO, James J.; SULLIVAN, Danielle S. Time s√©ries sales forecasting. Final year project, Computer Science, Stanford Univ., Stanford, CA, USA, 2017. Dispon√≠vel em:
https://cs229.stanford.edu/proj2017/final-reports/5244336.pdf.
PARZEN, E. An Approach to Time S√©ries Analysis. The Annals of Mathematical
Statistics, v. 32, n. 4, p. 951‚Äì989, 1961. Dispon√≠vel em:
https://www.jstor.org/stable/2237900.
SHIRI, F. M. et al. A Comprehensive Overview and Comparative Analysis on Deep
Learning Models. Journal on Artificial Intelligence, v. 6, n. 1, p. 301‚Äì360, 2024.
Dispon√≠vel em: https://doi.org/10.32604/jai.2024.054314.
SPILIOTIS, E.; ASSIMAKOPOULOS, V.; MAKRIDAKIS, S. Generalizing the Theta method for automatic forecasting. European Journal of Operational Research,
Jan. 2020. Dispon√≠vel em: http://dx.doi.org/10.1016/j.ejor.2020.01.007.
VAVLIAKIS, K.; SIAILIS, A.; SYMEONIDIS, A. Optimizing Sales Forecasting in e-
Commerce with ARIMA and LSTM Models. Proceedings of the 17th International
Conference on Web Information Systems and Technologies, 2021. Dispon√≠vel em: https://doi.org/10.5220/0010659500003058.